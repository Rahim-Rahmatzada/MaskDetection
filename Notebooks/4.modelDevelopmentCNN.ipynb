{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model optimised with Optuna and Transfer learning\n",
    "- Setting up PyTorch model architecture with efficientnet_b0 backbone\n",
    "- Optimizing hyperparameters using Optuna 5 trials\n",
    "- Training final model with most optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting random seeds n device\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#setting up paths \n",
    "projectRoot = Path().resolve().parent\n",
    "outputRoot = projectRoot / \"ModifiedDataset\"\n",
    "\n",
    "trainImagePath = outputRoot / \"train\" / \"images\"\n",
    "trainLabelPath = outputRoot / \"train\" / \"labels\"\n",
    "testImagePath = outputRoot / \"test\" / \"images\"\n",
    "testLabelPath = outputRoot / \"test\" / \"labels\"\n",
    "\n",
    "with open(outputRoot / \"kfold_splits.json\", \"r\") as f:\n",
    "    kfold_splits = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset func\n",
    "def load_dataset(image_dir, label_dir):\n",
    "    image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "    paths, labels = [], []\n",
    "    for fname in image_files:\n",
    "        paths.append(os.path.join(image_dir, fname))\n",
    "        label_path = os.path.join(label_dir, fname.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt'))\n",
    "        with open(label_path) as f:\n",
    "            labels.append(int(f.read().strip()))\n",
    "    return paths, np.array(labels)\n",
    "\n",
    "train_image_paths, train_labels = load_dataset(trainImagePath, trainLabelPath)\n",
    "test_image_paths, test_labels = load_dataset(testImagePath, testLabelPath)\n",
    "\n",
    "augImagePath = outputRoot / \"AugmentedData\" / \"images\"\n",
    "augLabelPath = outputRoot / \"AugmentedData\" / \"labels\"\n",
    "aug_image_paths, aug_labels = load_dataset(augImagePath, augLabelPath)\n",
    "\n",
    "all_train_image_paths = train_image_paths + aug_image_paths\n",
    "all_train_labels = np.concatenate([train_labels, aug_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms and dataset class\n",
    "def get_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.image_paths[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transform(img)\n",
    "        return img, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model builder and utilities\n",
    "def build_model(pretrained=True, num_classes=3):\n",
    "    base = models.efficientnet_b0(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "    features = base.classifier[1].in_features\n",
    "    base = nn.Sequential(base.features, nn.AdaptiveAvgPool2d(1))\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        base,\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    return model.to(device)\n",
    "\n",
    "def freeze_model(model, freeze_ratio=0.5):\n",
    "    params = list(model[0].parameters())\n",
    "    cutoff = int(len(params) * freeze_ratio)\n",
    "    for i, param in enumerate(params):\n",
    "        param.requires_grad = i >= cutoff\n",
    "    return model\n",
    "\n",
    "def calculate_class_weights(labels):\n",
    "    counts = np.bincount(labels)\n",
    "    total = len(labels)\n",
    "    return torch.tensor(total / (len(counts) * counts), dtype=torch.float32).to(device)\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            preds.extend(out.argmax(1).cpu().numpy())\n",
    "            targets.extend(y.cpu().numpy())\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(targets, preds, average='weighted')\n",
    "    cm = confusion_matrix(targets, preds)\n",
    "    report = classification_report(targets, preds, target_names=['No Mask', 'Mask', 'Improper Mask'])\n",
    "    return acc, prec, rec, f1, cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optuna objective\n",
    "def objective(trial):\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])\n",
    "    lr = trial.suggest_float('learning_rate', 1e-5, 5e-4, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    freeze_ratio = trial.suggest_float('freeze_ratio', 0.5, 0.9)\n",
    "    use_class_weights = trial.suggest_categorical('use_class_weights', [True, False])\n",
    "    scheduler_type = trial.suggest_categorical('scheduler_type', ['step', 'cosine', 'none'])\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for fold_idx in kfold_splits:\n",
    "        train_idx = kfold_splits[fold_idx]['train']\n",
    "        val_idx = kfold_splits[fold_idx]['val']\n",
    "\n",
    "        X_train = [all_train_image_paths[i] for i in train_idx]\n",
    "        y_train = all_train_labels[train_idx]\n",
    "        X_val = [all_train_image_paths[i] for i in val_idx]\n",
    "        y_val = all_train_labels[val_idx]\n",
    "\n",
    "        train_loader = DataLoader(CustomDataset(X_train, y_train, get_transforms()), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(CustomDataset(X_val, y_val, get_transforms()), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = build_model()\n",
    "        model = freeze_model(model, freeze_ratio)\n",
    "\n",
    "        class_weights = calculate_class_weights(y_train) if use_class_weights else None\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        if scheduler_type == 'step':\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "        elif scheduler_type == 'cosine':\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "        else:\n",
    "            scheduler = None\n",
    "\n",
    "        for epoch in range(10):\n",
    "            model.train()\n",
    "            for xb, yb in tqdm(train_loader, desc=f\"Fold {fold_idx} Epoch {epoch+1}\", leave=False):\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model(xb), yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "        acc, *_ = evaluate_model(model, val_loader)\n",
    "        scores.append(acc)\n",
    "\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 06:04:29,422] A new study created in memory with name: no-name-6c3ef741-a653-4928-8daa-d3edde251f2d\n",
      "[I 2025-04-27 06:27:37,147] Trial 0 finished with value: 0.9407457821762113 and parameters: {'batch_size': 16, 'learning_rate': 0.0003081036640811829, 'weight_decay': 0.0003620014114001303, 'freeze_ratio': 0.5890893944032941, 'use_class_weights': False, 'scheduler_type': 'step'}. Best is trial 0 with value: 0.9407457821762113.\n",
      "[I 2025-04-27 06:49:33,471] Trial 1 finished with value: 0.8687605762248156 and parameters: {'batch_size': 16, 'learning_rate': 4.305161439365348e-05, 'weight_decay': 6.229649916553409e-05, 'freeze_ratio': 0.7072290223746327, 'use_class_weights': True, 'scheduler_type': 'cosine'}. Best is trial 0 with value: 0.9407457821762113.\n",
      "[I 2025-04-27 07:08:26,682] Trial 2 finished with value: 0.7601442250857076 and parameters: {'batch_size': 32, 'learning_rate': 1.440407281858524e-05, 'weight_decay': 3.736507515202722e-05, 'freeze_ratio': 0.8191615918797701, 'use_class_weights': True, 'scheduler_type': 'step'}. Best is trial 0 with value: 0.9407457821762113.\n",
      "[I 2025-04-27 07:28:10,131] Trial 3 finished with value: 0.8058747234559978 and parameters: {'batch_size': 32, 'learning_rate': 2.424259780164549e-05, 'weight_decay': 6.688662851736841e-05, 'freeze_ratio': 0.5283095185130586, 'use_class_weights': False, 'scheduler_type': 'step'}. Best is trial 0 with value: 0.9407457821762113.\n",
      "[I 2025-04-27 07:48:25,246] Trial 4 finished with value: 0.7952203063516458 and parameters: {'batch_size': 16, 'learning_rate': 2.7212223772947088e-05, 'weight_decay': 6.0687857510148836e-05, 'freeze_ratio': 0.8956021193966353, 'use_class_weights': False, 'scheduler_type': 'cosine'}. Best is trial 0 with value: 0.9407457821762113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'batch_size': 16, 'learning_rate': 0.0003081036640811829, 'weight_decay': 0.0003620014114001303, 'freeze_ratio': 0.5890893944032941, 'use_class_weights': False, 'scheduler_type': 'step'}\n"
     ]
    }
   ],
   "source": [
    "#running Optuna search\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Loss = 0.3883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation Loss = 0.4119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validation Loss = 0.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validation Loss = 0.3092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Validation Loss = 0.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Validation Loss = 0.3152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Validation Loss = 0.3273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Validation Loss = 0.3123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Validation Loss = 0.2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Validation Loss = 0.3099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final model training and validation\n",
    "batch_size = best_params['batch_size']\n",
    "lr = best_params['learning_rate']\n",
    "weight_decay = best_params['weight_decay']\n",
    "freeze_ratio = best_params['freeze_ratio']\n",
    "use_class_weights = best_params['use_class_weights']\n",
    "scheduler_type = best_params['scheduler_type']\n",
    "\n",
    "model = build_model()\n",
    "model = freeze_model(model, freeze_ratio)\n",
    "\n",
    "val_split = 0.1\n",
    "val_size = int(len(all_train_image_paths) * val_split)\n",
    "train_paths = all_train_image_paths[val_size:]\n",
    "train_labels_ = all_train_labels[val_size:]\n",
    "val_paths = all_train_image_paths[:val_size]\n",
    "val_labels_ = all_train_labels[:val_size]\n",
    "\n",
    "train_loader_final = DataLoader(CustomDataset(train_paths, train_labels_, get_transforms()), batch_size=batch_size, shuffle=True)\n",
    "val_loader_final = DataLoader(CustomDataset(val_paths, val_labels_, get_transforms()), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class_weights = calculate_class_weights(train_labels_) if use_class_weights else None\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "if scheduler_type == 'step':\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "elif scheduler_type == 'cosine':\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for xb, yb in tqdm(train_loader_final, desc=f\"Final Train Epoch {epoch+1}\", leave=False):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(xb), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader_final:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader_final)\n",
    "    print(f\"Epoch {epoch+1}: Validation Loss = {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_wts = model.state_dict()\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on Test Set ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.75      0.65      0.69        51\n",
      "         Mask       0.94      0.97      0.96       388\n",
      "Improper Mask       0.83      0.53      0.65        19\n",
      "\n",
      "     accuracy                           0.92       458\n",
      "    macro avg       0.84      0.72      0.77       458\n",
      " weighted avg       0.91      0.92      0.91       458\n",
      "\n",
      "Test Set Accuracy: 91.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#evaluation\n",
    "print(\"\\n=== Evaluation on Test Set ===\")\n",
    "test_loader = DataLoader(CustomDataset(test_image_paths, test_labels, get_transforms()), batch_size=32, shuffle=False)\n",
    "test_results = evaluate_model(model, test_loader)\n",
    "print(test_results[-1])\n",
    "print(f\"Test Set Accuracy: {test_results[0]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model and hyperparameters saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#saving model and params\n",
    "save_path = projectRoot / \"Models\"\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), save_path / \"CNN_EfficientNet.pth\")\n",
    "\n",
    "with open(save_path / \"CNN_EfficientNet_params.json\", \"w\") as f:\n",
    "    json.dump(best_params, f, indent=4)\n",
    "\n",
    "print(\"\\nModel and hyperparameters saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development of CNN Model: Major Findings\n",
    "\n",
    "- **Transfer learning works effectively**: Pre-trained efficientnet_b0 vastly outperforms resnet18 and MobileNetV2, suggesting architecture matters more than model size\n",
    "\n",
    "- **Class imbalance** still remained an issue: but this was mititgated as much as possible by using augmentation, detection of the minority class (\"Improper Mask 2\") is still lagging behind, with only 53% recall compared to 97% for the majority class\n",
    "\n",
    "\n",
    "- **Hyperparameter significance**: Learning rate and freeze ratio were critical, freezing pre-trained layers helped to provide the right balance between feature reuse and adaptation\n",
    "\n",
    "- **Training efficiency**: Early stopping typically triggered between epochs 5-7, indicating diminishing returns beyond this point and potential for faster training cycles, and this was significantly helpful at reducing training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-env)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
