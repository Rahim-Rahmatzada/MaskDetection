{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from skimage.feature import local_binary_pattern\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#set up paths\n",
    "projectRoot = Path().resolve().parent\n",
    "datasetPath = projectRoot / \"CV2024_CW_Dataset\"\n",
    "outputRoot = projectRoot / \"ModifiedDataset\"\n",
    "\n",
    "#ddefine dataset paths\n",
    "trainOutputPath = outputRoot / \"train\" / \"images\"\n",
    "trainOutputLabelPath = outputRoot / \"train\" / \"labels\"\n",
    "testOutputPath = outputRoot / \"test\" / \"images\"\n",
    "testOutputLabelPath = outputRoot / \"test\" / \"labels\"\n",
    "valOutputPath = outputRoot / \"validation\" / \"images\"\n",
    "valOutputLabelPath = outputRoot / \"validation\" / \"labels\"\n",
    "augDataPath = outputRoot / \"AugmentedData\" / \"images\"\n",
    "augLabelPath = outputRoot / \"AugmentedData\" / \"labels\"\n",
    "\n",
    "#setup features directory\n",
    "featuresDir = outputRoot / \"features\"\n",
    "featuresDir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# verify the paths\n",
    "for path in [trainOutputPath, trainOutputLabelPath, testOutputPath, testOutputLabelPath, valOutputPath, valOutputLabelPath]:\n",
    "    if not path.exists():\n",
    "        print(f\"Warning: Path {path} does not exist\")\n",
    "\n",
    "print(\"Paths set up successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lbp_features(image, radius=3, n_points=24, method='uniform'):\n",
    "    ##computing lbp features for a img\n",
    "    # make sure img is greyscale\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # compute LBP\n",
    "    lbp = local_binary_pattern(image, n_points, radius, method)\n",
    "    \n",
    "    # calculate histogram of LBP\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset_features(image_paths, label_paths, lbp_params=None):\n",
    "    # extract lbp features for all imgs in a dataset\n",
    "    if lbp_params is None:\n",
    "        lbp_params = {\n",
    "            'radius': 3,\n",
    "            'n_points': 24,\n",
    "            'method': 'uniform'\n",
    "        }\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    #extract features/labels\n",
    "    for img_path, label_path in tqdm(zip(image_paths, label_paths), total=len(image_paths), desc=\"Extracting LBP features\"):\n",
    "\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            label = int(f.read().strip())\n",
    "        \n",
    "        # extract LBP features\n",
    "        lbp_features = compute_lbp_features(\n",
    "            image,\n",
    "            radius=lbp_params['radius'],\n",
    "            n_points=lbp_params['n_points'],\n",
    "            method=lbp_params['method']\n",
    "        )\n",
    "        \n",
    "        features.append(lbp_features)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_features(dataset_path, output_path, dataset_type, lbp_params=None):\n",
    "    # method prepares and saves lbp features for a dataset\n",
    "    \n",
    "    images_path = os.path.join(dataset_path, dataset_type, \"images\")\n",
    "    labels_path = os.path.join(dataset_path, dataset_type, \"labels\")\n",
    "    \n",
    "    # get all img files\n",
    "    image_files = sorted([f for f in os.listdir(images_path) if f.endswith('.jpeg')])\n",
    "    \n",
    "    #create full paths\n",
    "    image_paths = [os.path.join(images_path, f) for f in image_files]\n",
    "    label_paths = [os.path.join(labels_path, f.replace('.jpeg', '.txt')) for f in image_files]\n",
    "    \n",
    "    # extract features\n",
    "    X, y = extract_dataset_features(image_paths, label_paths, lbp_params)\n",
    "    \n",
    "    # create output directory if it dosent already exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # save features/labels\n",
    "    joblib.dump((X, y), os.path.join(output_path, f\"{dataset_type}_lbp_features.joblib\"))\n",
    "    \n",
    "    print(f\"Saved {dataset_type} LBP features with shape {X.shape}\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lbp_features(image_path, lbp_params=None):\n",
    "    #visualize lbp featuress for an img\n",
    "    if lbp_params is None:\n",
    "        lbp_params = {\n",
    "            'radius': 3,\n",
    "            'n_points': 24,\n",
    "            'method': 'uniform'\n",
    "        }\n",
    "    \n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Compute LBP\n",
    "    lbp_image = local_binary_pattern(\n",
    "        image, \n",
    "        lbp_params['n_points'], \n",
    "        lbp_params['radius'], \n",
    "        lbp_params['method']\n",
    "    )\n",
    "    \n",
    "    return image, lbp_image\n",
    "\n",
    "def display_sample_lbp_features(image_paths, lbp_params=None, num_samples=3):\n",
    "    ##display lbp features for sample imgs\n",
    "    import random\n",
    "    \n",
    "    # selecting random samples\n",
    "    if len(image_paths) > num_samples:\n",
    "        sample_paths = random.sample(image_paths, num_samples)\n",
    "    else:\n",
    "        sample_paths = image_paths\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(10, 4 * num_samples))\n",
    "    \n",
    "    for i, img_path in enumerate(sample_paths):\n",
    "        # get original img and LBP visualisation\n",
    "        original, lbp_img = visualize_lbp_features(img_path, lbp_params)\n",
    "        \n",
    "        # display original img\n",
    "        axes[i, 0].imshow(original, cmap='gray')\n",
    "        axes[i, 0].set_title(f\"Original Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # display LBP features\n",
    "        axes[i, 1].imshow(lbp_img, cmap='jet')\n",
    "        axes[i, 1].set_title(f\"LBP Features\")\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_lbp_parameters(sample_images, sample_labels, param_grid):\n",
    "    \"\"\"Find optimal LBP parameters using a small subset of images\"\"\"\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    radii = param_grid.get('radius', [3])\n",
    "    n_points_list = param_grid.get('n_points', [24])\n",
    "    methods = param_grid.get('method', ['uniform'])\n",
    "    \n",
    "    # Store results\n",
    "    results = []\n",
    "    \n",
    "    total_combinations = len(radii) * len(n_points_list) * len(methods)\n",
    "    pbar = tqdm(total=total_combinations, desc=\"Optimizing LBP parameters\")\n",
    "    \n",
    "    for radius in radii:\n",
    "        for n_points in n_points_list:\n",
    "            for method in methods:\n",
    "                lbp_params = {\n",
    "                    'radius': radius,\n",
    "                    'n_points': n_points,\n",
    "                    'method': method\n",
    "                }\n",
    "                \n",
    "                # Extract features for samples\n",
    "                sample_features = []\n",
    "                for img_path in sample_images:\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    features = compute_lbp_features(img, **lbp_params)\n",
    "                    sample_features.append(features)\n",
    "                \n",
    "                # Train a simple SVM\n",
    "                svm = SVC(kernel='linear')\n",
    "                svm.fit(sample_features, sample_labels)\n",
    "                score = svm.score(sample_features, sample_labels)\n",
    "                \n",
    "                # Store results\n",
    "                results.append({\n",
    "                    'params': lbp_params,\n",
    "                    'score': score,\n",
    "                    'feature_dim': len(sample_features[0])\n",
    "                })\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Find best parameters\n",
    "    results.sort(key=lambda x: x['score'], reverse=True)\n",
    "    best_params = results[0]['params']\n",
    "    \n",
    "    print(f\"Best LBP parameters: {best_params} with score {results[0]['score']:.4f}\")\n",
    "    print(f\"Feature dimension: {results[0]['feature_dim']}\")\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set LBP parameters\n",
    "lbp_params = {\n",
    "    'radius': 3,        \n",
    "    'n_points': 24, \n",
    "    'method': 'uniform'  \n",
    "}\n",
    "\n",
    "print(\"Extracting LBP features from datasets...\")\n",
    "\n",
    "# Training set\n",
    "X_train, y_train = prepare_dataset_features(\n",
    "    str(outputRoot),\n",
    "    str(features_dir),\n",
    "    \"train\",\n",
    "    lbp_params=lbp_params\n",
    ")\n",
    "\n",
    "# Validation set\n",
    "X_val, y_val = prepare_dataset_features(\n",
    "    str(outputRoot),\n",
    "    str(features_dir),\n",
    "    \"validation\",\n",
    "    lbp_params=lbp_params\n",
    ")\n",
    "\n",
    "# Test set\n",
    "X_test, y_test = prepare_dataset_features(\n",
    "    str(outputRoot),\n",
    "    str(features_dir),\n",
    "    \"test\",\n",
    "    lbp_params=lbp_params\n",
    ")\n",
    "\n",
    "# Augmented data set\n",
    "if augDataPath.exists() and augLabelPath.exists():\n",
    "    X_aug, y_aug = prepare_dataset_features(\n",
    "        str(outputRoot),\n",
    "        str(features_dir),\n",
    "        \"AugmentedData\",\n",
    "        lbp_params=lbp_params\n",
    "    )\n",
    "    print(f\"Augmented features shape: {X_aug.shape}\")\n",
    "else:\n",
    "    print(\"Augmented dataset not found, skipping feature extraction.\")\n",
    "\n",
    "print(\"LBP feature extraction complete!\")\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Validation features shape: {X_val.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display LBP features for sample images\n",
    "print(\"Displaying LBP features for sample images...\")\n",
    "\n",
    "# Path to training images\n",
    "train_image_dir = str(trainOutputPath)\n",
    "train_image_files = sorted([f for f in os.listdir(train_image_dir) if f.endswith('.jpeg')])\n",
    "train_image_paths = [os.path.join(train_image_dir, f) for f in train_image_files]\n",
    "\n",
    "# Show sample images with LBP features\n",
    "display_sample_lbp_features(train_image_paths, lbp_params, num_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LBP Feature Extraction\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from skimage.feature import local_binary_pattern\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Set up paths - same as HOG notebook\n",
    "projectRoot = Path().resolve().parent\n",
    "datasetPath = projectRoot / \"CV2024_CW_Dataset\"\n",
    "outputRoot = projectRoot / \"ModifiedDataset\"\n",
    "\n",
    "trainOutputPath = outputRoot / \"train\" / \"images\"\n",
    "trainOutputLabelPath = outputRoot / \"train\" / \"labels\"\n",
    "testOutputPath = outputRoot / \"test\" / \"images\"\n",
    "testOutputLabelPath = outputRoot / \"test\" / \"labels\"\n",
    "valOutputPath = outputRoot / \"validation\" / \"images\"\n",
    "valOutputLabelPath = outputRoot / \"validation\" / \"labels\"\n",
    "\n",
    "augDataPath = outputRoot / \"AugmentedData\" / \"images\"\n",
    "augLabelPath = outputRoot / \"AugmentedData\" / \"labels\"\n",
    "\n",
    "# Features directory\n",
    "featuresDir = outputRoot / \"features\"\n",
    "featuresDir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for path in [trainOutputPath, trainOutputLabelPath, testOutputPath, testOutputLabelPath, valOutputPath, valOutputLabelPath]:\n",
    "    if not path.exists():\n",
    "        print(f\"Warning: Path {path} does not exist\")\n",
    "\n",
    "print(\"Paths set up successfully.\")\n",
    "\n",
    "def compute_lbp_features(image, radius=3, n_points=24, method='uniform'):\n",
    "    \"\"\"\n",
    "    Compute LBP features for an image\n",
    "    \n",
    "    Args:\n",
    "        image: Input grayscale image\n",
    "        radius: Radius of circle (spatial resolution of the operator)\n",
    "        n_points: Number of circularly symmetric neighbor points\n",
    "        method: {'default', 'ror', 'uniform', 'var'}\n",
    "        \n",
    "    Returns:\n",
    "        lbp_features: Flattened LBP feature vector\n",
    "    \"\"\"\n",
    "    # Ensure the image is grayscale\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute LBP\n",
    "    lbp = local_binary_pattern(image, n_points, radius, method)\n",
    "    \n",
    "    # Calculate histogram of LBP\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    \n",
    "    return hist\n",
    "\n",
    "def extract_dataset_features(image_paths, label_paths, lbp_params=None):\n",
    "    \"\"\"\n",
    "    Extract LBP features for all images in a dataset\n",
    "    \n",
    "    Args:\n",
    "        image_paths: List of paths to images\n",
    "        label_paths: List of paths to label files\n",
    "        lbp_params: Dictionary of LBP parameters\n",
    "        \n",
    "    Returns:\n",
    "        X: Array of LBP features\n",
    "        y: Array of labels\n",
    "    \"\"\"\n",
    "    if lbp_params is None:\n",
    "        lbp_params = {\n",
    "            'radius': 3,\n",
    "            'n_points': 24,\n",
    "            'method': 'uniform'\n",
    "        }\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Extract features and labels\n",
    "    for img_path, label_path in tqdm(zip(image_paths, label_paths), total=len(image_paths), desc=\"Extracting LBP features\"):\n",
    "        # Read image\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Read label\n",
    "        with open(label_path, 'r') as f:\n",
    "            label = int(f.read().strip())\n",
    "        \n",
    "        # Extract LBP features\n",
    "        lbp_features = compute_lbp_features(\n",
    "            image,\n",
    "            radius=lbp_params['radius'],\n",
    "            n_points=lbp_params['n_points'],\n",
    "            method=lbp_params['method']\n",
    "        )\n",
    "        \n",
    "        features.append(lbp_features)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "def prepare_dataset_features(dataset_path, output_path, dataset_type, lbp_params=None):\n",
    "    \"\"\"\n",
    "    Prepare and save LBP features for a dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to the dataset folder\n",
    "        output_path: Path to save the extracted features\n",
    "        dataset_type: Type of dataset (train, validation, test)\n",
    "        lbp_params: Dictionary of LBP parameters\n",
    "    \n",
    "    Returns:\n",
    "        X: Array of LBP features\n",
    "        y: Array of labels\n",
    "    \"\"\"\n",
    "    # Define paths\n",
    "    images_path = os.path.join(dataset_path, dataset_type, \"images\")\n",
    "    labels_path = os.path.join(dataset_path, dataset_type, \"labels\")\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = sorted([f for f in os.listdir(images_path) if f.endswith('.jpeg')])\n",
    "    \n",
    "    # Create full paths\n",
    "    image_paths = [os.path.join(images_path, f) for f in image_files]\n",
    "    label_paths = [os.path.join(labels_path, f.replace('.jpeg', '.txt')) for f in image_files]\n",
    "    \n",
    "    # Extract features\n",
    "    X, y = extract_dataset_features(image_paths, label_paths, lbp_params)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Save features and labels\n",
    "    joblib.dump((X, y), os.path.join(output_path, f\"{dataset_type}_lbp_features.joblib\"))\n",
    "    \n",
    "    print(f\"Saved {dataset_type} LBP features with shape {X.shape}\")\n",
    "    return X, y\n",
    "\n",
    "def visualize_lbp_features(image_path, lbp_params=None):\n",
    "    \"\"\"\n",
    "    Visualize LBP features for an image\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image\n",
    "        lbp_params: Dictionary of LBP parameters\n",
    "        \n",
    "    Returns:\n",
    "        original_image: Original image\n",
    "        lbp_image: LBP image\n",
    "    \"\"\"\n",
    "    if lbp_params is None:\n",
    "        lbp_params = {\n",
    "            'radius': 3,\n",
    "            'n_points': 24,\n",
    "            'method': 'uniform'\n",
    "        }\n",
    "    \n",
    "    # Read image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Compute LBP\n",
    "    lbp_image = local_binary_pattern(\n",
    "        image, \n",
    "        lbp_params['n_points'], \n",
    "        lbp_params['radius'], \n",
    "        lbp_params['method']\n",
    "    )\n",
    "    \n",
    "    return image, lbp_image\n",
    "\n",
    "def optimize_lbp_parameters(sample_images, sample_labels, param_grid):\n",
    "    \"\"\"\n",
    "    Find optimal LBP parameters using a small subset of images\n",
    "    \n",
    "    Args:\n",
    "        sample_images: List of sample image paths\n",
    "        sample_labels: Corresponding labels\n",
    "        param_grid: Dictionary of LBP parameters to try\n",
    "        \n",
    "    Returns:\n",
    "        best_params: Dictionary with best LBP parameters\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    radii = param_grid.get('radius', [3])\n",
    "    n_points_list = param_grid.get('n_points', [24])\n",
    "    methods = param_grid.get('method', ['uniform'])\n",
    "    \n",
    "    # Store results\n",
    "    results = []\n",
    "    \n",
    "    total_combinations = len(radii) * len(n_points_list) * len(methods)\n",
    "    pbar = tqdm(total=total_combinations, desc=\"Optimizing LBP parameters\")\n",
    "    \n",
    "    for radius in radii:\n",
    "        for n_points in n_points_list:\n",
    "            for method in methods:\n",
    "                lbp_params = {\n",
    "                    'radius': radius,\n",
    "                    'n_points': n_points,\n",
    "                    'method': method\n",
    "                }\n",
    "                \n",
    "                # Extract features for samples\n",
    "                sample_features = []\n",
    "                for img_path in sample_images:\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    features = compute_lbp_features(img, **lbp_params)\n",
    "                    sample_features.append(features)\n",
    "                \n",
    "                # Train a simple SVM\n",
    "                svm = SVC(kernel='linear')\n",
    "                svm.fit(sample_features, sample_labels)\n",
    "                score = svm.score(sample_features, sample_labels)\n",
    "                \n",
    "                # Store results\n",
    "                results.append({\n",
    "                    'params': lbp_params,\n",
    "                    'score': score,\n",
    "                    'feature_dim': len(sample_features[0])\n",
    "                })\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Find best parameters\n",
    "    results.sort(key=lambda x: x['score'], reverse=True)\n",
    "    best_params = results[0]['params']\n",
    "    \n",
    "    print(f\"Best LBP parameters: {best_params} with score {results[0]['score']:.4f}\")\n",
    "    print(f\"Feature dimension: {results[0]['feature_dim']}\")\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "def display_sample_lbp_features(image_paths, lbp_params=None, num_samples=3):\n",
    "    \"\"\"\n",
    "    Display LBP features for sample images\n",
    "    \n",
    "    Args:\n",
    "        image_paths: List of image paths\n",
    "        lbp_params: LBP parameters\n",
    "        num_samples: Number of samples to display\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    # Select random samples\n",
    "    if len(image_paths) > num_samples:\n",
    "        sample_paths = random.sample(image_paths, num_samples)\n",
    "    else:\n",
    "        sample_paths = image_paths\n",
    "    \n",
    "    # Set up figure\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(10, 4 * num_samples))\n",
    "    \n",
    "    for i, img_path in enumerate(sample_paths):\n",
    "        # Get original image and LBP visualization\n",
    "        original, lbp_img = visualize_lbp_features(img_path, lbp_params)\n",
    "        \n",
    "        # Display original image\n",
    "        axes[i, 0].imshow(original, cmap='gray')\n",
    "        axes[i, 0].set_title(f\"Original Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Display LBP features\n",
    "        axes[i, 1].imshow(lbp_img, cmap='jet')\n",
    "        axes[i, 1].set_title(f\"LBP Features\")\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# LBP parameters - you can adjust these based on your needs\n",
    "lbp_params = {\n",
    "    'radius': 3,        \n",
    "    'n_points': 24, \n",
    "    'method': 'uniform'  \n",
    "}\n",
    "\n",
    "# Create features directory\n",
    "features_dir = outputRoot / \"features\"\n",
    "features_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Extracting LBP features from datasets...\")\n",
    "\n",
    "# Training set\n",
    "X_train, y_train = prepare_dataset_features(\n",
    "    str(outputRoot),\n",
    "    str(features_dir),\n",
    "    \"train\",\n",
    "    lbp_params=lbp_params\n",
    ")\n",
    "\n",
    "# Validation set\n",
    "X_val, y_val = prepare_dataset_features(\n",
    "    str(outputRoot),\n",
    "    str(features_dir),\n",
    "    \"validation\",\n",
    "    lbp_params=lbp_params\n",
    ")\n",
    "\n",
    "# Test set\n",
    "X_test, y_test = prepare_dataset_features(\n",
    "    str(outputRoot),\n",
    "    str(features_dir),\n",
    "    \"test\",\n",
    "    lbp_params=lbp_params\n",
    ")\n",
    "\n",
    "# Augmented data set\n",
    "if augDataPath.exists() and augLabelPath.exists():\n",
    "    X_aug, y_aug = prepare_dataset_features(\n",
    "        str(outputRoot),\n",
    "        str(features_dir),\n",
    "        \"AugmentedData\",\n",
    "        lbp_params=lbp_params\n",
    "    )\n",
    "    print(f\"Augmented features shape: {X_aug.shape}\")\n",
    "else:\n",
    "    print(\"Augmented dataset not found, skipping feature extraction.\")\n",
    "\n",
    "print(\"LBP feature extraction complete!\")\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Validation features shape: {X_val.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "\n",
    "# Visualize LBP features \n",
    "print(\"Displaying LBP features for sample images...\")\n",
    "\n",
    "# Path to some training images\n",
    "train_image_dir = str(trainOutputPath)\n",
    "train_image_files = sorted([f for f in os.listdir(train_image_dir) if f.endswith('.jpeg')])\n",
    "train_image_paths = [os.path.join(train_image_dir, f) for f in train_image_files]\n",
    "\n",
    "# Display LBP features for sample images\n",
    "display_sample_lbp_features(train_image_paths, lbp_params, num_samples=4)\n",
    "\n",
    "# Optional: Display class examples to see LBP patterns across classes\n",
    "def display_class_lbp_features(image_dir, label_dir, lbp_params=None, samples_per_class=2):\n",
    "    \"\"\"\n",
    "    Display LBP features for samples from each class\n",
    "    \"\"\"\n",
    "    # Group images by class\n",
    "    class_images = {0: [], 1: [], 2: []}\n",
    "    \n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpeg')]\n",
    "    for img_file in image_files:\n",
    "        label_file = img_file.replace('.jpeg', '.txt')\n",
    "        with open(os.path.join(label_dir, label_file), 'r') as f:\n",
    "            label = int(f.read().strip())\n",
    "        class_images[label].append(os.path.join(image_dir, img_file))\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(len(class_images), samples_per_class*2, \n",
    "                            figsize=(samples_per_class*4, len(class_images)*3))\n",
    "    \n",
    "    class_names = {0: \"No Mask\", 1: \"Mask\", 2: \"Improper Mask\"}\n",
    "    \n",
    "    # Display samples from each class\n",
    "    for class_idx, (label, images) in enumerate(class_images.items()):\n",
    "        if len(images) < samples_per_class:\n",
    "            sample_paths = images\n",
    "        else:\n",
    "            sample_paths = random.sample(images, samples_per_class)\n",
    "        \n",
    "        for sample_idx, img_path in enumerate(sample_paths):\n",
    "            original, lbp_img = visualize_lbp_features(img_path, lbp_params)\n",
    "            \n",
    "            # Display original\n",
    "            axes[class_idx, sample_idx*2].imshow(original, cmap='gray')\n",
    "            if sample_idx == 0:\n",
    "                axes[class_idx, sample_idx*2].set_ylabel(class_names[label])\n",
    "            axes[class_idx, sample_idx*2].axis('off')\n",
    "            \n",
    "            # Display LBP\n",
    "            axes[class_idx, sample_idx*2+1].imshow(lbp_img, cmap='jet')\n",
    "            axes[class_idx, sample_idx*2+1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nDisplaying LBP features by class...\")\n",
    "display_class_lbp_features(str(trainOutputPath), str(trainOutputLabelPath), \n",
    "                         lbp_params=lbp_params, samples_per_class=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv_env)",
   "language": "python",
   "name": "cv_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
