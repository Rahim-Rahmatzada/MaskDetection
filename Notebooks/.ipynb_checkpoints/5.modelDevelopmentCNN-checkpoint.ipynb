{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model optimised with Optuna and Transfer learning\n",
    "- Setting up PyTorch model architecture with ResNet18/MobileNetV2 backbone\n",
    "- Optimizing hyperparameters using Optuna 20 trials\n",
    "- Training final model with most optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectRoot = Path().resolve().parent\n",
    "outputRoot = projectRoot / \"ModifiedDataset\"\n",
    "\n",
    "trainImagePath = outputRoot / \"train\" / \"images\"\n",
    "trainLabelPath = outputRoot / \"train\" / \"labels\"\n",
    "testImagePath = outputRoot / \"test\" / \"images\"\n",
    "testLabelPath = outputRoot / \"test\" / \"labels\"\n",
    "augImagePath = outputRoot / \"AugmentedData\" / \"images\"\n",
    "augLabelPath = outputRoot / \"AugmentedData\" / \"labels\"\n",
    "\n",
    "modelsDir = outputRoot / \"models\"\n",
    "modelsDir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(outputRoot / \"kfold_splits.json\", \"r\") as f:\n",
    "    kfold_splits = json.load(f)\n",
    "\n",
    "def load_dataset(image_dir, label_dir):\n",
    "    image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpeg', '.jpg', '.png'))])\n",
    "    paths, labels = [], []\n",
    "    for fname in image_files:\n",
    "        paths.append(os.path.join(image_dir, fname))\n",
    "        with open(os.path.join(label_dir, fname.replace('.jpeg', '.txt'))) as f:\n",
    "            labels.append(int(f.read().strip()))\n",
    "    return paths, np.array(labels)\n",
    "\n",
    "train_image_paths, train_labels = load_dataset(trainImagePath, trainLabelPath)\n",
    "test_image_paths, test_labels = load_dataset(testImagePath, testLabelPath)\n",
    "aug_image_paths, aug_labels = load_dataset(augImagePath, augLabelPath)\n",
    "\n",
    "all_train_image_paths = train_image_paths + aug_image_paths\n",
    "all_train_labels = np.concatenate([train_labels, aug_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(augment=False):\n",
    "    return transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                            [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def create_dataset(image_paths, labels, transform):\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, image_paths, labels, transform):\n",
    "            self.image_paths = image_paths\n",
    "            self.labels = labels\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.image_paths)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img = cv2.imread(self.image_paths[idx])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = self.transform(img)\n",
    "            return img, self.labels[idx]\n",
    "    return CustomDataset(image_paths, labels, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(backbone='resnet18', pretrained=True, num_classes=3):\n",
    "    if backbone == 'resnet18':\n",
    "        base = models.resnet18(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "        features = base.fc.in_features\n",
    "        base = nn.Sequential(*list(base.children())[:-1])\n",
    "    elif backbone == 'mobilenet_v2':\n",
    "        base = models.mobilenet_v2(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "        features = base.classifier[1].in_features\n",
    "        base = nn.Sequential(base.features, nn.AdaptiveAvgPool2d(1))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported backbone\")\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        base,\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model, freeze_ratio=0.7):\n",
    "    all_params = list(model[0].parameters())\n",
    "    cut = int(len(all_params) * freeze_ratio)\n",
    "    for i, param in enumerate(all_params):\n",
    "        param.requires_grad = i >= cut\n",
    "    return model\n",
    "\n",
    "def calculate_weights(labels):\n",
    "    count = np.bincount(labels)\n",
    "    total = len(labels)\n",
    "    return torch.tensor(total / (len(count) * count), dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, scheduler=None):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler: scheduler.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n",
    "\n",
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    loss, preds, targets = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss += criterion(out, y).item() * x.size(0)\n",
    "            preds.extend(out.argmax(1).cpu().numpy())\n",
    "            targets.extend(y.cpu().numpy())\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(targets, preds, average='weighted')\n",
    "    return loss / len(loader.dataset), acc, prec, rec, f1, preds, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func to perform kfold cross validation\n",
    "def kfold_cross_validation(model_fn, train_image_paths, train_labels, \n",
    "                          kfold_splits, batch_size, num_epochs, \n",
    "                          learning_rate, weight_decay, class_weights=None,\n",
    "                          scheduler_type='step', early_stopping_patience=5,\n",
    "                          freeze_ratio=0.7):\n",
    "    \n",
    "    all_metrics = {}\n",
    "    fold_accuracies = []\n",
    "    all_val_preds = []\n",
    "    all_val_targets = []\n",
    "    \n",
    "    for fold_idx in kfold_splits:\n",
    "        print(f\"\\n#### Starting Fold {fold_idx} ####\")\n",
    "        \n",
    "        # get train/val split for this fold\n",
    "        train_indices = kfold_splits[fold_idx]['train']\n",
    "        val_indices = kfold_splits[fold_idx]['val']\n",
    "        \n",
    "        # get train/val data\n",
    "        fold_train_paths = [train_image_paths[i] for i in train_indices]\n",
    "        fold_train_labels = train_labels[train_indices]\n",
    "        fold_val_paths = [train_image_paths[i] for i in val_indices]\n",
    "        fold_val_labels = train_labels[val_indices]\n",
    "        \n",
    "        print(f\"Training on {len(fold_train_paths)} samples, validating on {len(fold_val_paths)} samples\")\n",
    "        print(f\"Training class distribution: {np.bincount(fold_train_labels)}\")\n",
    "        print(f\"Validation class distribution: {np.bincount(fold_val_labels)}\")\n",
    "        \n",
    "        # create datasets\n",
    "        train_transform = get_transforms(augment=False)\n",
    "        val_transform = get_transforms(augment=False)\n",
    "    \n",
    "        \n",
    "        train_dataset = FaceMaskDataset(fold_train_paths, fold_train_labels, transform=train_transform)\n",
    "        val_dataset = FaceMaskDataset(fold_val_paths, fold_val_labels, transform=val_transform)\n",
    "        \n",
    "        # create data loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                                num_workers=4, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, \n",
    "                              num_workers=4, pin_memory=True)\n",
    "        \n",
    "        # create model\n",
    "        model = model_fn()\n",
    "        model = freeze_layers(model, freeze_ratio=freeze_ratio)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # create loss function\n",
    "        if class_weights is not None:\n",
    "            criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        else:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # create optimizer\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "        # create learning rate scheduler\n",
    "        scheduler = None\n",
    "        if scheduler_type == 'step':\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "        elif scheduler_type == 'cosine':\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "        elif scheduler_type == 'onecycle':\n",
    "            steps_per_epoch = len(train_loader)\n",
    "            scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer, \n",
    "                max_lr=learning_rate,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=num_epochs\n",
    "            )\n",
    "        elif scheduler_type == 'reduce_on_plateau':\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "        \n",
    "        # training loop\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_weights = None\n",
    "        early_stopping_counter = 0\n",
    "        fold_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # training\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, \n",
    "                                             scheduler if scheduler_type == 'onecycle' else None)\n",
    "            \n",
    "            # validate\n",
    "            val_loss, val_acc, val_precision, val_recall, val_f1, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "            \n",
    "            # update the scheduler\n",
    "            if scheduler is not None:\n",
    "                if scheduler_type == 'reduce_on_plateau':\n",
    "                    scheduler.step(val_loss)\n",
    "                elif scheduler_type != 'onecycle':  # OneCycleLR is already updated in train_epoch\n",
    "                    scheduler.step()\n",
    "            \n",
    "            # track metrics\n",
    "            fold_history['train_loss'].append(train_loss)\n",
    "            fold_history['train_acc'].append(train_acc)\n",
    "            fold_history['val_loss'].append(val_loss)\n",
    "            fold_history['val_acc'].append(val_acc)\n",
    "            \n",
    "            # print stats\n",
    "            epoch_time = time.time() - start_time\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | \"\n",
    "                  f\"Val F1: {val_f1:.4f} | Time: {epoch_time:.2f}s\")\n",
    "            \n",
    "            # check if this is best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "                early_stopping_counter = 0\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "            \n",
    "            #early stopping\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        #load best model weights\n",
    "        model.load_state_dict(best_model_weights)\n",
    "        \n",
    "        # final evaluation on validation set\n",
    "        val_loss, val_acc, val_precision, val_recall, val_f1, val_preds, val_targets = evaluate(\n",
    "            model, val_loader, criterion, device)\n",
    "        \n",
    "        # store predictions for combined evaluation\n",
    "        all_val_preds.extend(val_preds)\n",
    "        all_val_targets.extend(val_targets)\n",
    "        \n",
    "        # print final metrics\n",
    "        print(f\"\\nFold {fold_idx} | Val Accuracy: {val_acc:.4f} | Precision: {val_precision:.4f} | \"\n",
    "              f\"Recall: {val_recall:.4f} | F1: {val_f1:.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(val_targets, val_preds, target_names=['No Mask', 'Mask', 'Improper Mask']))\n",
    "        \n",
    "        # store metrics\n",
    "        all_metrics[fold_idx] = {\n",
    "            'val_accuracy': val_acc,\n",
    "            'val_precision': val_precision,\n",
    "            'val_recall': val_recall,\n",
    "            'val_f1': val_f1,\n",
    "            'history': fold_history\n",
    "        }\n",
    "        \n",
    "        fold_accuracies.append(val_acc)\n",
    "        \n",
    "        # free up GPU memory to avoid crashing\n",
    "        del model, train_loader, val_loader, train_dataset, val_dataset\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # calculate avg metrics\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    print(f\"\\nAverage validation accuracy across all folds: {avg_accuracy:.4f}\")\n",
    "    \n",
    "    # Ppint overall metrics\n",
    "    overall_report = classification_report(all_val_targets, all_val_preds, \n",
    "                                         target_names=['No Mask', 'Mask', 'Improper Mask'])\n",
    "    print(\"\\nOverall Classification Report:\")\n",
    "    print(overall_report)\n",
    "    \n",
    "    all_metrics['average'] = {\n",
    "        'val_accuracy': avg_accuracy, \n",
    "        'overall_report': overall_report\n",
    "    }\n",
    "    return all_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(params, all_train_image_paths, all_train_labels, test_image_paths, test_labels):\n",
    "    indices = list(range(len(all_train_image_paths)))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(0.1 * len(indices))\n",
    "    train_idx, val_idx = indices[split:], indices[:split]\n",
    "\n",
    "    X_train = [all_train_image_paths[i] for i in train_idx]\n",
    "    y_train = all_train_labels[train_idx]\n",
    "    X_val = [all_train_image_paths[i] for i in val_idx]\n",
    "    y_val = all_train_labels[val_idx]\n",
    "\n",
    "    train_ds = create_dataset(X_train, y_train, get_transforms(augment=True))\n",
    "    val_ds = create_dataset(X_val, y_val, get_transforms(augment=False))\n",
    "    test_ds = create_dataset(test_image_paths, test_labels, get_transforms(augment=False))\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=params['batch_size'], shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_ds, batch_size=params['batch_size'], shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_ds, batch_size=params['batch_size'], shuffle=False, num_workers=4)\n",
    "\n",
    "    model = MaskDetectionCNN(backbone=params['backbone'], pretrained=True)\n",
    "    model = freeze_layers(model, params['freeze_ratio']).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=calculate_class_weights(all_train_labels)\n",
    "                                    if params['use_class_weights'] else None)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "\n",
    "    if params['scheduler_type'] == 'onecycle':\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=params['learning_rate'],\n",
    "                                                  steps_per_epoch=len(train_loader), epochs=30)\n",
    "    elif params['scheduler_type'] == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    elif params['scheduler_type'] == 'cosine':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    best_weights = None\n",
    "    best_loss = float('inf')\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(30):\n",
    "        t0 = time.time()\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer,\n",
    "                                                scheduler if params['scheduler_type'] == 'onecycle' else None)\n",
    "        val_loss, val_acc, *_ = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "        if params['scheduler_type'] == 'step' and scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {time.time()-t0:.2f}s\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= 5:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_weights)\n",
    "    torch.save(model.state_dict(), f\"{modelsDir}/cnn_final_model.pt\")\n",
    "\n",
    "    _, acc, prec, rec, f1, preds, targets = evaluate_model(model, test_loader, criterion)\n",
    "    cm = confusion_matrix(targets, preds)\n",
    "\n",
    "    return model, {\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': classification_report(targets, preds, target_names=['No Mask', 'Mask', 'Improper Mask'])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(train_image_paths, train_labels, kfold_splits, n_trials=20):\n",
    "    def objective(trial):\n",
    "        backbone = trial.suggest_categorical('backbone', ['resnet18', 'mobilenet_v2'])\n",
    "        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
    "        weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "        use_class_weights = trial.suggest_categorical('use_class_weights', [True, False])\n",
    "        scheduler_type = trial.suggest_categorical('scheduler_type', ['step', 'cosine', 'onecycle', 'reduce_on_plateau'])\n",
    "        freeze_ratio = trial.suggest_float('freeze_ratio', 0.5, 0.9)\n",
    "\n",
    "        class_weights = calculate_class_weights(train_labels) if use_class_weights else None\n",
    "\n",
    "        def create_model():\n",
    "            return MaskDetectionCNN(backbone=backbone, pretrained=True)\n",
    "\n",
    "        metrics = kfold_cross_validation(\n",
    "            model_fn=create_model,\n",
    "            train_image_paths=train_image_paths,\n",
    "            train_labels=train_labels,\n",
    "            kfold_splits=kfold_splits,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=5,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            class_weights=class_weights,\n",
    "            scheduler_type=scheduler_type,\n",
    "            early_stopping_patience=3,\n",
    "            freeze_ratio=freeze_ratio\n",
    "        )\n",
    "        return metrics['average']['val_accuracy']\n",
    "\n",
    "    pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "    sampler = TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=pruner, sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    print(f\"  Value: {study.best_trial.value}\")\n",
    "    for key, val in study.best_trial.params.items():\n",
    "        print(f\"  {key}: {val}\")\n",
    "    return study.best_trial.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:39:07,958] A new study created in memory with name: no-name-c5af7dce-dedc-4244-b95f-0f07cbea66b3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.1014 | Train Acc: 0.3304 | Val Loss: 0.9846 | Val Acc: 0.6247 | Val F1: 0.5924 | Time: 4.29s\n",
      "Epoch 2/5 | Train Loss: 0.8438 | Train Acc: 0.6540 | Val Loss: 0.6844 | Val Acc: 0.7922 | Val F1: 0.7798 | Time: 4.22s\n",
      "Epoch 3/5 | Train Loss: 0.6199 | Train Acc: 0.7710 | Val Loss: 0.5347 | Val Acc: 0.8312 | Val F1: 0.8249 | Time: 4.16s\n",
      "Epoch 4/5 | Train Loss: 0.5267 | Train Acc: 0.8086 | Val Loss: 0.5033 | Val Acc: 0.8545 | Val F1: 0.8492 | Time: 4.17s\n",
      "Epoch 5/5 | Train Loss: 0.4763 | Train Acc: 0.8330 | Val Loss: 0.4850 | Val Acc: 0.8519 | Val F1: 0.8468 | Time: 4.26s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.8519 | Precision: 0.8567 | Recall: 0.8519 | F1: 0.8468\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.77      0.81      0.79       226\n",
      "         Mask       0.88      0.97      0.92       388\n",
      "Improper Mask       0.92      0.62      0.74       156\n",
      "\n",
      "     accuracy                           0.85       770\n",
      "    macro avg       0.86      0.80      0.82       770\n",
      " weighted avg       0.86      0.85      0.85       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0990 | Train Acc: 0.3681 | Val Loss: 0.9620 | Val Acc: 0.6727 | Val F1: 0.6638 | Time: 5.17s\n",
      "Epoch 2/5 | Train Loss: 0.8259 | Train Acc: 0.6917 | Val Loss: 0.6724 | Val Acc: 0.7883 | Val F1: 0.7795 | Time: 4.30s\n",
      "Epoch 3/5 | Train Loss: 0.5934 | Train Acc: 0.7976 | Val Loss: 0.5407 | Val Acc: 0.8247 | Val F1: 0.8201 | Time: 4.11s\n",
      "Epoch 4/5 | Train Loss: 0.5092 | Train Acc: 0.8164 | Val Loss: 0.5069 | Val Acc: 0.8390 | Val F1: 0.8336 | Time: 4.21s\n",
      "Epoch 5/5 | Train Loss: 0.4696 | Train Acc: 0.8376 | Val Loss: 0.5063 | Val Acc: 0.8519 | Val F1: 0.8464 | Time: 4.09s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.8519 | Precision: 0.8582 | Recall: 0.8519 | F1: 0.8464\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.88      0.67      0.76       226\n",
      "         Mask       0.83      0.98      0.90       388\n",
      "Improper Mask       0.90      0.78      0.84       156\n",
      "\n",
      "     accuracy                           0.85       770\n",
      "    macro avg       0.87      0.81      0.83       770\n",
      " weighted avg       0.86      0.85      0.85       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0926 | Train Acc: 0.3379 | Val Loss: 0.9517 | Val Acc: 0.6961 | Val F1: 0.6865 | Time: 4.18s\n",
      "Epoch 2/5 | Train Loss: 0.8148 | Train Acc: 0.6878 | Val Loss: 0.6217 | Val Acc: 0.8078 | Val F1: 0.7965 | Time: 4.18s\n",
      "Epoch 3/5 | Train Loss: 0.6018 | Train Acc: 0.7956 | Val Loss: 0.5043 | Val Acc: 0.8234 | Val F1: 0.8187 | Time: 4.32s\n",
      "Epoch 4/5 | Train Loss: 0.5036 | Train Acc: 0.8246 | Val Loss: 0.4663 | Val Acc: 0.8468 | Val F1: 0.8439 | Time: 4.93s\n",
      "Epoch 5/5 | Train Loss: 0.4700 | Train Acc: 0.8366 | Val Loss: 0.4734 | Val Acc: 0.8416 | Val F1: 0.8376 | Time: 4.16s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.8468 | Precision: 0.8477 | Recall: 0.8468 | F1: 0.8439\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.78      0.77      0.78       226\n",
      "         Mask       0.87      0.95      0.91       388\n",
      "Improper Mask       0.89      0.70      0.78       156\n",
      "\n",
      "     accuracy                           0.85       770\n",
      "    macro avg       0.85      0.81      0.82       770\n",
      " weighted avg       0.85      0.85      0.84       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0954 | Train Acc: 0.4180 | Val Loss: 0.9644 | Val Acc: 0.6619 | Val F1: 0.6547 | Time: 4.16s\n",
      "Epoch 2/5 | Train Loss: 0.8357 | Train Acc: 0.6801 | Val Loss: 0.6282 | Val Acc: 0.7984 | Val F1: 0.7884 | Time: 4.18s\n",
      "Epoch 3/5 | Train Loss: 0.6229 | Train Acc: 0.7769 | Val Loss: 0.5102 | Val Acc: 0.8362 | Val F1: 0.8306 | Time: 4.17s\n",
      "Epoch 4/5 | Train Loss: 0.5184 | Train Acc: 0.8126 | Val Loss: 0.4658 | Val Acc: 0.8362 | Val F1: 0.8305 | Time: 4.13s\n",
      "Epoch 5/5 | Train Loss: 0.4790 | Train Acc: 0.8376 | Val Loss: 0.4474 | Val Acc: 0.8635 | Val F1: 0.8592 | Time: 4.15s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.8635 | Precision: 0.8640 | Recall: 0.8635 | F1: 0.8592\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.88      0.71      0.78       225\n",
      "         Mask       0.87      0.98      0.92       388\n",
      "Improper Mask       0.84      0.81      0.82       156\n",
      "\n",
      "     accuracy                           0.86       769\n",
      "    macro avg       0.86      0.83      0.84       769\n",
      " weighted avg       0.86      0.86      0.86       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0968 | Train Acc: 0.3738 | Val Loss: 0.9679 | Val Acc: 0.6554 | Val F1: 0.6462 | Time: 5.02s\n",
      "Epoch 2/5 | Train Loss: 0.8290 | Train Acc: 0.6846 | Val Loss: 0.6715 | Val Acc: 0.7893 | Val F1: 0.7821 | Time: 4.16s\n",
      "Epoch 3/5 | Train Loss: 0.6197 | Train Acc: 0.7830 | Val Loss: 0.5370 | Val Acc: 0.8257 | Val F1: 0.8208 | Time: 4.26s\n",
      "Epoch 4/5 | Train Loss: 0.5177 | Train Acc: 0.8314 | Val Loss: 0.4883 | Val Acc: 0.8388 | Val F1: 0.8370 | Time: 4.16s\n",
      "Epoch 5/5 | Train Loss: 0.4710 | Train Acc: 0.8295 | Val Loss: 0.4892 | Val Acc: 0.8414 | Val F1: 0.8387 | Time: 4.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:41:00,442] Trial 0 finished with value: 0.850572002769662 and parameters: {'backbone': 'mobilenet_v2', 'batch_size': 16, 'learning_rate': 2.0511104188433963e-05, 'weight_decay': 1.3066739238053272e-05, 'use_class_weights': True, 'scheduler_type': 'onecycle', 'freeze_ratio': 0.5849356442713105}. Best is trial 0 with value: 0.850572002769662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.8388 | Precision: 0.8376 | Recall: 0.8388 | F1: 0.8370\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.77      0.76      0.77       225\n",
      "         Mask       0.87      0.93      0.90       388\n",
      "Improper Mask       0.85      0.74      0.79       156\n",
      "\n",
      "     accuracy                           0.84       769\n",
      "    macro avg       0.83      0.81      0.82       769\n",
      " weighted avg       0.84      0.84      0.84       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.8506\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.81      0.75      0.78      1128\n",
      "         Mask       0.86      0.96      0.91      1940\n",
      "Improper Mask       0.88      0.73      0.80       780\n",
      "\n",
      "     accuracy                           0.85      3848\n",
      "    macro avg       0.85      0.81      0.83      3848\n",
      " weighted avg       0.85      0.85      0.85      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0405 | Train Acc: 0.4636 | Val Loss: 0.8430 | Val Acc: 0.6481 | Val F1: 0.5914 | Time: 3.82s\n",
      "Epoch 2/5 | Train Loss: 0.6922 | Train Acc: 0.7199 | Val Loss: 0.5210 | Val Acc: 0.7844 | Val F1: 0.7712 | Time: 3.69s\n",
      "Epoch 3/5 | Train Loss: 0.5016 | Train Acc: 0.7995 | Val Loss: 0.4295 | Val Acc: 0.8312 | Val F1: 0.8219 | Time: 3.75s\n",
      "Epoch 4/5 | Train Loss: 0.3912 | Train Acc: 0.8431 | Val Loss: 0.3833 | Val Acc: 0.8494 | Val F1: 0.8455 | Time: 4.54s\n",
      "Epoch 5/5 | Train Loss: 0.3613 | Train Acc: 0.8632 | Val Loss: 0.3824 | Val Acc: 0.8584 | Val F1: 0.8558 | Time: 3.74s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.8584 | Precision: 0.8614 | Recall: 0.8584 | F1: 0.8558\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.77      0.85      0.81       226\n",
      "         Mask       0.90      0.94      0.92       388\n",
      "Improper Mask       0.89      0.66      0.76       156\n",
      "\n",
      "     accuracy                           0.86       770\n",
      "    macro avg       0.85      0.82      0.83       770\n",
      " weighted avg       0.86      0.86      0.86       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0414 | Train Acc: 0.4607 | Val Loss: 0.8590 | Val Acc: 0.6779 | Val F1: 0.6351 | Time: 3.81s\n",
      "Epoch 2/5 | Train Loss: 0.6879 | Train Acc: 0.7320 | Val Loss: 0.5543 | Val Acc: 0.7831 | Val F1: 0.7691 | Time: 3.73s\n",
      "Epoch 3/5 | Train Loss: 0.4886 | Train Acc: 0.8090 | Val Loss: 0.4363 | Val Acc: 0.8312 | Val F1: 0.8246 | Time: 3.71s\n",
      "Epoch 4/5 | Train Loss: 0.3837 | Train Acc: 0.8545 | Val Loss: 0.4028 | Val Acc: 0.8429 | Val F1: 0.8364 | Time: 3.75s\n",
      "Epoch 5/5 | Train Loss: 0.3548 | Train Acc: 0.8684 | Val Loss: 0.3945 | Val Acc: 0.8494 | Val F1: 0.8435 | Time: 3.74s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.8494 | Precision: 0.8539 | Recall: 0.8494 | F1: 0.8435\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.87      0.67      0.76       226\n",
      "         Mask       0.83      0.99      0.90       388\n",
      "Improper Mask       0.89      0.76      0.82       156\n",
      "\n",
      "     accuracy                           0.85       770\n",
      "    macro avg       0.86      0.81      0.83       770\n",
      " weighted avg       0.85      0.85      0.84       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0722 | Train Acc: 0.4035 | Val Loss: 0.8542 | Val Acc: 0.6545 | Val F1: 0.6050 | Time: 3.76s\n",
      "Epoch 2/5 | Train Loss: 0.7003 | Train Acc: 0.7326 | Val Loss: 0.5269 | Val Acc: 0.8091 | Val F1: 0.7981 | Time: 4.57s\n",
      "Epoch 3/5 | Train Loss: 0.4832 | Train Acc: 0.8142 | Val Loss: 0.4360 | Val Acc: 0.8286 | Val F1: 0.8213 | Time: 3.73s\n",
      "Epoch 4/5 | Train Loss: 0.3883 | Train Acc: 0.8538 | Val Loss: 0.3938 | Val Acc: 0.8416 | Val F1: 0.8374 | Time: 3.73s\n",
      "Epoch 5/5 | Train Loss: 0.3484 | Train Acc: 0.8674 | Val Loss: 0.3880 | Val Acc: 0.8403 | Val F1: 0.8350 | Time: 3.75s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.8403 | Precision: 0.8384 | Recall: 0.8403 | F1: 0.8350\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.82      0.69      0.75       226\n",
      "         Mask       0.85      0.97      0.91       388\n",
      "Improper Mask       0.83      0.72      0.77       156\n",
      "\n",
      "     accuracy                           0.84       770\n",
      "    macro avg       0.83      0.80      0.81       770\n",
      " weighted avg       0.84      0.84      0.84       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0472 | Train Acc: 0.4424 | Val Loss: 0.8231 | Val Acc: 0.6762 | Val F1: 0.6267 | Time: 3.78s\n",
      "Epoch 2/5 | Train Loss: 0.7034 | Train Acc: 0.7301 | Val Loss: 0.5046 | Val Acc: 0.8088 | Val F1: 0.7987 | Time: 3.69s\n",
      "Epoch 3/5 | Train Loss: 0.4828 | Train Acc: 0.8136 | Val Loss: 0.4139 | Val Acc: 0.8388 | Val F1: 0.8321 | Time: 4.11s\n",
      "Epoch 4/5 | Train Loss: 0.3799 | Train Acc: 0.8545 | Val Loss: 0.3725 | Val Acc: 0.8505 | Val F1: 0.8465 | Time: 4.31s\n",
      "Epoch 5/5 | Train Loss: 0.3650 | Train Acc: 0.8590 | Val Loss: 0.3694 | Val Acc: 0.8518 | Val F1: 0.8481 | Time: 5.24s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.8518 | Precision: 0.8520 | Recall: 0.8518 | F1: 0.8481\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.78      0.77      0.77       225\n",
      "         Mask       0.88      0.97      0.92       388\n",
      "Improper Mask       0.89      0.69      0.78       156\n",
      "\n",
      "     accuracy                           0.85       769\n",
      "    macro avg       0.85      0.81      0.82       769\n",
      " weighted avg       0.85      0.85      0.85       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.9937 | Train Acc: 0.5297 | Val Loss: 0.8182 | Val Acc: 0.6749 | Val F1: 0.6173 | Time: 4.39s\n",
      "Epoch 2/5 | Train Loss: 0.6842 | Train Acc: 0.7324 | Val Loss: 0.5163 | Val Acc: 0.8010 | Val F1: 0.7905 | Time: 4.27s\n",
      "Epoch 3/5 | Train Loss: 0.4728 | Train Acc: 0.8165 | Val Loss: 0.4393 | Val Acc: 0.8244 | Val F1: 0.8214 | Time: 4.35s\n",
      "Epoch 4/5 | Train Loss: 0.3806 | Train Acc: 0.8538 | Val Loss: 0.3975 | Val Acc: 0.8401 | Val F1: 0.8366 | Time: 4.21s\n",
      "Epoch 5/5 | Train Loss: 0.3385 | Train Acc: 0.8727 | Val Loss: 0.3812 | Val Acc: 0.8531 | Val F1: 0.8504 | Time: 4.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:42:45,995] Trial 1 finished with value: 0.8505726782969957 and parameters: {'backbone': 'mobilenet_v2', 'batch_size': 32, 'learning_rate': 3.8234752246751835e-05, 'weight_decay': 0.00016738085788752134, 'use_class_weights': False, 'scheduler_type': 'onecycle', 'freeze_ratio': 0.7056937753654446}. Best is trial 1 with value: 0.8505726782969957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.8531 | Precision: 0.8518 | Recall: 0.8531 | F1: 0.8504\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.80      0.76      0.78       225\n",
      "         Mask       0.87      0.95      0.91       388\n",
      "Improper Mask       0.86      0.74      0.80       156\n",
      "\n",
      "     accuracy                           0.85       769\n",
      "    macro avg       0.85      0.82      0.83       769\n",
      " weighted avg       0.85      0.85      0.85       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.8506\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.81      0.75      0.78      1128\n",
      "         Mask       0.87      0.96      0.91      1940\n",
      "Improper Mask       0.87      0.71      0.79       780\n",
      "\n",
      "     accuracy                           0.85      3848\n",
      "    macro avg       0.85      0.81      0.82      3848\n",
      " weighted avg       0.85      0.85      0.85      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5840 | Train Acc: 0.7693 | Val Loss: 0.3105 | Val Acc: 0.8818 | Val F1: 0.8841 | Time: 4.50s\n",
      "Epoch 2/5 | Train Loss: 0.3015 | Train Acc: 0.8977 | Val Loss: 0.2687 | Val Acc: 0.9169 | Val F1: 0.9166 | Time: 5.39s\n",
      "Epoch 3/5 | Train Loss: 0.1519 | Train Acc: 0.9464 | Val Loss: 0.2497 | Val Acc: 0.9364 | Val F1: 0.9364 | Time: 4.57s\n",
      "Epoch 4/5 | Train Loss: 0.0690 | Train Acc: 0.9766 | Val Loss: 0.3129 | Val Acc: 0.9325 | Val F1: 0.9326 | Time: 4.44s\n",
      "Epoch 5/5 | Train Loss: 0.0384 | Train Acc: 0.9880 | Val Loss: 0.2227 | Val Acc: 0.9416 | Val F1: 0.9417 | Time: 4.74s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9416 | Precision: 0.9430 | Recall: 0.9416 | F1: 0.9417\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.89      0.95      0.92       226\n",
      "         Mask       0.96      0.96      0.96       388\n",
      "Improper Mask       0.97      0.89      0.93       156\n",
      "\n",
      "     accuracy                           0.94       770\n",
      "    macro avg       0.94      0.93      0.94       770\n",
      " weighted avg       0.94      0.94      0.94       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5903 | Train Acc: 0.7723 | Val Loss: 0.3770 | Val Acc: 0.8727 | Val F1: 0.8739 | Time: 4.55s\n",
      "Epoch 2/5 | Train Loss: 0.2953 | Train Acc: 0.9009 | Val Loss: 0.4165 | Val Acc: 0.8714 | Val F1: 0.8711 | Time: 4.61s\n",
      "Epoch 3/5 | Train Loss: 0.1548 | Train Acc: 0.9493 | Val Loss: 0.2623 | Val Acc: 0.9234 | Val F1: 0.9229 | Time: 4.36s\n",
      "Epoch 4/5 | Train Loss: 0.0775 | Train Acc: 0.9750 | Val Loss: 0.3108 | Val Acc: 0.9065 | Val F1: 0.9069 | Time: 5.29s\n",
      "Epoch 5/5 | Train Loss: 0.0297 | Train Acc: 0.9909 | Val Loss: 0.2636 | Val Acc: 0.9286 | Val F1: 0.9289 | Time: 4.43s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9234 | Precision: 0.9230 | Recall: 0.9234 | F1: 0.9229\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.86      0.88       226\n",
      "         Mask       0.93      0.95      0.94       388\n",
      "Improper Mask       0.93      0.94      0.94       156\n",
      "\n",
      "     accuracy                           0.92       770\n",
      "    macro avg       0.92      0.92      0.92       770\n",
      " weighted avg       0.92      0.92      0.92       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5756 | Train Acc: 0.7820 | Val Loss: 0.4170 | Val Acc: 0.8636 | Val F1: 0.8610 | Time: 4.36s\n",
      "Epoch 2/5 | Train Loss: 0.2821 | Train Acc: 0.8928 | Val Loss: 0.3316 | Val Acc: 0.8792 | Val F1: 0.8811 | Time: 4.50s\n",
      "Epoch 3/5 | Train Loss: 0.1544 | Train Acc: 0.9480 | Val Loss: 0.2514 | Val Acc: 0.9312 | Val F1: 0.9311 | Time: 4.45s\n",
      "Epoch 4/5 | Train Loss: 0.0740 | Train Acc: 0.9737 | Val Loss: 0.2581 | Val Acc: 0.9351 | Val F1: 0.9351 | Time: 4.47s\n",
      "Epoch 5/5 | Train Loss: 0.0250 | Train Acc: 0.9912 | Val Loss: 0.2454 | Val Acc: 0.9390 | Val F1: 0.9390 | Time: 4.41s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9390 | Precision: 0.9395 | Recall: 0.9390 | F1: 0.9390\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.92      0.92       226\n",
      "         Mask       0.94      0.96      0.95       388\n",
      "Improper Mask       0.97      0.92      0.94       156\n",
      "\n",
      "     accuracy                           0.94       770\n",
      "    macro avg       0.94      0.93      0.94       770\n",
      " weighted avg       0.94      0.94      0.94       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5941 | Train Acc: 0.7743 | Val Loss: 0.4276 | Val Acc: 0.8674 | Val F1: 0.8646 | Time: 4.48s\n",
      "Epoch 2/5 | Train Loss: 0.2746 | Train Acc: 0.9042 | Val Loss: 0.4144 | Val Acc: 0.8088 | Val F1: 0.8062 | Time: 4.91s\n",
      "Epoch 3/5 | Train Loss: 0.1584 | Train Acc: 0.9419 | Val Loss: 0.2737 | Val Acc: 0.9012 | Val F1: 0.9026 | Time: 5.53s\n",
      "Epoch 4/5 | Train Loss: 0.0694 | Train Acc: 0.9737 | Val Loss: 0.2073 | Val Acc: 0.9363 | Val F1: 0.9357 | Time: 5.23s\n",
      "Epoch 5/5 | Train Loss: 0.0356 | Train Acc: 0.9883 | Val Loss: 0.2297 | Val Acc: 0.9415 | Val F1: 0.9412 | Time: 5.34s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9363 | Precision: 0.9363 | Recall: 0.9363 | F1: 0.9357\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.94      0.87      0.90       225\n",
      "         Mask       0.94      0.97      0.96       388\n",
      "Improper Mask       0.92      0.94      0.93       156\n",
      "\n",
      "     accuracy                           0.94       769\n",
      "    macro avg       0.93      0.93      0.93       769\n",
      " weighted avg       0.94      0.94      0.94       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5860 | Train Acc: 0.7749 | Val Loss: 0.4549 | Val Acc: 0.8283 | Val F1: 0.8291 | Time: 6.07s\n",
      "Epoch 2/5 | Train Loss: 0.3180 | Train Acc: 0.8909 | Val Loss: 0.3004 | Val Acc: 0.8882 | Val F1: 0.8870 | Time: 5.17s\n",
      "Epoch 3/5 | Train Loss: 0.1694 | Train Acc: 0.9402 | Val Loss: 0.2596 | Val Acc: 0.9142 | Val F1: 0.9148 | Time: 5.19s\n",
      "Epoch 4/5 | Train Loss: 0.0623 | Train Acc: 0.9773 | Val Loss: 0.2198 | Val Acc: 0.9220 | Val F1: 0.9225 | Time: 5.09s\n",
      "Epoch 5/5 | Train Loss: 0.0287 | Train Acc: 0.9906 | Val Loss: 0.2015 | Val Acc: 0.9350 | Val F1: 0.9351 | Time: 4.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:44:53,724] Trial 2 finished with value: 0.9350314964619256 and parameters: {'backbone': 'resnet18', 'batch_size': 16, 'learning_rate': 0.000790261954970823, 'weight_decay': 0.0008536189862866829, 'use_class_weights': True, 'scheduler_type': 'cosine', 'freeze_ratio': 0.6980707640445081}. Best is trial 2 with value: 0.9350314964619256.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9350 | Precision: 0.9353 | Recall: 0.9350 | F1: 0.9351\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.91      0.90       225\n",
      "         Mask       0.95      0.95      0.95       388\n",
      "Improper Mask       0.96      0.94      0.95       156\n",
      "\n",
      "     accuracy                           0.93       769\n",
      "    macro avg       0.93      0.93      0.93       769\n",
      " weighted avg       0.94      0.93      0.94       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9350\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.90      0.90      1128\n",
      "         Mask       0.95      0.96      0.95      1940\n",
      "Improper Mask       0.95      0.93      0.94       780\n",
      "\n",
      "     accuracy                           0.94      3848\n",
      "    macro avg       0.93      0.93      0.93      3848\n",
      " weighted avg       0.94      0.94      0.93      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6818 | Train Acc: 0.7105 | Val Loss: 0.4543 | Val Acc: 0.8143 | Val F1: 0.8052 | Time: 4.65s\n",
      "Epoch 2/5 | Train Loss: 0.4277 | Train Acc: 0.8255 | Val Loss: 0.3693 | Val Acc: 0.8571 | Val F1: 0.8558 | Time: 4.73s\n",
      "Epoch 3/5 | Train Loss: 0.3294 | Train Acc: 0.8756 | Val Loss: 0.3226 | Val Acc: 0.8623 | Val F1: 0.8598 | Time: 5.38s\n",
      "Epoch 4/5 | Train Loss: 0.2697 | Train Acc: 0.9009 | Val Loss: 0.3067 | Val Acc: 0.8883 | Val F1: 0.8867 | Time: 4.72s\n",
      "Epoch 5/5 | Train Loss: 0.2310 | Train Acc: 0.9097 | Val Loss: 0.2939 | Val Acc: 0.8896 | Val F1: 0.8882 | Time: 4.82s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.8896 | Precision: 0.8903 | Recall: 0.8896 | F1: 0.8882\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.84      0.85      0.84       226\n",
      "         Mask       0.91      0.96      0.93       388\n",
      "Improper Mask       0.92      0.78      0.84       156\n",
      "\n",
      "     accuracy                           0.89       770\n",
      "    macro avg       0.89      0.86      0.87       770\n",
      " weighted avg       0.89      0.89      0.89       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6756 | Train Acc: 0.7242 | Val Loss: 0.5028 | Val Acc: 0.7935 | Val F1: 0.7809 | Time: 4.86s\n",
      "Epoch 2/5 | Train Loss: 0.4205 | Train Acc: 0.8317 | Val Loss: 0.3945 | Val Acc: 0.8429 | Val F1: 0.8385 | Time: 4.88s\n",
      "Epoch 3/5 | Train Loss: 0.3222 | Train Acc: 0.8697 | Val Loss: 0.3879 | Val Acc: 0.8468 | Val F1: 0.8434 | Time: 5.95s\n",
      "Epoch 4/5 | Train Loss: 0.2558 | Train Acc: 0.9022 | Val Loss: 0.3787 | Val Acc: 0.8545 | Val F1: 0.8525 | Time: 6.91s\n",
      "Epoch 5/5 | Train Loss: 0.2296 | Train Acc: 0.9136 | Val Loss: 0.3507 | Val Acc: 0.8558 | Val F1: 0.8537 | Time: 5.26s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.8558 | Precision: 0.8569 | Recall: 0.8558 | F1: 0.8537\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.81      0.77      0.79       226\n",
      "         Mask       0.86      0.95      0.90       388\n",
      "Improper Mask       0.92      0.76      0.83       156\n",
      "\n",
      "     accuracy                           0.86       770\n",
      "    macro avg       0.86      0.82      0.84       770\n",
      " weighted avg       0.86      0.86      0.85       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6907 | Train Acc: 0.7083 | Val Loss: 0.4790 | Val Acc: 0.8130 | Val F1: 0.8040 | Time: 5.81s\n",
      "Epoch 2/5 | Train Loss: 0.4227 | Train Acc: 0.8294 | Val Loss: 0.3874 | Val Acc: 0.8519 | Val F1: 0.8479 | Time: 4.40s\n",
      "Epoch 3/5 | Train Loss: 0.3219 | Train Acc: 0.8765 | Val Loss: 0.3715 | Val Acc: 0.8597 | Val F1: 0.8586 | Time: 4.08s\n",
      "Epoch 4/5 | Train Loss: 0.2558 | Train Acc: 0.9038 | Val Loss: 0.3382 | Val Acc: 0.8753 | Val F1: 0.8732 | Time: 3.85s\n",
      "Epoch 5/5 | Train Loss: 0.2315 | Train Acc: 0.9129 | Val Loss: 0.3398 | Val Acc: 0.8675 | Val F1: 0.8658 | Time: 4.77s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.8753 | Precision: 0.8740 | Recall: 0.8753 | F1: 0.8732\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.86      0.76      0.81       226\n",
      "         Mask       0.89      0.96      0.93       388\n",
      "Improper Mask       0.84      0.83      0.84       156\n",
      "\n",
      "     accuracy                           0.88       770\n",
      "    macro avg       0.87      0.85      0.86       770\n",
      " weighted avg       0.87      0.88      0.87       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6944 | Train Acc: 0.6967 | Val Loss: 0.4526 | Val Acc: 0.8179 | Val F1: 0.8089 | Time: 3.93s\n",
      "Epoch 2/5 | Train Loss: 0.4261 | Train Acc: 0.8236 | Val Loss: 0.3692 | Val Acc: 0.8570 | Val F1: 0.8532 | Time: 4.06s\n",
      "Epoch 3/5 | Train Loss: 0.3345 | Train Acc: 0.8701 | Val Loss: 0.3534 | Val Acc: 0.8635 | Val F1: 0.8617 | Time: 3.95s\n",
      "Epoch 4/5 | Train Loss: 0.2723 | Train Acc: 0.8951 | Val Loss: 0.3348 | Val Acc: 0.8674 | Val F1: 0.8652 | Time: 3.88s\n",
      "Epoch 5/5 | Train Loss: 0.2297 | Train Acc: 0.9139 | Val Loss: 0.3279 | Val Acc: 0.8726 | Val F1: 0.8699 | Time: 3.96s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.8726 | Precision: 0.8714 | Recall: 0.8726 | F1: 0.8699\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.85      0.76      0.80       225\n",
      "         Mask       0.88      0.97      0.92       388\n",
      "Improper Mask       0.88      0.81      0.84       156\n",
      "\n",
      "     accuracy                           0.87       769\n",
      "    macro avg       0.87      0.84      0.85       769\n",
      " weighted avg       0.87      0.87      0.87       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6866 | Train Acc: 0.7184 | Val Loss: 0.4878 | Val Acc: 0.7997 | Val F1: 0.7939 | Time: 3.91s\n",
      "Epoch 2/5 | Train Loss: 0.4400 | Train Acc: 0.8175 | Val Loss: 0.4177 | Val Acc: 0.8231 | Val F1: 0.8241 | Time: 4.08s\n",
      "Epoch 3/5 | Train Loss: 0.3231 | Train Acc: 0.8737 | Val Loss: 0.3839 | Val Acc: 0.8427 | Val F1: 0.8411 | Time: 5.01s\n",
      "Epoch 4/5 | Train Loss: 0.2805 | Train Acc: 0.8970 | Val Loss: 0.3513 | Val Acc: 0.8674 | Val F1: 0.8651 | Time: 4.03s\n",
      "Epoch 5/5 | Train Loss: 0.2431 | Train Acc: 0.9048 | Val Loss: 0.3455 | Val Acc: 0.8687 | Val F1: 0.8674 | Time: 3.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:46:55,050] Trial 3 finished with value: 0.8724003174978469 and parameters: {'backbone': 'mobilenet_v2', 'batch_size': 32, 'learning_rate': 0.00010968217207529509, 'weight_decay': 0.00012399967836846095, 'use_class_weights': False, 'scheduler_type': 'cosine', 'freeze_ratio': 0.8687496940092467}. Best is trial 2 with value: 0.9350314964619256.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.8687 | Precision: 0.8692 | Recall: 0.8687 | F1: 0.8674\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.81      0.81      0.81       225\n",
      "         Mask       0.89      0.94      0.92       388\n",
      "Improper Mask       0.90      0.76      0.83       156\n",
      "\n",
      "     accuracy                           0.87       769\n",
      "    macro avg       0.87      0.84      0.85       769\n",
      " weighted avg       0.87      0.87      0.87       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.8724\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.83      0.79      0.81      1128\n",
      "         Mask       0.89      0.96      0.92      1940\n",
      "Improper Mask       0.89      0.79      0.84       780\n",
      "\n",
      "     accuracy                           0.87      3848\n",
      "    macro avg       0.87      0.84      0.86      3848\n",
      " weighted avg       0.87      0.87      0.87      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.1011 | Train Acc: 0.4337 | Val Loss: 1.0203 | Val Acc: 0.5494 | Val F1: 0.5322 | Time: 3.83s\n",
      "Epoch 2/5 | Train Loss: 0.9183 | Train Acc: 0.6127 | Val Loss: 0.7959 | Val Acc: 0.7519 | Val F1: 0.7397 | Time: 3.91s\n",
      "Epoch 3/5 | Train Loss: 0.7443 | Train Acc: 0.7326 | Val Loss: 0.7008 | Val Acc: 0.7740 | Val F1: 0.7638 | Time: 3.98s\n",
      "Epoch 4/5 | Train Loss: 0.6629 | Train Acc: 0.7560 | Val Loss: 0.6620 | Val Acc: 0.7753 | Val F1: 0.7663 | Time: 4.05s\n",
      "Epoch 5/5 | Train Loss: 0.6438 | Train Acc: 0.7719 | Val Loss: 0.6580 | Val Acc: 0.7870 | Val F1: 0.7795 | Time: 4.04s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.7870 | Precision: 0.7802 | Recall: 0.7870 | F1: 0.7795\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.72      0.63      0.67       226\n",
      "         Mask       0.83      0.95      0.88       388\n",
      "Improper Mask       0.74      0.62      0.67       156\n",
      "\n",
      "     accuracy                           0.79       770\n",
      "    macro avg       0.76      0.73      0.74       770\n",
      " weighted avg       0.78      0.79      0.78       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0939 | Train Acc: 0.4392 | Val Loss: 1.0040 | Val Acc: 0.6091 | Val F1: 0.5899 | Time: 4.46s\n",
      "Epoch 2/5 | Train Loss: 0.9087 | Train Acc: 0.6352 | Val Loss: 0.7934 | Val Acc: 0.7260 | Val F1: 0.7055 | Time: 3.87s\n",
      "Epoch 3/5 | Train Loss: 0.7429 | Train Acc: 0.7359 | Val Loss: 0.6933 | Val Acc: 0.7636 | Val F1: 0.7466 | Time: 3.87s\n",
      "Epoch 4/5 | Train Loss: 0.6599 | Train Acc: 0.7697 | Val Loss: 0.6639 | Val Acc: 0.7792 | Val F1: 0.7660 | Time: 3.83s\n",
      "Epoch 5/5 | Train Loss: 0.6428 | Train Acc: 0.7749 | Val Loss: 0.6566 | Val Acc: 0.7779 | Val F1: 0.7639 | Time: 3.81s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.7779 | Precision: 0.7804 | Recall: 0.7779 | F1: 0.7639\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.80      0.49      0.61       226\n",
      "         Mask       0.79      0.95      0.86       388\n",
      "Improper Mask       0.73      0.76      0.74       156\n",
      "\n",
      "     accuracy                           0.78       770\n",
      "    macro avg       0.77      0.73      0.74       770\n",
      " weighted avg       0.78      0.78      0.76       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.1055 | Train Acc: 0.3713 | Val Loss: 1.0304 | Val Acc: 0.4662 | Val F1: 0.4729 | Time: 3.50s\n",
      "Epoch 2/5 | Train Loss: 0.9171 | Train Acc: 0.6218 | Val Loss: 0.7782 | Val Acc: 0.7494 | Val F1: 0.7372 | Time: 3.60s\n",
      "Epoch 3/5 | Train Loss: 0.7508 | Train Acc: 0.7352 | Val Loss: 0.6740 | Val Acc: 0.7753 | Val F1: 0.7674 | Time: 3.80s\n",
      "Epoch 4/5 | Train Loss: 0.6642 | Train Acc: 0.7638 | Val Loss: 0.6387 | Val Acc: 0.7883 | Val F1: 0.7787 | Time: 5.38s\n",
      "Epoch 5/5 | Train Loss: 0.6439 | Train Acc: 0.7775 | Val Loss: 0.6346 | Val Acc: 0.7766 | Val F1: 0.7669 | Time: 3.95s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.7766 | Precision: 0.7833 | Recall: 0.7766 | F1: 0.7669\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.80      0.50      0.62       226\n",
      "         Mask       0.84      0.94      0.88       388\n",
      "Improper Mask       0.62      0.77      0.69       156\n",
      "\n",
      "     accuracy                           0.78       770\n",
      "    macro avg       0.75      0.74      0.73       770\n",
      " weighted avg       0.78      0.78      0.77       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0975 | Train Acc: 0.4316 | Val Loss: 1.0036 | Val Acc: 0.6346 | Val F1: 0.6230 | Time: 4.00s\n",
      "Epoch 2/5 | Train Loss: 0.9309 | Train Acc: 0.6096 | Val Loss: 0.7841 | Val Acc: 0.7490 | Val F1: 0.7383 | Time: 3.84s\n",
      "Epoch 3/5 | Train Loss: 0.7556 | Train Acc: 0.7324 | Val Loss: 0.6705 | Val Acc: 0.7828 | Val F1: 0.7727 | Time: 4.51s\n",
      "Epoch 4/5 | Train Loss: 0.6857 | Train Acc: 0.7577 | Val Loss: 0.6390 | Val Acc: 0.7828 | Val F1: 0.7764 | Time: 4.57s\n",
      "Epoch 5/5 | Train Loss: 0.6624 | Train Acc: 0.7629 | Val Loss: 0.6396 | Val Acc: 0.7854 | Val F1: 0.7783 | Time: 4.34s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.7828 | Precision: 0.7785 | Recall: 0.7828 | F1: 0.7764\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.73      0.56      0.64       225\n",
      "         Mask       0.84      0.92      0.88       388\n",
      "Improper Mask       0.69      0.76      0.73       156\n",
      "\n",
      "     accuracy                           0.78       769\n",
      "    macro avg       0.75      0.75      0.75       769\n",
      " weighted avg       0.78      0.78      0.78       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.1274 | Train Acc: 0.3914 | Val Loss: 1.0434 | Val Acc: 0.5072 | Val F1: 0.5074 | Time: 5.20s\n",
      "Epoch 2/5 | Train Loss: 0.9373 | Train Acc: 0.5918 | Val Loss: 0.8117 | Val Acc: 0.7334 | Val F1: 0.7259 | Time: 4.35s\n",
      "Epoch 3/5 | Train Loss: 0.7625 | Train Acc: 0.7236 | Val Loss: 0.7157 | Val Acc: 0.7594 | Val F1: 0.7535 | Time: 4.48s\n",
      "Epoch 4/5 | Train Loss: 0.6864 | Train Acc: 0.7532 | Val Loss: 0.6750 | Val Acc: 0.7776 | Val F1: 0.7697 | Time: 4.30s\n",
      "Epoch 5/5 | Train Loss: 0.6574 | Train Acc: 0.7671 | Val Loss: 0.6785 | Val Acc: 0.7685 | Val F1: 0.7655 | Time: 4.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:48:45,183] Trial 4 finished with value: 0.7804053164001148 and parameters: {'backbone': 'mobilenet_v2', 'batch_size': 64, 'learning_rate': 3.488976654890367e-05, 'weight_decay': 0.00045443839603360173, 'use_class_weights': True, 'scheduler_type': 'onecycle', 'freeze_ratio': 0.8947547746402069}. Best is trial 2 with value: 0.9350314964619256.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.7776 | Precision: 0.7716 | Recall: 0.7776 | F1: 0.7697\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.74      0.58      0.65       225\n",
      "         Mask       0.82      0.94      0.87       388\n",
      "Improper Mask       0.70      0.67      0.69       156\n",
      "\n",
      "     accuracy                           0.78       769\n",
      "    macro avg       0.75      0.73      0.74       769\n",
      " weighted avg       0.77      0.78      0.77       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.7804\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.75      0.55      0.64      1128\n",
      "         Mask       0.82      0.94      0.88      1940\n",
      "Improper Mask       0.69      0.72      0.70       780\n",
      "\n",
      "     accuracy                           0.78      3848\n",
      "    macro avg       0.76      0.74      0.74      3848\n",
      " weighted avg       0.78      0.78      0.77      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5041 | Train Acc: 0.8005 | Val Loss: 0.2782 | Val Acc: 0.8922 | Val F1: 0.8899 | Time: 4.86s\n",
      "Epoch 2/5 | Train Loss: 0.1874 | Train Acc: 0.9353 | Val Loss: 0.2517 | Val Acc: 0.9117 | Val F1: 0.9099 | Time: 4.98s\n",
      "Epoch 3/5 | Train Loss: 0.0586 | Train Acc: 0.9815 | Val Loss: 0.2099 | Val Acc: 0.9351 | Val F1: 0.9342 | Time: 5.80s\n",
      "Epoch 4/5 | Train Loss: 0.0342 | Train Acc: 0.9877 | Val Loss: 0.2104 | Val Acc: 0.9390 | Val F1: 0.9384 | Time: 4.41s\n",
      "Epoch 5/5 | Train Loss: 0.0157 | Train Acc: 0.9964 | Val Loss: 0.1963 | Val Acc: 0.9468 | Val F1: 0.9461 | Time: 4.00s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9468 | Precision: 0.9475 | Recall: 0.9468 | F1: 0.9461\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.96      0.88      0.92       226\n",
      "         Mask       0.94      0.99      0.96       388\n",
      "Improper Mask       0.95      0.92      0.93       156\n",
      "\n",
      "     accuracy                           0.95       770\n",
      "    macro avg       0.95      0.93      0.94       770\n",
      " weighted avg       0.95      0.95      0.95       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.4787 | Train Acc: 0.7999 | Val Loss: 0.2888 | Val Acc: 0.8792 | Val F1: 0.8799 | Time: 3.93s\n",
      "Epoch 2/5 | Train Loss: 0.1578 | Train Acc: 0.9444 | Val Loss: 0.2745 | Val Acc: 0.9117 | Val F1: 0.9105 | Time: 3.96s\n",
      "Epoch 3/5 | Train Loss: 0.0841 | Train Acc: 0.9727 | Val Loss: 0.2699 | Val Acc: 0.9182 | Val F1: 0.9174 | Time: 3.93s\n",
      "Epoch 4/5 | Train Loss: 0.0357 | Train Acc: 0.9877 | Val Loss: 0.2194 | Val Acc: 0.9338 | Val F1: 0.9335 | Time: 3.82s\n",
      "Epoch 5/5 | Train Loss: 0.0152 | Train Acc: 0.9971 | Val Loss: 0.2169 | Val Acc: 0.9312 | Val F1: 0.9313 | Time: 5.17s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9312 | Precision: 0.9321 | Recall: 0.9312 | F1: 0.9313\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.89      0.92      0.90       226\n",
      "         Mask       0.95      0.95      0.95       388\n",
      "Improper Mask       0.96      0.89      0.92       156\n",
      "\n",
      "     accuracy                           0.93       770\n",
      "    macro avg       0.93      0.92      0.93       770\n",
      " weighted avg       0.93      0.93      0.93       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.4982 | Train Acc: 0.8021 | Val Loss: 0.2460 | Val Acc: 0.9065 | Val F1: 0.9060 | Time: 3.82s\n",
      "Epoch 2/5 | Train Loss: 0.1649 | Train Acc: 0.9383 | Val Loss: 0.2706 | Val Acc: 0.8987 | Val F1: 0.8996 | Time: 3.89s\n",
      "Epoch 3/5 | Train Loss: 0.1012 | Train Acc: 0.9636 | Val Loss: 0.2058 | Val Acc: 0.9403 | Val F1: 0.9400 | Time: 3.98s\n",
      "Epoch 4/5 | Train Loss: 0.0277 | Train Acc: 0.9916 | Val Loss: 0.1934 | Val Acc: 0.9403 | Val F1: 0.9406 | Time: 4.09s\n",
      "Epoch 5/5 | Train Loss: 0.0147 | Train Acc: 0.9964 | Val Loss: 0.1757 | Val Acc: 0.9481 | Val F1: 0.9482 | Time: 3.76s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9481 | Precision: 0.9485 | Recall: 0.9481 | F1: 0.9482\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.92      0.95      0.93       226\n",
      "         Mask       0.97      0.95      0.96       388\n",
      "Improper Mask       0.95      0.94      0.95       156\n",
      "\n",
      "     accuracy                           0.95       770\n",
      "    macro avg       0.94      0.95      0.95       770\n",
      " weighted avg       0.95      0.95      0.95       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5112 | Train Acc: 0.7899 | Val Loss: 0.2487 | Val Acc: 0.9103 | Val F1: 0.9101 | Time: 3.92s\n",
      "Epoch 2/5 | Train Loss: 0.1664 | Train Acc: 0.9415 | Val Loss: 0.2883 | Val Acc: 0.9038 | Val F1: 0.9026 | Time: 3.92s\n",
      "Epoch 3/5 | Train Loss: 0.0739 | Train Acc: 0.9740 | Val Loss: 0.1996 | Val Acc: 0.9402 | Val F1: 0.9400 | Time: 5.18s\n",
      "Epoch 4/5 | Train Loss: 0.0282 | Train Acc: 0.9893 | Val Loss: 0.1699 | Val Acc: 0.9545 | Val F1: 0.9542 | Time: 3.91s\n",
      "Epoch 5/5 | Train Loss: 0.0121 | Train Acc: 0.9977 | Val Loss: 0.1661 | Val Acc: 0.9441 | Val F1: 0.9444 | Time: 3.84s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9441 | Precision: 0.9452 | Recall: 0.9441 | F1: 0.9444\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.89      0.93      0.91       225\n",
      "         Mask       0.96      0.95      0.96       388\n",
      "Improper Mask       0.99      0.95      0.97       156\n",
      "\n",
      "     accuracy                           0.94       769\n",
      "    macro avg       0.95      0.94      0.94       769\n",
      " weighted avg       0.95      0.94      0.94       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.4782 | Train Acc: 0.8168 | Val Loss: 0.3137 | Val Acc: 0.8687 | Val F1: 0.8676 | Time: 3.81s\n",
      "Epoch 2/5 | Train Loss: 0.1711 | Train Acc: 0.9396 | Val Loss: 0.2183 | Val Acc: 0.9155 | Val F1: 0.9152 | Time: 3.80s\n",
      "Epoch 3/5 | Train Loss: 0.0572 | Train Acc: 0.9802 | Val Loss: 0.2579 | Val Acc: 0.9194 | Val F1: 0.9205 | Time: 3.95s\n",
      "Epoch 4/5 | Train Loss: 0.0282 | Train Acc: 0.9912 | Val Loss: 0.2015 | Val Acc: 0.9285 | Val F1: 0.9281 | Time: 3.97s\n",
      "Epoch 5/5 | Train Loss: 0.0087 | Train Acc: 0.9984 | Val Loss: 0.1886 | Val Acc: 0.9389 | Val F1: 0.9390 | Time: 4.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:50:35,131] Trial 5 finished with value: 0.9417877830881732 and parameters: {'backbone': 'resnet18', 'batch_size': 32, 'learning_rate': 0.0002870875348195468, 'weight_decay': 0.000348771262454593, 'use_class_weights': False, 'scheduler_type': 'cosine', 'freeze_ratio': 0.5254233401144095}. Best is trial 5 with value: 0.9417877830881732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9389 | Precision: 0.9392 | Recall: 0.9389 | F1: 0.9390\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.92      0.91       225\n",
      "         Mask       0.96      0.95      0.95       388\n",
      "Improper Mask       0.95      0.94      0.94       156\n",
      "\n",
      "     accuracy                           0.94       769\n",
      "    macro avg       0.94      0.94      0.94       769\n",
      " weighted avg       0.94      0.94      0.94       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9418\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.92      0.91      1128\n",
      "         Mask       0.95      0.96      0.96      1940\n",
      "Improper Mask       0.96      0.93      0.94       780\n",
      "\n",
      "     accuracy                           0.94      3848\n",
      "    macro avg       0.94      0.94      0.94      3848\n",
      " weighted avg       0.94      0.94      0.94      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.7283 | Train Acc: 0.6927 | Val Loss: 0.4813 | Val Acc: 0.8052 | Val F1: 0.7963 | Time: 5.15s\n",
      "Epoch 2/5 | Train Loss: 0.4006 | Train Acc: 0.8434 | Val Loss: 0.3633 | Val Acc: 0.8610 | Val F1: 0.8563 | Time: 4.08s\n",
      "Epoch 3/5 | Train Loss: 0.2633 | Train Acc: 0.8983 | Val Loss: 0.2839 | Val Acc: 0.8935 | Val F1: 0.8921 | Time: 3.97s\n",
      "Epoch 4/5 | Train Loss: 0.1781 | Train Acc: 0.9396 | Val Loss: 0.2815 | Val Acc: 0.8922 | Val F1: 0.8901 | Time: 3.80s\n",
      "Epoch 5/5 | Train Loss: 0.1414 | Train Acc: 0.9532 | Val Loss: 0.2794 | Val Acc: 0.8961 | Val F1: 0.8942 | Time: 4.03s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.8961 | Precision: 0.8961 | Recall: 0.8961 | F1: 0.8942\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.86      0.84      0.85       226\n",
      "         Mask       0.91      0.98      0.94       388\n",
      "Improper Mask       0.92      0.78      0.84       156\n",
      "\n",
      "     accuracy                           0.90       770\n",
      "    macro avg       0.90      0.86      0.88       770\n",
      " weighted avg       0.90      0.90      0.89       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.7159 | Train Acc: 0.7079 | Val Loss: 0.4821 | Val Acc: 0.8026 | Val F1: 0.7951 | Time: 4.13s\n",
      "Epoch 2/5 | Train Loss: 0.3891 | Train Acc: 0.8454 | Val Loss: 0.3671 | Val Acc: 0.8558 | Val F1: 0.8518 | Time: 3.87s\n",
      "Epoch 3/5 | Train Loss: 0.2511 | Train Acc: 0.9094 | Val Loss: 0.3194 | Val Acc: 0.8792 | Val F1: 0.8779 | Time: 4.01s\n",
      "Epoch 4/5 | Train Loss: 0.1809 | Train Acc: 0.9363 | Val Loss: 0.3157 | Val Acc: 0.8857 | Val F1: 0.8839 | Time: 5.27s\n",
      "Epoch 5/5 | Train Loss: 0.1480 | Train Acc: 0.9555 | Val Loss: 0.3134 | Val Acc: 0.8922 | Val F1: 0.8908 | Time: 4.13s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.8922 | Precision: 0.8948 | Recall: 0.8922 | F1: 0.8908\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.80      0.85       226\n",
      "         Mask       0.87      0.97      0.92       388\n",
      "Improper Mask       0.95      0.84      0.89       156\n",
      "\n",
      "     accuracy                           0.89       770\n",
      "    macro avg       0.91      0.87      0.88       770\n",
      " weighted avg       0.89      0.89      0.89       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.7326 | Train Acc: 0.7008 | Val Loss: 0.4809 | Val Acc: 0.8234 | Val F1: 0.8188 | Time: 3.68s\n",
      "Epoch 2/5 | Train Loss: 0.4000 | Train Acc: 0.8428 | Val Loss: 0.3615 | Val Acc: 0.8584 | Val F1: 0.8577 | Time: 3.87s\n",
      "Epoch 3/5 | Train Loss: 0.2565 | Train Acc: 0.9071 | Val Loss: 0.3257 | Val Acc: 0.8727 | Val F1: 0.8723 | Time: 3.97s\n",
      "Epoch 4/5 | Train Loss: 0.1721 | Train Acc: 0.9415 | Val Loss: 0.3209 | Val Acc: 0.8831 | Val F1: 0.8814 | Time: 3.88s\n",
      "Epoch 5/5 | Train Loss: 0.1440 | Train Acc: 0.9519 | Val Loss: 0.3150 | Val Acc: 0.8792 | Val F1: 0.8784 | Time: 4.05s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.8792 | Precision: 0.8803 | Recall: 0.8792 | F1: 0.8784\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.81      0.84      0.83       226\n",
      "         Mask       0.91      0.94      0.93       388\n",
      "Improper Mask       0.91      0.78      0.84       156\n",
      "\n",
      "     accuracy                           0.88       770\n",
      "    macro avg       0.88      0.85      0.86       770\n",
      " weighted avg       0.88      0.88      0.88       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.7287 | Train Acc: 0.6980 | Val Loss: 0.4646 | Val Acc: 0.8075 | Val F1: 0.8006 | Time: 5.02s\n",
      "Epoch 2/5 | Train Loss: 0.4024 | Train Acc: 0.8428 | Val Loss: 0.3325 | Val Acc: 0.8713 | Val F1: 0.8701 | Time: 4.01s\n",
      "Epoch 3/5 | Train Loss: 0.2549 | Train Acc: 0.9039 | Val Loss: 0.3160 | Val Acc: 0.8674 | Val F1: 0.8637 | Time: 3.98s\n",
      "Epoch 4/5 | Train Loss: 0.1739 | Train Acc: 0.9415 | Val Loss: 0.2729 | Val Acc: 0.8921 | Val F1: 0.8909 | Time: 3.66s\n",
      "Epoch 5/5 | Train Loss: 0.1392 | Train Acc: 0.9513 | Val Loss: 0.2664 | Val Acc: 0.8986 | Val F1: 0.8980 | Time: 3.90s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.8986 | Precision: 0.8978 | Recall: 0.8986 | F1: 0.8980\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.86      0.83      0.84       225\n",
      "         Mask       0.92      0.95      0.93       388\n",
      "Improper Mask       0.90      0.88      0.89       156\n",
      "\n",
      "     accuracy                           0.90       769\n",
      "    macro avg       0.89      0.89      0.89       769\n",
      " weighted avg       0.90      0.90      0.90       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6983 | Train Acc: 0.7158 | Val Loss: 0.5037 | Val Acc: 0.7880 | Val F1: 0.7878 | Time: 3.85s\n",
      "Epoch 2/5 | Train Loss: 0.3896 | Train Acc: 0.8454 | Val Loss: 0.3447 | Val Acc: 0.8661 | Val F1: 0.8649 | Time: 3.80s\n",
      "Epoch 3/5 | Train Loss: 0.2487 | Train Acc: 0.9113 | Val Loss: 0.3025 | Val Acc: 0.8882 | Val F1: 0.8869 | Time: 3.91s\n",
      "Epoch 4/5 | Train Loss: 0.1681 | Train Acc: 0.9402 | Val Loss: 0.2918 | Val Acc: 0.8843 | Val F1: 0.8839 | Time: 5.20s\n",
      "Epoch 5/5 | Train Loss: 0.1320 | Train Acc: 0.9578 | Val Loss: 0.2966 | Val Acc: 0.8804 | Val F1: 0.8805 | Time: 4.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:52:23,856] Trial 6 finished with value: 0.8900734635975208 and parameters: {'backbone': 'mobilenet_v2', 'batch_size': 64, 'learning_rate': 8.798929749689021e-05, 'weight_decay': 1.7345566642360933e-05, 'use_class_weights': False, 'scheduler_type': 'cosine', 'freeze_ratio': 0.6710164073434198}. Best is trial 5 with value: 0.9417877830881732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.8843 | Precision: 0.8840 | Recall: 0.8843 | F1: 0.8839\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.83      0.83      0.83       225\n",
      "         Mask       0.91      0.94      0.92       388\n",
      "Improper Mask       0.89      0.83      0.86       156\n",
      "\n",
      "     accuracy                           0.88       769\n",
      "    macro avg       0.88      0.87      0.87       769\n",
      " weighted avg       0.88      0.88      0.88       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.8901\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.85      0.83      0.84      1128\n",
      "         Mask       0.90      0.95      0.93      1940\n",
      "Improper Mask       0.91      0.82      0.87       780\n",
      "\n",
      "     accuracy                           0.89      3848\n",
      "    macro avg       0.89      0.87      0.88      3848\n",
      " weighted avg       0.89      0.89      0.89      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6278 | Train Acc: 0.7329 | Val Loss: 0.4076 | Val Acc: 0.8403 | Val F1: 0.8316 | Time: 4.04s\n",
      "Epoch 2/5 | Train Loss: 0.3012 | Train Acc: 0.8847 | Val Loss: 0.2841 | Val Acc: 0.9000 | Val F1: 0.8993 | Time: 3.88s\n",
      "Epoch 3/5 | Train Loss: 0.1740 | Train Acc: 0.9396 | Val Loss: 0.2504 | Val Acc: 0.9169 | Val F1: 0.9169 | Time: 4.03s\n",
      "Epoch 4/5 | Train Loss: 0.1014 | Train Acc: 0.9675 | Val Loss: 0.2583 | Val Acc: 0.9312 | Val F1: 0.9305 | Time: 3.96s\n",
      "Epoch 5/5 | Train Loss: 0.0784 | Train Acc: 0.9750 | Val Loss: 0.2883 | Val Acc: 0.9182 | Val F1: 0.9176 | Time: 4.05s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9169 | Precision: 0.9169 | Recall: 0.9169 | F1: 0.9169\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.89      0.89      0.89       226\n",
      "         Mask       0.95      0.95      0.95       388\n",
      "Improper Mask       0.87      0.87      0.87       156\n",
      "\n",
      "     accuracy                           0.92       770\n",
      "    macro avg       0.90      0.90      0.90       770\n",
      " weighted avg       0.92      0.92      0.92       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6162 | Train Acc: 0.7479 | Val Loss: 0.4121 | Val Acc: 0.8364 | Val F1: 0.8316 | Time: 4.07s\n",
      "Epoch 2/5 | Train Loss: 0.2981 | Train Acc: 0.8811 | Val Loss: 0.2719 | Val Acc: 0.9000 | Val F1: 0.8991 | Time: 5.47s\n",
      "Epoch 3/5 | Train Loss: 0.1614 | Train Acc: 0.9457 | Val Loss: 0.2349 | Val Acc: 0.9078 | Val F1: 0.9071 | Time: 4.31s\n",
      "Epoch 4/5 | Train Loss: 0.0965 | Train Acc: 0.9665 | Val Loss: 0.2975 | Val Acc: 0.8974 | Val F1: 0.8969 | Time: 4.09s\n",
      "Epoch 5/5 | Train Loss: 0.0582 | Train Acc: 0.9805 | Val Loss: 0.3005 | Val Acc: 0.9104 | Val F1: 0.9106 | Time: 4.06s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9078 | Precision: 0.9086 | Recall: 0.9078 | F1: 0.9071\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.89      0.85      0.87       226\n",
      "         Mask       0.90      0.96      0.93       388\n",
      "Improper Mask       0.95      0.87      0.91       156\n",
      "\n",
      "     accuracy                           0.91       770\n",
      "    macro avg       0.91      0.89      0.90       770\n",
      " weighted avg       0.91      0.91      0.91       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6257 | Train Acc: 0.7466 | Val Loss: 0.3940 | Val Acc: 0.8403 | Val F1: 0.8343 | Time: 4.25s\n",
      "Epoch 2/5 | Train Loss: 0.3128 | Train Acc: 0.8811 | Val Loss: 0.2815 | Val Acc: 0.8987 | Val F1: 0.8970 | Time: 4.27s\n",
      "Epoch 3/5 | Train Loss: 0.1649 | Train Acc: 0.9415 | Val Loss: 0.2911 | Val Acc: 0.9013 | Val F1: 0.9003 | Time: 4.53s\n",
      "Epoch 4/5 | Train Loss: 0.1013 | Train Acc: 0.9636 | Val Loss: 0.2753 | Val Acc: 0.9078 | Val F1: 0.9088 | Time: 5.36s\n",
      "Epoch 5/5 | Train Loss: 0.0736 | Train Acc: 0.9721 | Val Loss: 0.2560 | Val Acc: 0.9195 | Val F1: 0.9191 | Time: 4.20s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9195 | Precision: 0.9191 | Recall: 0.9195 | F1: 0.9191\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.86      0.88       226\n",
      "         Mask       0.93      0.96      0.94       388\n",
      "Improper Mask       0.92      0.91      0.91       156\n",
      "\n",
      "     accuracy                           0.92       770\n",
      "    macro avg       0.92      0.91      0.91       770\n",
      " weighted avg       0.92      0.92      0.92       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6164 | Train Acc: 0.7450 | Val Loss: 0.3593 | Val Acc: 0.8492 | Val F1: 0.8473 | Time: 4.01s\n",
      "Epoch 2/5 | Train Loss: 0.2949 | Train Acc: 0.8860 | Val Loss: 0.2696 | Val Acc: 0.8934 | Val F1: 0.8919 | Time: 4.09s\n",
      "Epoch 3/5 | Train Loss: 0.1771 | Train Acc: 0.9331 | Val Loss: 0.2769 | Val Acc: 0.8934 | Val F1: 0.8919 | Time: 4.31s\n",
      "Epoch 4/5 | Train Loss: 0.0994 | Train Acc: 0.9646 | Val Loss: 0.2479 | Val Acc: 0.9168 | Val F1: 0.9165 | Time: 4.27s\n",
      "Epoch 5/5 | Train Loss: 0.0654 | Train Acc: 0.9802 | Val Loss: 0.3059 | Val Acc: 0.9103 | Val F1: 0.9099 | Time: 4.17s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9168 | Precision: 0.9164 | Recall: 0.9168 | F1: 0.9165\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.89      0.86      0.87       225\n",
      "         Mask       0.93      0.95      0.94       388\n",
      "Improper Mask       0.92      0.92      0.92       156\n",
      "\n",
      "     accuracy                           0.92       769\n",
      "    macro avg       0.91      0.91      0.91       769\n",
      " weighted avg       0.92      0.92      0.92       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6245 | Train Acc: 0.7392 | Val Loss: 0.3679 | Val Acc: 0.8583 | Val F1: 0.8561 | Time: 5.54s\n",
      "Epoch 2/5 | Train Loss: 0.2910 | Train Acc: 0.8896 | Val Loss: 0.2795 | Val Acc: 0.8934 | Val F1: 0.8927 | Time: 4.31s\n",
      "Epoch 3/5 | Train Loss: 0.1569 | Train Acc: 0.9441 | Val Loss: 0.3190 | Val Acc: 0.9012 | Val F1: 0.9002 | Time: 4.17s\n",
      "Epoch 4/5 | Train Loss: 0.0942 | Train Acc: 0.9672 | Val Loss: 0.2680 | Val Acc: 0.9194 | Val F1: 0.9185 | Time: 3.95s\n",
      "Epoch 5/5 | Train Loss: 0.0597 | Train Acc: 0.9786 | Val Loss: 0.2708 | Val Acc: 0.9194 | Val F1: 0.9189 | Time: 4.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:54:16,477] Trial 7 finished with value: 0.916061337881884 and parameters: {'backbone': 'mobilenet_v2', 'batch_size': 32, 'learning_rate': 0.0001040258761588385, 'weight_decay': 0.0006533305220227731, 'use_class_weights': False, 'scheduler_type': 'step', 'freeze_ratio': 0.5644885149016018}. Best is trial 5 with value: 0.9417877830881732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9194 | Precision: 0.9201 | Recall: 0.9194 | F1: 0.9185\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.85      0.88       225\n",
      "         Mask       0.91      0.98      0.94       388\n",
      "Improper Mask       0.95      0.87      0.91       156\n",
      "\n",
      "     accuracy                           0.92       769\n",
      "    macro avg       0.93      0.90      0.91       769\n",
      " weighted avg       0.92      0.92      0.92       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9161\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.86      0.88      1128\n",
      "         Mask       0.93      0.96      0.94      1940\n",
      "Improper Mask       0.92      0.89      0.90       780\n",
      "\n",
      "     accuracy                           0.92      3848\n",
      "    macro avg       0.91      0.90      0.91      3848\n",
      " weighted avg       0.92      0.92      0.92      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.9223 | Train Acc: 0.5741 | Val Loss: 0.6906 | Val Acc: 0.7494 | Val F1: 0.7255 | Time: 3.82s\n",
      "Epoch 2/5 | Train Loss: 0.6478 | Train Acc: 0.7479 | Val Loss: 0.5192 | Val Acc: 0.8026 | Val F1: 0.7906 | Time: 3.89s\n",
      "Epoch 3/5 | Train Loss: 0.4863 | Train Acc: 0.8174 | Val Loss: 0.4252 | Val Acc: 0.8286 | Val F1: 0.8210 | Time: 3.82s\n",
      "Epoch 4/5 | Train Loss: 0.3580 | Train Acc: 0.8726 | Val Loss: 0.3537 | Val Acc: 0.8662 | Val F1: 0.8626 | Time: 5.06s\n",
      "Epoch 5/5 | Train Loss: 0.2671 | Train Acc: 0.9077 | Val Loss: 0.3173 | Val Acc: 0.8844 | Val F1: 0.8821 | Time: 3.91s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.8844 | Precision: 0.8867 | Recall: 0.8844 | F1: 0.8821\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.83      0.84      0.84       226\n",
      "         Mask       0.90      0.97      0.93       388\n",
      "Improper Mask       0.94      0.73      0.82       156\n",
      "\n",
      "     accuracy                           0.88       770\n",
      "    macro avg       0.89      0.85      0.86       770\n",
      " weighted avg       0.89      0.88      0.88       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.9915 | Train Acc: 0.5305 | Val Loss: 0.7080 | Val Acc: 0.7390 | Val F1: 0.7150 | Time: 3.62s\n",
      "Epoch 2/5 | Train Loss: 0.6433 | Train Acc: 0.7495 | Val Loss: 0.5370 | Val Acc: 0.8026 | Val F1: 0.7920 | Time: 3.62s\n",
      "Epoch 3/5 | Train Loss: 0.4792 | Train Acc: 0.8255 | Val Loss: 0.4321 | Val Acc: 0.8416 | Val F1: 0.8363 | Time: 3.92s\n",
      "Epoch 4/5 | Train Loss: 0.3744 | Train Acc: 0.8717 | Val Loss: 0.3610 | Val Acc: 0.8727 | Val F1: 0.8709 | Time: 4.04s\n",
      "Epoch 5/5 | Train Loss: 0.2611 | Train Acc: 0.9113 | Val Loss: 0.3246 | Val Acc: 0.8870 | Val F1: 0.8857 | Time: 3.96s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.8870 | Precision: 0.8887 | Recall: 0.8870 | F1: 0.8857\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.86      0.85      0.85       226\n",
      "         Mask       0.89      0.95      0.92       388\n",
      "Improper Mask       0.94      0.78      0.85       156\n",
      "\n",
      "     accuracy                           0.89       770\n",
      "    macro avg       0.89      0.86      0.87       770\n",
      " weighted avg       0.89      0.89      0.89       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.9305 | Train Acc: 0.5640 | Val Loss: 0.6909 | Val Acc: 0.7532 | Val F1: 0.7330 | Time: 4.08s\n",
      "Epoch 2/5 | Train Loss: 0.6448 | Train Acc: 0.7537 | Val Loss: 0.5256 | Val Acc: 0.7987 | Val F1: 0.7871 | Time: 5.25s\n",
      "Epoch 3/5 | Train Loss: 0.4856 | Train Acc: 0.8171 | Val Loss: 0.4346 | Val Acc: 0.8273 | Val F1: 0.8193 | Time: 4.17s\n",
      "Epoch 4/5 | Train Loss: 0.3774 | Train Acc: 0.8593 | Val Loss: 0.3735 | Val Acc: 0.8545 | Val F1: 0.8500 | Time: 3.80s\n",
      "Epoch 5/5 | Train Loss: 0.2768 | Train Acc: 0.9042 | Val Loss: 0.3309 | Val Acc: 0.8714 | Val F1: 0.8684 | Time: 3.88s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.8714 | Precision: 0.8705 | Recall: 0.8714 | F1: 0.8684\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.85      0.76      0.80       226\n",
      "         Mask       0.88      0.97      0.92       388\n",
      "Improper Mask       0.88      0.78      0.82       156\n",
      "\n",
      "     accuracy                           0.87       770\n",
      "    macro avg       0.87      0.84      0.85       770\n",
      " weighted avg       0.87      0.87      0.87       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.8939 | Train Acc: 0.6054 | Val Loss: 0.6531 | Val Acc: 0.7724 | Val F1: 0.7558 | Time: 4.07s\n",
      "Epoch 2/5 | Train Loss: 0.6308 | Train Acc: 0.7590 | Val Loss: 0.4986 | Val Acc: 0.8088 | Val F1: 0.7985 | Time: 4.12s\n",
      "Epoch 3/5 | Train Loss: 0.4746 | Train Acc: 0.8162 | Val Loss: 0.4138 | Val Acc: 0.8322 | Val F1: 0.8262 | Time: 4.04s\n",
      "Epoch 4/5 | Train Loss: 0.3558 | Train Acc: 0.8668 | Val Loss: 0.3513 | Val Acc: 0.8557 | Val F1: 0.8532 | Time: 4.00s\n",
      "Epoch 5/5 | Train Loss: 0.2574 | Train Acc: 0.9169 | Val Loss: 0.3193 | Val Acc: 0.8661 | Val F1: 0.8642 | Time: 5.23s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.8661 | Precision: 0.8639 | Recall: 0.8661 | F1: 0.8642\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.81      0.76      0.79       225\n",
      "         Mask       0.90      0.95      0.92       388\n",
      "Improper Mask       0.85      0.81      0.83       156\n",
      "\n",
      "     accuracy                           0.87       769\n",
      "    macro avg       0.85      0.84      0.85       769\n",
      " weighted avg       0.86      0.87      0.86       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.9373 | Train Acc: 0.5593 | Val Loss: 0.7120 | Val Acc: 0.7347 | Val F1: 0.7092 | Time: 3.93s\n",
      "Epoch 2/5 | Train Loss: 0.6547 | Train Acc: 0.7486 | Val Loss: 0.5426 | Val Acc: 0.7932 | Val F1: 0.7816 | Time: 3.66s\n",
      "Epoch 3/5 | Train Loss: 0.5037 | Train Acc: 0.8042 | Val Loss: 0.4493 | Val Acc: 0.8322 | Val F1: 0.8258 | Time: 3.94s\n",
      "Epoch 4/5 | Train Loss: 0.3846 | Train Acc: 0.8636 | Val Loss: 0.3813 | Val Acc: 0.8466 | Val F1: 0.8419 | Time: 3.99s\n",
      "Epoch 5/5 | Train Loss: 0.2984 | Train Acc: 0.9003 | Val Loss: 0.3444 | Val Acc: 0.8531 | Val F1: 0.8495 | Time: 4.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:56:03,679] Trial 8 finished with value: 0.8723945755155118 and parameters: {'backbone': 'resnet18', 'batch_size': 32, 'learning_rate': 2.3612399244412595e-05, 'weight_decay': 0.0006097025297491432, 'use_class_weights': False, 'scheduler_type': 'step', 'freeze_ratio': 0.6708431154505026}. Best is trial 5 with value: 0.9417877830881732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.8531 | Precision: 0.8526 | Recall: 0.8531 | F1: 0.8495\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.81      0.76      0.78       225\n",
      "         Mask       0.87      0.96      0.91       388\n",
      "Improper Mask       0.88      0.72      0.79       156\n",
      "\n",
      "     accuracy                           0.85       769\n",
      "    macro avg       0.85      0.81      0.83       769\n",
      " weighted avg       0.85      0.85      0.85       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.8724\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.83      0.79      0.81      1128\n",
      "         Mask       0.88      0.96      0.92      1940\n",
      "Improper Mask       0.90      0.76      0.82       780\n",
      "\n",
      "     accuracy                           0.87      3848\n",
      "    macro avg       0.87      0.84      0.85      3848\n",
      " weighted avg       0.87      0.87      0.87      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0519 | Train Acc: 0.4558 | Val Loss: 0.9208 | Val Acc: 0.5792 | Val F1: 0.4876 | Time: 4.05s\n",
      "Epoch 2/5 | Train Loss: 0.8042 | Train Acc: 0.6754 | Val Loss: 0.6645 | Val Acc: 0.7584 | Val F1: 0.7391 | Time: 5.37s\n",
      "Epoch 3/5 | Train Loss: 0.6473 | Train Acc: 0.7524 | Val Loss: 0.5726 | Val Acc: 0.7753 | Val F1: 0.7592 | Time: 4.15s\n",
      "Epoch 4/5 | Train Loss: 0.5716 | Train Acc: 0.7781 | Val Loss: 0.5268 | Val Acc: 0.7961 | Val F1: 0.7848 | Time: 3.91s\n",
      "Epoch 5/5 | Train Loss: 0.5657 | Train Acc: 0.7804 | Val Loss: 0.5304 | Val Acc: 0.7883 | Val F1: 0.7756 | Time: 3.86s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.7961 | Precision: 0.7961 | Recall: 0.7961 | F1: 0.7848\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.74      0.64      0.69       226\n",
      "         Mask       0.81      0.98      0.89       388\n",
      "Improper Mask       0.84      0.56      0.67       156\n",
      "\n",
      "     accuracy                           0.80       770\n",
      "    macro avg       0.80      0.73      0.75       770\n",
      " weighted avg       0.80      0.80      0.78       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0854 | Train Acc: 0.4029 | Val Loss: 0.9313 | Val Acc: 0.5870 | Val F1: 0.4965 | Time: 3.90s\n",
      "Epoch 2/5 | Train Loss: 0.8107 | Train Acc: 0.6696 | Val Loss: 0.6810 | Val Acc: 0.7429 | Val F1: 0.7195 | Time: 4.08s\n",
      "Epoch 3/5 | Train Loss: 0.6407 | Train Acc: 0.7511 | Val Loss: 0.5833 | Val Acc: 0.7714 | Val F1: 0.7548 | Time: 4.11s\n",
      "Epoch 4/5 | Train Loss: 0.5575 | Train Acc: 0.7771 | Val Loss: 0.5566 | Val Acc: 0.7831 | Val F1: 0.7692 | Time: 4.13s\n",
      "Epoch 5/5 | Train Loss: 0.5637 | Train Acc: 0.7742 | Val Loss: 0.5552 | Val Acc: 0.7805 | Val F1: 0.7657 | Time: 5.36s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.7805 | Precision: 0.7782 | Recall: 0.7805 | F1: 0.7657\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.75      0.52      0.62       226\n",
      "         Mask       0.78      0.99      0.87       388\n",
      "Improper Mask       0.80      0.64      0.71       156\n",
      "\n",
      "     accuracy                           0.78       770\n",
      "    macro avg       0.78      0.72      0.73       770\n",
      " weighted avg       0.78      0.78      0.77       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0763 | Train Acc: 0.4431 | Val Loss: 0.9326 | Val Acc: 0.5442 | Val F1: 0.4247 | Time: 4.00s\n",
      "Epoch 2/5 | Train Loss: 0.8256 | Train Acc: 0.6520 | Val Loss: 0.6736 | Val Acc: 0.7740 | Val F1: 0.7567 | Time: 3.66s\n",
      "Epoch 3/5 | Train Loss: 0.6507 | Train Acc: 0.7554 | Val Loss: 0.5750 | Val Acc: 0.7935 | Val F1: 0.7807 | Time: 4.03s\n",
      "Epoch 4/5 | Train Loss: 0.5738 | Train Acc: 0.7729 | Val Loss: 0.5434 | Val Acc: 0.7961 | Val F1: 0.7847 | Time: 4.02s\n",
      "Epoch 5/5 | Train Loss: 0.5616 | Train Acc: 0.7801 | Val Loss: 0.5307 | Val Acc: 0.7922 | Val F1: 0.7810 | Time: 4.05s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.7922 | Precision: 0.7868 | Recall: 0.7922 | F1: 0.7810\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.75      0.61      0.67       226\n",
      "         Mask       0.81      0.98      0.89       388\n",
      "Improper Mask       0.77      0.59      0.67       156\n",
      "\n",
      "     accuracy                           0.79       770\n",
      "    macro avg       0.78      0.73      0.74       770\n",
      " weighted avg       0.79      0.79      0.78       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.1554 | Train Acc: 0.3124 | Val Loss: 0.9427 | Val Acc: 0.5930 | Val F1: 0.5113 | Time: 3.97s\n",
      "Epoch 2/5 | Train Loss: 0.8299 | Train Acc: 0.6655 | Val Loss: 0.6643 | Val Acc: 0.7594 | Val F1: 0.7420 | Time: 3.96s\n",
      "Epoch 3/5 | Train Loss: 0.6563 | Train Acc: 0.7447 | Val Loss: 0.5637 | Val Acc: 0.7867 | Val F1: 0.7748 | Time: 5.36s\n",
      "Epoch 4/5 | Train Loss: 0.5905 | Train Acc: 0.7671 | Val Loss: 0.5305 | Val Acc: 0.7919 | Val F1: 0.7804 | Time: 3.98s\n",
      "Epoch 5/5 | Train Loss: 0.5689 | Train Acc: 0.7740 | Val Loss: 0.5328 | Val Acc: 0.7945 | Val F1: 0.7843 | Time: 3.86s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.7919 | Precision: 0.7891 | Recall: 0.7919 | F1: 0.7804\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.71      0.63      0.67       225\n",
      "         Mask       0.82      0.98      0.89       388\n",
      "Improper Mask       0.83      0.55      0.66       156\n",
      "\n",
      "     accuracy                           0.79       769\n",
      "    macro avg       0.79      0.72      0.74       769\n",
      " weighted avg       0.79      0.79      0.78       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0383 | Train Acc: 0.4784 | Val Loss: 0.9085 | Val Acc: 0.5956 | Val F1: 0.5124 | Time: 4.05s\n",
      "Epoch 2/5 | Train Loss: 0.7908 | Train Acc: 0.6713 | Val Loss: 0.6614 | Val Acc: 0.7607 | Val F1: 0.7436 | Time: 4.16s\n",
      "Epoch 3/5 | Train Loss: 0.6271 | Train Acc: 0.7535 | Val Loss: 0.5589 | Val Acc: 0.7867 | Val F1: 0.7767 | Time: 3.98s\n",
      "Epoch 4/5 | Train Loss: 0.5731 | Train Acc: 0.7772 | Val Loss: 0.5316 | Val Acc: 0.7971 | Val F1: 0.7863 | Time: 4.11s\n",
      "Epoch 5/5 | Train Loss: 0.5468 | Train Acc: 0.7817 | Val Loss: 0.5275 | Val Acc: 0.7997 | Val F1: 0.7891 | Time: 5.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:57:54,308] Trial 9 finished with value: 0.7921017344164288 and parameters: {'backbone': 'mobilenet_v2', 'batch_size': 32, 'learning_rate': 2.781093697926551e-05, 'weight_decay': 1.736723715159314e-05, 'use_class_weights': False, 'scheduler_type': 'onecycle', 'freeze_ratio': 0.8887128330883842}. Best is trial 5 with value: 0.9417877830881732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.7997 | Precision: 0.7972 | Recall: 0.7997 | F1: 0.7891\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.76      0.63      0.69       225\n",
      "         Mask       0.81      0.98      0.89       388\n",
      "Improper Mask       0.82      0.60      0.69       156\n",
      "\n",
      "     accuracy                           0.80       769\n",
      "    macro avg       0.80      0.73      0.75       769\n",
      " weighted avg       0.80      0.80      0.79       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.7921\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.74      0.61      0.67      1128\n",
      "         Mask       0.81      0.98      0.89      1940\n",
      "Improper Mask       0.81      0.59      0.68       780\n",
      "\n",
      "     accuracy                           0.79      3848\n",
      "    macro avg       0.79      0.73      0.74      3848\n",
      " weighted avg       0.79      0.79      0.78      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5914 | Train Acc: 0.7697 | Val Loss: 0.4083 | Val Acc: 0.8558 | Val F1: 0.8564 | Time: 4.24s\n",
      "Epoch 2/5 | Train Loss: 0.2973 | Train Acc: 0.8951 | Val Loss: 0.6219 | Val Acc: 0.8779 | Val F1: 0.8745 | Time: 4.00s\n",
      "Epoch 3/5 | Train Loss: 0.1992 | Train Acc: 0.9292 | Val Loss: 0.2991 | Val Acc: 0.9286 | Val F1: 0.9286 | Time: 4.19s\n",
      "Epoch 4/5 | Train Loss: 0.1355 | Train Acc: 0.9607 | Val Loss: 0.2830 | Val Acc: 0.9091 | Val F1: 0.9102 | Time: 4.19s\n",
      "Epoch 5/5 | Train Loss: 0.1236 | Train Acc: 0.9623 | Val Loss: 0.2700 | Val Acc: 0.9325 | Val F1: 0.9321 | Time: 4.18s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9325 | Precision: 0.9323 | Recall: 0.9325 | F1: 0.9321\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.92      0.88      0.90       226\n",
      "         Mask       0.94      0.97      0.95       388\n",
      "Improper Mask       0.94      0.90      0.92       156\n",
      "\n",
      "     accuracy                           0.93       770\n",
      "    macro avg       0.93      0.92      0.93       770\n",
      " weighted avg       0.93      0.93      0.93       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5750 | Train Acc: 0.7830 | Val Loss: 0.3951 | Val Acc: 0.8442 | Val F1: 0.8464 | Time: 4.42s\n",
      "Epoch 2/5 | Train Loss: 0.2955 | Train Acc: 0.8918 | Val Loss: 0.3780 | Val Acc: 0.8870 | Val F1: 0.8871 | Time: 5.61s\n",
      "Epoch 3/5 | Train Loss: 0.1776 | Train Acc: 0.9357 | Val Loss: 0.3776 | Val Acc: 0.9026 | Val F1: 0.9016 | Time: 4.55s\n",
      "Epoch 4/5 | Train Loss: 0.1344 | Train Acc: 0.9594 | Val Loss: 0.2942 | Val Acc: 0.9065 | Val F1: 0.9061 | Time: 4.35s\n",
      "Epoch 5/5 | Train Loss: 0.0962 | Train Acc: 0.9708 | Val Loss: 0.2652 | Val Acc: 0.9195 | Val F1: 0.9193 | Time: 4.48s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9195 | Precision: 0.9197 | Recall: 0.9195 | F1: 0.9193\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.87      0.90      0.88       226\n",
      "         Mask       0.95      0.96      0.95       388\n",
      "Improper Mask       0.92      0.85      0.88       156\n",
      "\n",
      "     accuracy                           0.92       770\n",
      "    macro avg       0.91      0.90      0.91       770\n",
      " weighted avg       0.92      0.92      0.92       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5965 | Train Acc: 0.7775 | Val Loss: 0.3046 | Val Acc: 0.8805 | Val F1: 0.8808 | Time: 5.17s\n",
      "Epoch 2/5 | Train Loss: 0.3382 | Train Acc: 0.8889 | Val Loss: 0.2812 | Val Acc: 0.8883 | Val F1: 0.8892 | Time: 5.92s\n",
      "Epoch 3/5 | Train Loss: 0.1946 | Train Acc: 0.9363 | Val Loss: 0.2080 | Val Acc: 0.9260 | Val F1: 0.9260 | Time: 5.63s\n",
      "Epoch 4/5 | Train Loss: 0.1297 | Train Acc: 0.9526 | Val Loss: 0.2426 | Val Acc: 0.9442 | Val F1: 0.9444 | Time: 6.93s\n",
      "Epoch 5/5 | Train Loss: 0.0981 | Train Acc: 0.9665 | Val Loss: 0.2601 | Val Acc: 0.9325 | Val F1: 0.9320 | Time: 4.93s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9260 | Precision: 0.9278 | Recall: 0.9260 | F1: 0.9260\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.93      0.86      0.89       226\n",
      "         Mask       0.96      0.96      0.96       388\n",
      "Improper Mask       0.85      0.95      0.90       156\n",
      "\n",
      "     accuracy                           0.93       770\n",
      "    macro avg       0.91      0.92      0.92       770\n",
      " weighted avg       0.93      0.93      0.93       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5813 | Train Acc: 0.7886 | Val Loss: 0.3503 | Val Acc: 0.8739 | Val F1: 0.8739 | Time: 4.26s\n",
      "Epoch 2/5 | Train Loss: 0.2862 | Train Acc: 0.9039 | Val Loss: 0.3603 | Val Acc: 0.8596 | Val F1: 0.8622 | Time: 4.39s\n",
      "Epoch 3/5 | Train Loss: 0.1971 | Train Acc: 0.9279 | Val Loss: 0.2719 | Val Acc: 0.8986 | Val F1: 0.8997 | Time: 4.58s\n",
      "Epoch 4/5 | Train Loss: 0.1307 | Train Acc: 0.9568 | Val Loss: 0.2255 | Val Acc: 0.9194 | Val F1: 0.9199 | Time: 4.57s\n",
      "Epoch 5/5 | Train Loss: 0.0842 | Train Acc: 0.9730 | Val Loss: 0.3367 | Val Acc: 0.8934 | Val F1: 0.8946 | Time: 5.51s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9194 | Precision: 0.9211 | Recall: 0.9194 | F1: 0.9199\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.86      0.90      0.88       225\n",
      "         Mask       0.96      0.92      0.94       388\n",
      "Improper Mask       0.92      0.94      0.93       156\n",
      "\n",
      "     accuracy                           0.92       769\n",
      "    macro avg       0.91      0.92      0.92       769\n",
      " weighted avg       0.92      0.92      0.92       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5640 | Train Acc: 0.7918 | Val Loss: 0.3952 | Val Acc: 0.8622 | Val F1: 0.8603 | Time: 4.50s\n",
      "Epoch 2/5 | Train Loss: 0.2796 | Train Acc: 0.9091 | Val Loss: 0.3768 | Val Acc: 0.9012 | Val F1: 0.8989 | Time: 4.67s\n",
      "Epoch 3/5 | Train Loss: 0.2053 | Train Acc: 0.9250 | Val Loss: 0.3016 | Val Acc: 0.8921 | Val F1: 0.8935 | Time: 4.53s\n",
      "Epoch 4/5 | Train Loss: 0.1348 | Train Acc: 0.9584 | Val Loss: 0.3287 | Val Acc: 0.8908 | Val F1: 0.8895 | Time: 4.69s\n",
      "Epoch 5/5 | Train Loss: 0.0942 | Train Acc: 0.9717 | Val Loss: 0.1834 | Val Acc: 0.9441 | Val F1: 0.9439 | Time: 4.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 17:59:58,763] Trial 10 finished with value: 0.9282762231266781 and parameters: {'backbone': 'resnet18', 'batch_size': 16, 'learning_rate': 0.0006746377252925518, 'weight_decay': 4.939713749567097e-05, 'use_class_weights': True, 'scheduler_type': 'reduce_on_plateau', 'freeze_ratio': 0.5060619611170866}. Best is trial 5 with value: 0.9417877830881732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9441 | Precision: 0.9441 | Recall: 0.9441 | F1: 0.9439\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.94      0.90      0.92       225\n",
      "         Mask       0.96      0.97      0.96       388\n",
      "Improper Mask       0.92      0.94      0.93       156\n",
      "\n",
      "     accuracy                           0.94       769\n",
      "    macro avg       0.94      0.94      0.94       769\n",
      " weighted avg       0.94      0.94      0.94       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9283\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.89      0.90      1128\n",
      "         Mask       0.95      0.96      0.95      1940\n",
      "Improper Mask       0.91      0.92      0.91       780\n",
      "\n",
      "     accuracy                           0.93      3848\n",
      "    macro avg       0.92      0.92      0.92      3848\n",
      " weighted avg       0.93      0.93      0.93      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5911 | Train Acc: 0.7719 | Val Loss: 0.3380 | Val Acc: 0.8740 | Val F1: 0.8742 | Time: 4.38s\n",
      "Epoch 2/5 | Train Loss: 0.3214 | Train Acc: 0.8811 | Val Loss: 0.3696 | Val Acc: 0.8870 | Val F1: 0.8866 | Time: 5.51s\n",
      "Epoch 3/5 | Train Loss: 0.1774 | Train Acc: 0.9386 | Val Loss: 0.2571 | Val Acc: 0.9260 | Val F1: 0.9259 | Time: 4.38s\n",
      "Epoch 4/5 | Train Loss: 0.0745 | Train Acc: 0.9750 | Val Loss: 0.3012 | Val Acc: 0.9338 | Val F1: 0.9331 | Time: 4.52s\n",
      "Epoch 5/5 | Train Loss: 0.0514 | Train Acc: 0.9825 | Val Loss: 0.2847 | Val Acc: 0.9364 | Val F1: 0.9357 | Time: 4.38s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9260 | Precision: 0.9298 | Recall: 0.9260 | F1: 0.9259\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.86      0.95      0.90       226\n",
      "         Mask       0.95      0.95      0.95       388\n",
      "Improper Mask       0.98      0.83      0.90       156\n",
      "\n",
      "     accuracy                           0.93       770\n",
      "    macro avg       0.93      0.91      0.92       770\n",
      " weighted avg       0.93      0.93      0.93       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6070 | Train Acc: 0.7654 | Val Loss: 0.4755 | Val Acc: 0.8143 | Val F1: 0.8166 | Time: 4.41s\n",
      "Epoch 2/5 | Train Loss: 0.3000 | Train Acc: 0.8957 | Val Loss: 0.4060 | Val Acc: 0.8727 | Val F1: 0.8687 | Time: 4.49s\n",
      "Epoch 3/5 | Train Loss: 0.1497 | Train Acc: 0.9493 | Val Loss: 0.4186 | Val Acc: 0.8740 | Val F1: 0.8738 | Time: 4.38s\n",
      "Epoch 4/5 | Train Loss: 0.0834 | Train Acc: 0.9721 | Val Loss: 0.3365 | Val Acc: 0.9130 | Val F1: 0.9128 | Time: 5.50s\n",
      "Epoch 5/5 | Train Loss: 0.0469 | Train Acc: 0.9854 | Val Loss: 0.3350 | Val Acc: 0.9312 | Val F1: 0.9311 | Time: 4.48s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9312 | Precision: 0.9311 | Recall: 0.9312 | F1: 0.9311\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.90      0.90       226\n",
      "         Mask       0.94      0.95      0.94       388\n",
      "Improper Mask       0.94      0.93      0.94       156\n",
      "\n",
      "     accuracy                           0.93       770\n",
      "    macro avg       0.93      0.93      0.93       770\n",
      " weighted avg       0.93      0.93      0.93       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5864 | Train Acc: 0.7736 | Val Loss: 0.3963 | Val Acc: 0.8532 | Val F1: 0.8502 | Time: 4.33s\n",
      "Epoch 2/5 | Train Loss: 0.2943 | Train Acc: 0.8866 | Val Loss: 0.3886 | Val Acc: 0.8883 | Val F1: 0.8872 | Time: 4.38s\n",
      "Epoch 3/5 | Train Loss: 0.1737 | Train Acc: 0.9415 | Val Loss: 0.3641 | Val Acc: 0.9065 | Val F1: 0.9060 | Time: 4.56s\n",
      "Epoch 4/5 | Train Loss: 0.0855 | Train Acc: 0.9724 | Val Loss: 0.3109 | Val Acc: 0.9078 | Val F1: 0.9079 | Time: 4.43s\n",
      "Epoch 5/5 | Train Loss: 0.0466 | Train Acc: 0.9847 | Val Loss: 0.2692 | Val Acc: 0.9234 | Val F1: 0.9235 | Time: 4.43s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9234 | Precision: 0.9244 | Recall: 0.9234 | F1: 0.9235\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.87      0.91      0.89       226\n",
      "         Mask       0.94      0.95      0.95       388\n",
      "Improper Mask       0.95      0.88      0.91       156\n",
      "\n",
      "     accuracy                           0.92       770\n",
      "    macro avg       0.92      0.91      0.92       770\n",
      " weighted avg       0.92      0.92      0.92       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5946 | Train Acc: 0.7639 | Val Loss: 0.4020 | Val Acc: 0.8492 | Val F1: 0.8478 | Time: 5.57s\n",
      "Epoch 2/5 | Train Loss: 0.3142 | Train Acc: 0.8889 | Val Loss: 0.2539 | Val Acc: 0.9051 | Val F1: 0.9023 | Time: 4.80s\n",
      "Epoch 3/5 | Train Loss: 0.1633 | Train Acc: 0.9415 | Val Loss: 0.3209 | Val Acc: 0.9168 | Val F1: 0.9165 | Time: 4.50s\n",
      "Epoch 4/5 | Train Loss: 0.1057 | Train Acc: 0.9627 | Val Loss: 0.2558 | Val Acc: 0.9025 | Val F1: 0.9036 | Time: 4.39s\n",
      "Epoch 5/5 | Train Loss: 0.0490 | Train Acc: 0.9831 | Val Loss: 0.2668 | Val Acc: 0.9259 | Val F1: 0.9255 | Time: 4.39s\n",
      "Early stopping at epoch 5\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9051 | Precision: 0.9065 | Recall: 0.9051 | F1: 0.9023\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.92      0.75      0.83       225\n",
      "         Mask       0.91      0.97      0.94       388\n",
      "Improper Mask       0.87      0.96      0.91       156\n",
      "\n",
      "     accuracy                           0.91       769\n",
      "    macro avg       0.90      0.89      0.89       769\n",
      " weighted avg       0.91      0.91      0.90       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.6091 | Train Acc: 0.7671 | Val Loss: 0.4138 | Val Acc: 0.8388 | Val F1: 0.8421 | Time: 4.41s\n",
      "Epoch 2/5 | Train Loss: 0.2823 | Train Acc: 0.9000 | Val Loss: 0.4054 | Val Acc: 0.8700 | Val F1: 0.8667 | Time: 4.41s\n",
      "Epoch 3/5 | Train Loss: 0.1741 | Train Acc: 0.9367 | Val Loss: 0.3649 | Val Acc: 0.8830 | Val F1: 0.8835 | Time: 5.48s\n",
      "Epoch 4/5 | Train Loss: 0.0837 | Train Acc: 0.9678 | Val Loss: 0.3259 | Val Acc: 0.9051 | Val F1: 0.9058 | Time: 4.44s\n",
      "Epoch 5/5 | Train Loss: 0.0482 | Train Acc: 0.9857 | Val Loss: 0.3137 | Val Acc: 0.9077 | Val F1: 0.9074 | Time: 4.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 18:01:59,645] Trial 11 finished with value: 0.918652660733285 and parameters: {'backbone': 'resnet18', 'batch_size': 16, 'learning_rate': 0.0008332334231893163, 'weight_decay': 0.0002733762389478881, 'use_class_weights': True, 'scheduler_type': 'cosine', 'freeze_ratio': 0.7822929774689608}. Best is trial 5 with value: 0.9417877830881732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9077 | Precision: 0.9072 | Recall: 0.9077 | F1: 0.9074\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.87      0.85      0.86       225\n",
      "         Mask       0.93      0.95      0.94       388\n",
      "Improper Mask       0.91      0.88      0.90       156\n",
      "\n",
      "     accuracy                           0.91       769\n",
      "    macro avg       0.90      0.90      0.90       769\n",
      " weighted avg       0.91      0.91      0.91       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9187\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.88      0.87      0.88      1128\n",
      "         Mask       0.93      0.96      0.94      1940\n",
      "Improper Mask       0.93      0.89      0.91       780\n",
      "\n",
      "     accuracy                           0.92      3848\n",
      "    macro avg       0.92      0.91      0.91      3848\n",
      " weighted avg       0.92      0.92      0.92      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5793 | Train Acc: 0.7726 | Val Loss: 0.3213 | Val Acc: 0.8896 | Val F1: 0.8893 | Time: 4.29s\n",
      "Epoch 2/5 | Train Loss: 0.2347 | Train Acc: 0.9146 | Val Loss: 0.2881 | Val Acc: 0.9182 | Val F1: 0.9184 | Time: 4.38s\n",
      "Epoch 3/5 | Train Loss: 0.1222 | Train Acc: 0.9591 | Val Loss: 0.3308 | Val Acc: 0.9156 | Val F1: 0.9151 | Time: 4.33s\n",
      "Epoch 4/5 | Train Loss: 0.0768 | Train Acc: 0.9737 | Val Loss: 0.2403 | Val Acc: 0.9429 | Val F1: 0.9427 | Time: 4.31s\n",
      "Epoch 5/5 | Train Loss: 0.0427 | Train Acc: 0.9867 | Val Loss: 0.2279 | Val Acc: 0.9494 | Val F1: 0.9490 | Time: 5.48s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9494 | Precision: 0.9494 | Recall: 0.9494 | F1: 0.9490\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.94      0.92      0.93       226\n",
      "         Mask       0.95      0.98      0.97       388\n",
      "Improper Mask       0.96      0.91      0.93       156\n",
      "\n",
      "     accuracy                           0.95       770\n",
      "    macro avg       0.95      0.94      0.94       770\n",
      " weighted avg       0.95      0.95      0.95       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5948 | Train Acc: 0.7641 | Val Loss: 0.3911 | Val Acc: 0.8740 | Val F1: 0.8732 | Time: 4.32s\n",
      "Epoch 2/5 | Train Loss: 0.2528 | Train Acc: 0.9090 | Val Loss: 0.3927 | Val Acc: 0.8766 | Val F1: 0.8750 | Time: 4.41s\n",
      "Epoch 3/5 | Train Loss: 0.1531 | Train Acc: 0.9454 | Val Loss: 0.2722 | Val Acc: 0.9104 | Val F1: 0.9104 | Time: 4.42s\n",
      "Epoch 4/5 | Train Loss: 0.0621 | Train Acc: 0.9789 | Val Loss: 0.2891 | Val Acc: 0.9208 | Val F1: 0.9206 | Time: 4.40s\n",
      "Epoch 5/5 | Train Loss: 0.0389 | Train Acc: 0.9873 | Val Loss: 0.3069 | Val Acc: 0.9234 | Val F1: 0.9231 | Time: 4.38s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9104 | Precision: 0.9108 | Recall: 0.9104 | F1: 0.9104\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.87      0.88      0.87       226\n",
      "         Mask       0.92      0.94      0.93       388\n",
      "Improper Mask       0.95      0.90      0.92       156\n",
      "\n",
      "     accuracy                           0.91       770\n",
      "    macro avg       0.91      0.90      0.91       770\n",
      " weighted avg       0.91      0.91      0.91       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5657 | Train Acc: 0.7703 | Val Loss: 0.4149 | Val Acc: 0.8662 | Val F1: 0.8654 | Time: 4.39s\n",
      "Epoch 2/5 | Train Loss: 0.2384 | Train Acc: 0.9139 | Val Loss: 0.3387 | Val Acc: 0.8883 | Val F1: 0.8896 | Time: 5.53s\n",
      "Epoch 3/5 | Train Loss: 0.1191 | Train Acc: 0.9584 | Val Loss: 0.3453 | Val Acc: 0.9195 | Val F1: 0.9189 | Time: 4.43s\n",
      "Epoch 4/5 | Train Loss: 0.0614 | Train Acc: 0.9808 | Val Loss: 0.3086 | Val Acc: 0.9299 | Val F1: 0.9296 | Time: 4.26s\n",
      "Epoch 5/5 | Train Loss: 0.0342 | Train Acc: 0.9877 | Val Loss: 0.3034 | Val Acc: 0.9325 | Val F1: 0.9321 | Time: 4.50s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9325 | Precision: 0.9332 | Recall: 0.9325 | F1: 0.9321\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.93      0.89      0.91       226\n",
      "         Mask       0.92      0.97      0.95       388\n",
      "Improper Mask       0.97      0.88      0.92       156\n",
      "\n",
      "     accuracy                           0.93       770\n",
      "    macro avg       0.94      0.92      0.93       770\n",
      " weighted avg       0.93      0.93      0.93       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5774 | Train Acc: 0.7691 | Val Loss: 0.3921 | Val Acc: 0.8544 | Val F1: 0.8560 | Time: 4.43s\n",
      "Epoch 2/5 | Train Loss: 0.2498 | Train Acc: 0.9104 | Val Loss: 0.2729 | Val Acc: 0.8973 | Val F1: 0.8986 | Time: 4.36s\n",
      "Epoch 3/5 | Train Loss: 0.1146 | Train Acc: 0.9571 | Val Loss: 0.2752 | Val Acc: 0.9103 | Val F1: 0.9099 | Time: 4.47s\n",
      "Epoch 4/5 | Train Loss: 0.0481 | Train Acc: 0.9838 | Val Loss: 0.2343 | Val Acc: 0.9285 | Val F1: 0.9289 | Time: 6.16s\n",
      "Epoch 5/5 | Train Loss: 0.0334 | Train Acc: 0.9899 | Val Loss: 0.2133 | Val Acc: 0.9415 | Val F1: 0.9411 | Time: 4.78s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9415 | Precision: 0.9416 | Recall: 0.9415 | F1: 0.9411\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.94      0.88      0.91       225\n",
      "         Mask       0.94      0.97      0.95       388\n",
      "Improper Mask       0.96      0.96      0.96       156\n",
      "\n",
      "     accuracy                           0.94       769\n",
      "    macro avg       0.94      0.94      0.94       769\n",
      " weighted avg       0.94      0.94      0.94       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5766 | Train Acc: 0.7704 | Val Loss: 0.3468 | Val Acc: 0.8687 | Val F1: 0.8661 | Time: 4.17s\n",
      "Epoch 2/5 | Train Loss: 0.2700 | Train Acc: 0.9042 | Val Loss: 0.3165 | Val Acc: 0.8791 | Val F1: 0.8796 | Time: 4.25s\n",
      "Epoch 3/5 | Train Loss: 0.1177 | Train Acc: 0.9627 | Val Loss: 0.3095 | Val Acc: 0.9038 | Val F1: 0.9040 | Time: 4.31s\n",
      "Epoch 4/5 | Train Loss: 0.0552 | Train Acc: 0.9805 | Val Loss: 0.2995 | Val Acc: 0.9038 | Val F1: 0.9039 | Time: 4.40s\n",
      "Epoch 5/5 | Train Loss: 0.0334 | Train Acc: 0.9909 | Val Loss: 0.2788 | Val Acc: 0.9129 | Val F1: 0.9136 | Time: 4.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 18:03:59,762] Trial 12 finished with value: 0.9293128198199719 and parameters: {'backbone': 'resnet18', 'batch_size': 16, 'learning_rate': 0.0003067691543425867, 'weight_decay': 0.0009889552999047873, 'use_class_weights': True, 'scheduler_type': 'cosine', 'freeze_ratio': 0.7612012640576854}. Best is trial 5 with value: 0.9417877830881732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9129 | Precision: 0.9156 | Recall: 0.9129 | F1: 0.9136\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.84      0.91      0.87       225\n",
      "         Mask       0.95      0.91      0.93       388\n",
      "Improper Mask       0.94      0.93      0.93       156\n",
      "\n",
      "     accuracy                           0.91       769\n",
      "    macro avg       0.91      0.92      0.91       769\n",
      " weighted avg       0.92      0.91      0.91       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9293\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.90      0.90      1128\n",
      "         Mask       0.94      0.95      0.95      1940\n",
      "Improper Mask       0.95      0.92      0.93       780\n",
      "\n",
      "     accuracy                           0.93      3848\n",
      "    macro avg       0.93      0.92      0.93      3848\n",
      " weighted avg       0.93      0.93      0.93      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5610 | Train Acc: 0.7758 | Val Loss: 0.2903 | Val Acc: 0.9013 | Val F1: 0.9021 | Time: 4.40s\n",
      "Epoch 2/5 | Train Loss: 0.2509 | Train Acc: 0.9038 | Val Loss: 0.2208 | Val Acc: 0.9377 | Val F1: 0.9377 | Time: 4.41s\n",
      "Epoch 3/5 | Train Loss: 0.1144 | Train Acc: 0.9568 | Val Loss: 0.2460 | Val Acc: 0.9312 | Val F1: 0.9311 | Time: 4.48s\n",
      "Epoch 4/5 | Train Loss: 0.0840 | Train Acc: 0.9743 | Val Loss: 0.1811 | Val Acc: 0.9481 | Val F1: 0.9478 | Time: 4.42s\n",
      "Epoch 5/5 | Train Loss: 0.0329 | Train Acc: 0.9903 | Val Loss: 0.1986 | Val Acc: 0.9545 | Val F1: 0.9544 | Time: 4.43s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9481 | Precision: 0.9503 | Recall: 0.9481 | F1: 0.9478\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.96      0.93       226\n",
      "         Mask       0.96      0.97      0.97       388\n",
      "Improper Mask       0.99      0.86      0.92       156\n",
      "\n",
      "     accuracy                           0.95       770\n",
      "    macro avg       0.95      0.93      0.94       770\n",
      " weighted avg       0.95      0.95      0.95       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5766 | Train Acc: 0.7765 | Val Loss: 0.3712 | Val Acc: 0.8987 | Val F1: 0.8976 | Time: 4.66s\n",
      "Epoch 2/5 | Train Loss: 0.2502 | Train Acc: 0.9116 | Val Loss: 0.2804 | Val Acc: 0.8896 | Val F1: 0.8913 | Time: 5.61s\n",
      "Epoch 3/5 | Train Loss: 0.1329 | Train Acc: 0.9539 | Val Loss: 0.2573 | Val Acc: 0.9234 | Val F1: 0.9236 | Time: 4.56s\n",
      "Epoch 4/5 | Train Loss: 0.0641 | Train Acc: 0.9828 | Val Loss: 0.2718 | Val Acc: 0.9416 | Val F1: 0.9413 | Time: 4.55s\n",
      "Epoch 5/5 | Train Loss: 0.0277 | Train Acc: 0.9912 | Val Loss: 0.2289 | Val Acc: 0.9364 | Val F1: 0.9364 | Time: 4.57s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9364 | Precision: 0.9368 | Recall: 0.9364 | F1: 0.9364\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.92      0.91       226\n",
      "         Mask       0.94      0.96      0.95       388\n",
      "Improper Mask       0.97      0.91      0.94       156\n",
      "\n",
      "     accuracy                           0.94       770\n",
      "    macro avg       0.94      0.93      0.93       770\n",
      " weighted avg       0.94      0.94      0.94       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5993 | Train Acc: 0.7596 | Val Loss: 0.2871 | Val Acc: 0.8961 | Val F1: 0.8972 | Time: 4.39s\n",
      "Epoch 2/5 | Train Loss: 0.2432 | Train Acc: 0.9178 | Val Loss: 0.3295 | Val Acc: 0.8831 | Val F1: 0.8844 | Time: 4.40s\n",
      "Epoch 3/5 | Train Loss: 0.1216 | Train Acc: 0.9539 | Val Loss: 0.2392 | Val Acc: 0.9312 | Val F1: 0.9315 | Time: 4.49s\n",
      "Epoch 4/5 | Train Loss: 0.0553 | Train Acc: 0.9838 | Val Loss: 0.2078 | Val Acc: 0.9455 | Val F1: 0.9458 | Time: 5.71s\n",
      "Epoch 5/5 | Train Loss: 0.0316 | Train Acc: 0.9896 | Val Loss: 0.1968 | Val Acc: 0.9506 | Val F1: 0.9509 | Time: 4.57s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9506 | Precision: 0.9514 | Recall: 0.9506 | F1: 0.9509\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.94      0.93       226\n",
      "         Mask       0.95      0.96      0.95       388\n",
      "Improper Mask       1.00      0.96      0.98       156\n",
      "\n",
      "     accuracy                           0.95       770\n",
      "    macro avg       0.96      0.95      0.95       770\n",
      " weighted avg       0.95      0.95      0.95       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5657 | Train Acc: 0.7652 | Val Loss: 0.3422 | Val Acc: 0.8674 | Val F1: 0.8665 | Time: 4.62s\n",
      "Epoch 2/5 | Train Loss: 0.2259 | Train Acc: 0.9185 | Val Loss: 0.2050 | Val Acc: 0.9298 | Val F1: 0.9295 | Time: 4.51s\n",
      "Epoch 3/5 | Train Loss: 0.0988 | Train Acc: 0.9597 | Val Loss: 0.4745 | Val Acc: 0.8908 | Val F1: 0.8909 | Time: 4.50s\n",
      "Epoch 4/5 | Train Loss: 0.0699 | Train Acc: 0.9779 | Val Loss: 0.2198 | Val Acc: 0.9402 | Val F1: 0.9404 | Time: 4.62s\n",
      "Epoch 5/5 | Train Loss: 0.0308 | Train Acc: 0.9916 | Val Loss: 0.2079 | Val Acc: 0.9428 | Val F1: 0.9431 | Time: 4.54s\n",
      "Early stopping at epoch 5\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9298 | Precision: 0.9298 | Recall: 0.9298 | F1: 0.9295\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.88      0.89       225\n",
      "         Mask       0.94      0.97      0.95       388\n",
      "Improper Mask       0.96      0.91      0.93       156\n",
      "\n",
      "     accuracy                           0.93       769\n",
      "    macro avg       0.93      0.92      0.92       769\n",
      " weighted avg       0.93      0.93      0.93       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5615 | Train Acc: 0.7853 | Val Loss: 0.3825 | Val Acc: 0.8557 | Val F1: 0.8555 | Time: 5.52s\n",
      "Epoch 2/5 | Train Loss: 0.2461 | Train Acc: 0.9188 | Val Loss: 0.3540 | Val Acc: 0.8570 | Val F1: 0.8586 | Time: 4.60s\n",
      "Epoch 3/5 | Train Loss: 0.1151 | Train Acc: 0.9643 | Val Loss: 0.2204 | Val Acc: 0.9181 | Val F1: 0.9186 | Time: 4.58s\n",
      "Epoch 4/5 | Train Loss: 0.0579 | Train Acc: 0.9821 | Val Loss: 0.2116 | Val Acc: 0.9324 | Val F1: 0.9323 | Time: 4.51s\n",
      "Epoch 5/5 | Train Loss: 0.0333 | Train Acc: 0.9906 | Val Loss: 0.2124 | Val Acc: 0.9350 | Val F1: 0.9347 | Time: 4.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 18:06:01,738] Trial 13 finished with value: 0.9394447165318427 and parameters: {'backbone': 'resnet18', 'batch_size': 16, 'learning_rate': 0.00029606940211992025, 'weight_decay': 0.0002806531832376586, 'use_class_weights': True, 'scheduler_type': 'cosine', 'freeze_ratio': 0.5908556046603515}. Best is trial 5 with value: 0.9417877830881732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9324 | Precision: 0.9323 | Recall: 0.9324 | F1: 0.9323\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.89      0.90       225\n",
      "         Mask       0.94      0.94      0.94       388\n",
      "Improper Mask       0.96      0.96      0.96       156\n",
      "\n",
      "     accuracy                           0.93       769\n",
      "    macro avg       0.93      0.93      0.93       769\n",
      " weighted avg       0.93      0.93      0.93       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9394\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.92      0.91      1128\n",
      "         Mask       0.95      0.96      0.95      1940\n",
      "Improper Mask       0.98      0.92      0.95       780\n",
      "\n",
      "     accuracy                           0.94      3848\n",
      "    macro avg       0.94      0.93      0.94      3848\n",
      " weighted avg       0.94      0.94      0.94      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5419 | Train Acc: 0.7710 | Val Loss: 0.2855 | Val Acc: 0.8831 | Val F1: 0.8829 | Time: 4.06s\n",
      "Epoch 2/5 | Train Loss: 0.1732 | Train Acc: 0.9347 | Val Loss: 0.3973 | Val Acc: 0.8987 | Val F1: 0.8965 | Time: 4.04s\n",
      "Epoch 3/5 | Train Loss: 0.0630 | Train Acc: 0.9786 | Val Loss: 0.3428 | Val Acc: 0.9182 | Val F1: 0.9171 | Time: 5.06s\n",
      "Epoch 4/5 | Train Loss: 0.0367 | Train Acc: 0.9886 | Val Loss: 0.3827 | Val Acc: 0.9117 | Val F1: 0.9115 | Time: 3.80s\n",
      "Early stopping at epoch 4\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.8831 | Precision: 0.8829 | Recall: 0.8831 | F1: 0.8829\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.84      0.86      0.85       226\n",
      "         Mask       0.93      0.93      0.93       388\n",
      "Improper Mask       0.83      0.79      0.81       156\n",
      "\n",
      "     accuracy                           0.88       770\n",
      "    macro avg       0.87      0.86      0.86       770\n",
      " weighted avg       0.88      0.88      0.88       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5245 | Train Acc: 0.7853 | Val Loss: 0.3272 | Val Acc: 0.8740 | Val F1: 0.8740 | Time: 3.97s\n",
      "Epoch 2/5 | Train Loss: 0.1643 | Train Acc: 0.9425 | Val Loss: 0.2956 | Val Acc: 0.8935 | Val F1: 0.8920 | Time: 4.08s\n",
      "Epoch 3/5 | Train Loss: 0.0736 | Train Acc: 0.9753 | Val Loss: 0.3589 | Val Acc: 0.8909 | Val F1: 0.8901 | Time: 3.97s\n",
      "Epoch 4/5 | Train Loss: 0.0626 | Train Acc: 0.9795 | Val Loss: 0.2977 | Val Acc: 0.9078 | Val F1: 0.9073 | Time: 3.99s\n",
      "Epoch 5/5 | Train Loss: 0.0556 | Train Acc: 0.9815 | Val Loss: 0.3114 | Val Acc: 0.9208 | Val F1: 0.9203 | Time: 3.96s\n",
      "Early stopping at epoch 5\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.8935 | Precision: 0.8969 | Recall: 0.8935 | F1: 0.8920\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.87      0.82      0.85       226\n",
      "         Mask       0.88      0.97      0.93       388\n",
      "Improper Mask       0.98      0.79      0.88       156\n",
      "\n",
      "     accuracy                           0.89       770\n",
      "    macro avg       0.91      0.86      0.88       770\n",
      " weighted avg       0.90      0.89      0.89       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5616 | Train Acc: 0.7573 | Val Loss: 0.3012 | Val Acc: 0.8896 | Val F1: 0.8899 | Time: 5.17s\n",
      "Epoch 2/5 | Train Loss: 0.1650 | Train Acc: 0.9412 | Val Loss: 0.2490 | Val Acc: 0.9117 | Val F1: 0.9107 | Time: 4.17s\n",
      "Epoch 3/5 | Train Loss: 0.0499 | Train Acc: 0.9821 | Val Loss: 0.2639 | Val Acc: 0.9221 | Val F1: 0.9222 | Time: 3.99s\n",
      "Epoch 4/5 | Train Loss: 0.0882 | Train Acc: 0.9714 | Val Loss: 0.2901 | Val Acc: 0.9234 | Val F1: 0.9228 | Time: 4.04s\n",
      "Epoch 5/5 | Train Loss: 0.0494 | Train Acc: 0.9821 | Val Loss: 0.3212 | Val Acc: 0.9208 | Val F1: 0.9213 | Time: 4.05s\n",
      "Early stopping at epoch 5\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9117 | Precision: 0.9121 | Recall: 0.9117 | F1: 0.9107\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.84      0.87       226\n",
      "         Mask       0.91      0.97      0.94       388\n",
      "Improper Mask       0.94      0.87      0.90       156\n",
      "\n",
      "     accuracy                           0.91       770\n",
      "    macro avg       0.92      0.89      0.90       770\n",
      " weighted avg       0.91      0.91      0.91       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5498 | Train Acc: 0.7714 | Val Loss: 0.3738 | Val Acc: 0.8583 | Val F1: 0.8604 | Time: 3.91s\n",
      "Epoch 2/5 | Train Loss: 0.1753 | Train Acc: 0.9357 | Val Loss: 0.2485 | Val Acc: 0.9129 | Val F1: 0.9120 | Time: 3.90s\n",
      "Epoch 3/5 | Train Loss: 0.0675 | Train Acc: 0.9802 | Val Loss: 0.3232 | Val Acc: 0.8947 | Val F1: 0.8957 | Time: 3.99s\n",
      "Epoch 4/5 | Train Loss: 0.0766 | Train Acc: 0.9753 | Val Loss: 0.3425 | Val Acc: 0.9116 | Val F1: 0.9088 | Time: 5.21s\n",
      "Epoch 5/5 | Train Loss: 0.0600 | Train Acc: 0.9805 | Val Loss: 0.3683 | Val Acc: 0.9077 | Val F1: 0.9058 | Time: 3.98s\n",
      "Early stopping at epoch 5\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9129 | Precision: 0.9125 | Recall: 0.9129 | F1: 0.9120\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.88      0.83      0.86       225\n",
      "         Mask       0.92      0.97      0.94       388\n",
      "Improper Mask       0.94      0.89      0.91       156\n",
      "\n",
      "     accuracy                           0.91       769\n",
      "    macro avg       0.91      0.90      0.90       769\n",
      " weighted avg       0.91      0.91      0.91       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5169 | Train Acc: 0.7847 | Val Loss: 0.3445 | Val Acc: 0.8583 | Val F1: 0.8609 | Time: 3.93s\n",
      "Epoch 2/5 | Train Loss: 0.1609 | Train Acc: 0.9432 | Val Loss: 0.3490 | Val Acc: 0.8947 | Val F1: 0.8937 | Time: 3.87s\n",
      "Epoch 3/5 | Train Loss: 0.0760 | Train Acc: 0.9734 | Val Loss: 0.3060 | Val Acc: 0.9090 | Val F1: 0.9079 | Time: 3.94s\n",
      "Epoch 4/5 | Train Loss: 0.0570 | Train Acc: 0.9805 | Val Loss: 0.2709 | Val Acc: 0.9077 | Val F1: 0.9081 | Time: 3.97s\n",
      "Epoch 5/5 | Train Loss: 0.0576 | Train Acc: 0.9828 | Val Loss: 0.2415 | Val Acc: 0.9220 | Val F1: 0.9222 | Time: 4.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 18:07:46,179] Trial 14 finished with value: 0.9046324286896459 and parameters: {'backbone': 'resnet18', 'batch_size': 64, 'learning_rate': 0.00028961603572682067, 'weight_decay': 6.821018330793571e-05, 'use_class_weights': False, 'scheduler_type': 'reduce_on_plateau', 'freeze_ratio': 0.5805269296622017}. Best is trial 5 with value: 0.9417877830881732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9220 | Precision: 0.9225 | Recall: 0.9220 | F1: 0.9222\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.87      0.89      0.88       225\n",
      "         Mask       0.95      0.93      0.94       388\n",
      "Improper Mask       0.92      0.94      0.93       156\n",
      "\n",
      "     accuracy                           0.92       769\n",
      "    macro avg       0.92      0.92      0.92       769\n",
      " weighted avg       0.92      0.92      0.92       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9046\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.87      0.85      0.86      1128\n",
      "         Mask       0.92      0.96      0.94      1940\n",
      "Improper Mask       0.92      0.86      0.89       780\n",
      "\n",
      "     accuracy                           0.90      3848\n",
      "    macro avg       0.90      0.89      0.89      3848\n",
      " weighted avg       0.90      0.90      0.90      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5556 | Train Acc: 0.7788 | Val Loss: 0.2936 | Val Acc: 0.9104 | Val F1: 0.9091 | Time: 4.06s\n",
      "Epoch 2/5 | Train Loss: 0.1863 | Train Acc: 0.9324 | Val Loss: 0.3069 | Val Acc: 0.9182 | Val F1: 0.9172 | Time: 5.17s\n",
      "Epoch 3/5 | Train Loss: 0.0640 | Train Acc: 0.9792 | Val Loss: 0.3329 | Val Acc: 0.9286 | Val F1: 0.9280 | Time: 4.07s\n",
      "Epoch 4/5 | Train Loss: 0.0313 | Train Acc: 0.9883 | Val Loss: 0.1970 | Val Acc: 0.9468 | Val F1: 0.9468 | Time: 4.13s\n",
      "Epoch 5/5 | Train Loss: 0.0151 | Train Acc: 0.9968 | Val Loss: 0.1977 | Val Acc: 0.9468 | Val F1: 0.9468 | Time: 4.21s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9468 | Precision: 0.9473 | Recall: 0.9468 | F1: 0.9468\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.95      0.93       226\n",
      "         Mask       0.96      0.96      0.96       388\n",
      "Improper Mask       0.96      0.92      0.94       156\n",
      "\n",
      "     accuracy                           0.95       770\n",
      "    macro avg       0.94      0.94      0.94       770\n",
      " weighted avg       0.95      0.95      0.95       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5316 | Train Acc: 0.7898 | Val Loss: 0.3782 | Val Acc: 0.8545 | Val F1: 0.8553 | Time: 4.06s\n",
      "Epoch 2/5 | Train Loss: 0.1899 | Train Acc: 0.9305 | Val Loss: 0.2691 | Val Acc: 0.9130 | Val F1: 0.9129 | Time: 4.02s\n",
      "Epoch 3/5 | Train Loss: 0.0741 | Train Acc: 0.9737 | Val Loss: 0.2576 | Val Acc: 0.9260 | Val F1: 0.9265 | Time: 4.09s\n",
      "Epoch 4/5 | Train Loss: 0.0296 | Train Acc: 0.9880 | Val Loss: 0.2992 | Val Acc: 0.9312 | Val F1: 0.9315 | Time: 5.30s\n",
      "Epoch 5/5 | Train Loss: 0.0168 | Train Acc: 0.9948 | Val Loss: 0.2790 | Val Acc: 0.9390 | Val F1: 0.9389 | Time: 4.24s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9260 | Precision: 0.9282 | Recall: 0.9260 | F1: 0.9265\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.86      0.92      0.89       226\n",
      "         Mask       0.96      0.92      0.94       388\n",
      "Improper Mask       0.95      0.95      0.95       156\n",
      "\n",
      "     accuracy                           0.93       770\n",
      "    macro avg       0.92      0.93      0.93       770\n",
      " weighted avg       0.93      0.93      0.93       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5502 | Train Acc: 0.7827 | Val Loss: 0.3730 | Val Acc: 0.8844 | Val F1: 0.8833 | Time: 4.05s\n",
      "Epoch 2/5 | Train Loss: 0.1739 | Train Acc: 0.9347 | Val Loss: 0.2237 | Val Acc: 0.9377 | Val F1: 0.9377 | Time: 4.09s\n",
      "Epoch 3/5 | Train Loss: 0.0734 | Train Acc: 0.9776 | Val Loss: 0.2212 | Val Acc: 0.9468 | Val F1: 0.9467 | Time: 4.04s\n",
      "Epoch 4/5 | Train Loss: 0.0331 | Train Acc: 0.9883 | Val Loss: 0.1994 | Val Acc: 0.9519 | Val F1: 0.9519 | Time: 3.98s\n",
      "Epoch 5/5 | Train Loss: 0.0179 | Train Acc: 0.9945 | Val Loss: 0.2013 | Val Acc: 0.9519 | Val F1: 0.9521 | Time: 4.10s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9519 | Precision: 0.9520 | Recall: 0.9519 | F1: 0.9519\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.94      0.94      0.94       226\n",
      "         Mask       0.95      0.97      0.96       388\n",
      "Improper Mask       0.97      0.94      0.95       156\n",
      "\n",
      "     accuracy                           0.95       770\n",
      "    macro avg       0.95      0.95      0.95       770\n",
      " weighted avg       0.95      0.95      0.95       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5297 | Train Acc: 0.7824 | Val Loss: 0.3117 | Val Acc: 0.8934 | Val F1: 0.8937 | Time: 4.19s\n",
      "Epoch 2/5 | Train Loss: 0.1929 | Train Acc: 0.9305 | Val Loss: 0.2324 | Val Acc: 0.9233 | Val F1: 0.9230 | Time: 5.27s\n",
      "Epoch 3/5 | Train Loss: 0.0645 | Train Acc: 0.9756 | Val Loss: 0.2871 | Val Acc: 0.9194 | Val F1: 0.9206 | Time: 4.05s\n",
      "Epoch 4/5 | Train Loss: 0.0259 | Train Acc: 0.9916 | Val Loss: 0.1723 | Val Acc: 0.9480 | Val F1: 0.9484 | Time: 4.06s\n",
      "Epoch 5/5 | Train Loss: 0.0145 | Train Acc: 0.9964 | Val Loss: 0.1501 | Val Acc: 0.9545 | Val F1: 0.9547 | Time: 4.23s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9545 | Precision: 0.9555 | Recall: 0.9545 | F1: 0.9547\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.95      0.93       225\n",
      "         Mask       0.97      0.95      0.96       388\n",
      "Improper Mask       0.98      0.97      0.97       156\n",
      "\n",
      "     accuracy                           0.95       769\n",
      "    macro avg       0.95      0.96      0.95       769\n",
      " weighted avg       0.96      0.95      0.95       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5425 | Train Acc: 0.7850 | Val Loss: 0.4649 | Val Acc: 0.8270 | Val F1: 0.8319 | Time: 4.12s\n",
      "Epoch 2/5 | Train Loss: 0.1754 | Train Acc: 0.9370 | Val Loss: 0.2476 | Val Acc: 0.9116 | Val F1: 0.9125 | Time: 4.18s\n",
      "Epoch 3/5 | Train Loss: 0.0678 | Train Acc: 0.9763 | Val Loss: 0.2532 | Val Acc: 0.9337 | Val F1: 0.9332 | Time: 4.13s\n",
      "Epoch 4/5 | Train Loss: 0.0392 | Train Acc: 0.9877 | Val Loss: 0.2299 | Val Acc: 0.9324 | Val F1: 0.9328 | Time: 5.33s\n",
      "Epoch 5/5 | Train Loss: 0.0207 | Train Acc: 0.9958 | Val Loss: 0.2081 | Val Acc: 0.9454 | Val F1: 0.9454 | Time: 4.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 18:09:38,963] Trial 15 finished with value: 0.9449090571327243 and parameters: {'backbone': 'resnet18', 'batch_size': 32, 'learning_rate': 0.0003131594569593978, 'weight_decay': 0.000299450113017805, 'use_class_weights': True, 'scheduler_type': 'cosine', 'freeze_ratio': 0.5087792159637191}. Best is trial 15 with value: 0.9449090571327243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9454 | Precision: 0.9453 | Recall: 0.9454 | F1: 0.9454\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.92      0.92      0.92       225\n",
      "         Mask       0.95      0.96      0.95       388\n",
      "Improper Mask       0.96      0.96      0.96       156\n",
      "\n",
      "     accuracy                           0.95       769\n",
      "    macro avg       0.94      0.94      0.94       769\n",
      " weighted avg       0.95      0.95      0.95       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9449\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.94      0.92      1128\n",
      "         Mask       0.96      0.95      0.96      1940\n",
      "Improper Mask       0.96      0.95      0.95       780\n",
      "\n",
      "     accuracy                           0.94      3848\n",
      "    macro avg       0.94      0.94      0.94      3848\n",
      " weighted avg       0.95      0.94      0.95      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5570 | Train Acc: 0.7680 | Val Loss: 0.2670 | Val Acc: 0.9013 | Val F1: 0.8987 | Time: 4.00s\n",
      "Epoch 2/5 | Train Loss: 0.1754 | Train Acc: 0.9415 | Val Loss: 0.1928 | Val Acc: 0.9377 | Val F1: 0.9369 | Time: 4.08s\n",
      "Epoch 3/5 | Train Loss: 0.0569 | Train Acc: 0.9847 | Val Loss: 0.2001 | Val Acc: 0.9338 | Val F1: 0.9333 | Time: 4.17s\n",
      "Epoch 4/5 | Train Loss: 0.0250 | Train Acc: 0.9938 | Val Loss: 0.1800 | Val Acc: 0.9364 | Val F1: 0.9357 | Time: 4.14s\n",
      "Epoch 5/5 | Train Loss: 0.0132 | Train Acc: 0.9964 | Val Loss: 0.1898 | Val Acc: 0.9403 | Val F1: 0.9396 | Time: 4.16s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9364 | Precision: 0.9368 | Recall: 0.9364 | F1: 0.9357\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.93      0.90      0.91       226\n",
      "         Mask       0.93      0.98      0.96       388\n",
      "Improper Mask       0.96      0.87      0.91       156\n",
      "\n",
      "     accuracy                           0.94       770\n",
      "    macro avg       0.94      0.92      0.93       770\n",
      " weighted avg       0.94      0.94      0.94       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5662 | Train Acc: 0.7693 | Val Loss: 0.2975 | Val Acc: 0.8844 | Val F1: 0.8840 | Time: 4.19s\n",
      "Epoch 2/5 | Train Loss: 0.1764 | Train Acc: 0.9357 | Val Loss: 0.2261 | Val Acc: 0.9156 | Val F1: 0.9156 | Time: 5.22s\n",
      "Epoch 3/5 | Train Loss: 0.0707 | Train Acc: 0.9786 | Val Loss: 0.2093 | Val Acc: 0.9299 | Val F1: 0.9298 | Time: 4.04s\n",
      "Epoch 4/5 | Train Loss: 0.0247 | Train Acc: 0.9958 | Val Loss: 0.2046 | Val Acc: 0.9338 | Val F1: 0.9337 | Time: 4.05s\n",
      "Epoch 5/5 | Train Loss: 0.0121 | Train Acc: 0.9994 | Val Loss: 0.2096 | Val Acc: 0.9325 | Val F1: 0.9323 | Time: 4.12s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9338 | Precision: 0.9341 | Recall: 0.9338 | F1: 0.9337\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.92      0.92       226\n",
      "         Mask       0.94      0.95      0.95       388\n",
      "Improper Mask       0.95      0.90      0.92       156\n",
      "\n",
      "     accuracy                           0.93       770\n",
      "    macro avg       0.93      0.93      0.93       770\n",
      " weighted avg       0.93      0.93      0.93       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5170 | Train Acc: 0.7801 | Val Loss: 0.2692 | Val Acc: 0.8883 | Val F1: 0.8889 | Time: 4.14s\n",
      "Epoch 2/5 | Train Loss: 0.1632 | Train Acc: 0.9451 | Val Loss: 0.2085 | Val Acc: 0.9208 | Val F1: 0.9210 | Time: 4.08s\n",
      "Epoch 3/5 | Train Loss: 0.0691 | Train Acc: 0.9818 | Val Loss: 0.1782 | Val Acc: 0.9455 | Val F1: 0.9456 | Time: 4.18s\n",
      "Epoch 4/5 | Train Loss: 0.0331 | Train Acc: 0.9896 | Val Loss: 0.1766 | Val Acc: 0.9455 | Val F1: 0.9455 | Time: 5.34s\n",
      "Epoch 5/5 | Train Loss: 0.0157 | Train Acc: 0.9958 | Val Loss: 0.1600 | Val Acc: 0.9390 | Val F1: 0.9390 | Time: 4.20s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9390 | Precision: 0.9393 | Recall: 0.9390 | F1: 0.9390\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.92      0.92       226\n",
      "         Mask       0.95      0.95      0.95       388\n",
      "Improper Mask       0.97      0.92      0.94       156\n",
      "\n",
      "     accuracy                           0.94       770\n",
      "    macro avg       0.94      0.93      0.94       770\n",
      " weighted avg       0.94      0.94      0.94       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5275 | Train Acc: 0.7853 | Val Loss: 0.2396 | Val Acc: 0.9077 | Val F1: 0.9072 | Time: 4.12s\n",
      "Epoch 2/5 | Train Loss: 0.1671 | Train Acc: 0.9399 | Val Loss: 0.2008 | Val Acc: 0.9220 | Val F1: 0.9221 | Time: 4.15s\n",
      "Epoch 3/5 | Train Loss: 0.0587 | Train Acc: 0.9834 | Val Loss: 0.1895 | Val Acc: 0.9428 | Val F1: 0.9427 | Time: 4.12s\n",
      "Epoch 4/5 | Train Loss: 0.0237 | Train Acc: 0.9942 | Val Loss: 0.1940 | Val Acc: 0.9428 | Val F1: 0.9426 | Time: 4.19s\n",
      "Epoch 5/5 | Train Loss: 0.0134 | Train Acc: 0.9974 | Val Loss: 0.1724 | Val Acc: 0.9402 | Val F1: 0.9398 | Time: 4.11s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9402 | Precision: 0.9401 | Recall: 0.9402 | F1: 0.9398\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.90      0.91       225\n",
      "         Mask       0.95      0.98      0.96       388\n",
      "Improper Mask       0.96      0.90      0.93       156\n",
      "\n",
      "     accuracy                           0.94       769\n",
      "    macro avg       0.94      0.93      0.93       769\n",
      " weighted avg       0.94      0.94      0.94       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5483 | Train Acc: 0.7714 | Val Loss: 0.3130 | Val Acc: 0.8700 | Val F1: 0.8712 | Time: 5.39s\n",
      "Epoch 2/5 | Train Loss: 0.1736 | Train Acc: 0.9402 | Val Loss: 0.2371 | Val Acc: 0.9103 | Val F1: 0.9105 | Time: 4.29s\n",
      "Epoch 3/5 | Train Loss: 0.0539 | Train Acc: 0.9841 | Val Loss: 0.2791 | Val Acc: 0.9220 | Val F1: 0.9207 | Time: 4.12s\n",
      "Epoch 4/5 | Train Loss: 0.0214 | Train Acc: 0.9964 | Val Loss: 0.1911 | Val Acc: 0.9298 | Val F1: 0.9299 | Time: 3.95s\n",
      "Epoch 5/5 | Train Loss: 0.0127 | Train Acc: 0.9974 | Val Loss: 0.1812 | Val Acc: 0.9311 | Val F1: 0.9309 | Time: 4.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 18:11:31,361] Trial 16 finished with value: 0.9360704575008867 and parameters: {'backbone': 'resnet18', 'batch_size': 32, 'learning_rate': 0.00017273208663745886, 'weight_decay': 0.00030060949994479473, 'use_class_weights': False, 'scheduler_type': 'cosine', 'freeze_ratio': 0.5043956756975085}. Best is trial 15 with value: 0.9449090571327243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9311 | Precision: 0.9309 | Recall: 0.9311 | F1: 0.9309\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.88      0.89       225\n",
      "         Mask       0.94      0.95      0.95       388\n",
      "Improper Mask       0.95      0.94      0.95       156\n",
      "\n",
      "     accuracy                           0.93       769\n",
      "    macro avg       0.93      0.93      0.93       769\n",
      " weighted avg       0.93      0.93      0.93       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9361\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.91      0.91      1128\n",
      "         Mask       0.94      0.96      0.95      1940\n",
      "Improper Mask       0.96      0.91      0.93       780\n",
      "\n",
      "     accuracy                           0.94      3848\n",
      "    macro avg       0.94      0.93      0.93      3848\n",
      " weighted avg       0.94      0.94      0.94      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5267 | Train Acc: 0.8103 | Val Loss: 0.3378 | Val Acc: 0.8753 | Val F1: 0.8772 | Time: 4.07s\n",
      "Epoch 2/5 | Train Loss: 0.1991 | Train Acc: 0.9295 | Val Loss: 0.2966 | Val Acc: 0.9078 | Val F1: 0.9086 | Time: 4.10s\n",
      "Epoch 3/5 | Train Loss: 0.1093 | Train Acc: 0.9662 | Val Loss: 0.2651 | Val Acc: 0.9286 | Val F1: 0.9287 | Time: 4.16s\n",
      "Epoch 4/5 | Train Loss: 0.0458 | Train Acc: 0.9834 | Val Loss: 0.2168 | Val Acc: 0.9532 | Val F1: 0.9531 | Time: 4.22s\n",
      "Epoch 5/5 | Train Loss: 0.0156 | Train Acc: 0.9964 | Val Loss: 0.2092 | Val Acc: 0.9519 | Val F1: 0.9520 | Time: 4.21s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9519 | Precision: 0.9528 | Recall: 0.9519 | F1: 0.9520\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.92      0.95      0.93       226\n",
      "         Mask       0.96      0.97      0.96       388\n",
      "Improper Mask       0.99      0.91      0.95       156\n",
      "\n",
      "     accuracy                           0.95       770\n",
      "    macro avg       0.95      0.94      0.95       770\n",
      " weighted avg       0.95      0.95      0.95       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5289 | Train Acc: 0.7950 | Val Loss: 0.4287 | Val Acc: 0.8519 | Val F1: 0.8446 | Time: 4.11s\n",
      "Epoch 2/5 | Train Loss: 0.1812 | Train Acc: 0.9350 | Val Loss: 0.2479 | Val Acc: 0.9195 | Val F1: 0.9195 | Time: 5.57s\n",
      "Epoch 3/5 | Train Loss: 0.0949 | Train Acc: 0.9633 | Val Loss: 0.2627 | Val Acc: 0.9195 | Val F1: 0.9201 | Time: 4.48s\n",
      "Epoch 4/5 | Train Loss: 0.0337 | Train Acc: 0.9877 | Val Loss: 0.2121 | Val Acc: 0.9468 | Val F1: 0.9469 | Time: 4.45s\n",
      "Epoch 5/5 | Train Loss: 0.0122 | Train Acc: 0.9974 | Val Loss: 0.2420 | Val Acc: 0.9455 | Val F1: 0.9452 | Time: 4.16s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9468 | Precision: 0.9474 | Recall: 0.9468 | F1: 0.9469\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.94      0.92       226\n",
      "         Mask       0.96      0.95      0.96       388\n",
      "Improper Mask       0.97      0.95      0.96       156\n",
      "\n",
      "     accuracy                           0.95       770\n",
      "    macro avg       0.95      0.95      0.95       770\n",
      " weighted avg       0.95      0.95      0.95       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5241 | Train Acc: 0.7856 | Val Loss: 0.4236 | Val Acc: 0.8338 | Val F1: 0.8361 | Time: 4.12s\n",
      "Epoch 2/5 | Train Loss: 0.1995 | Train Acc: 0.9305 | Val Loss: 0.2298 | Val Acc: 0.9156 | Val F1: 0.9158 | Time: 4.01s\n",
      "Epoch 3/5 | Train Loss: 0.1092 | Train Acc: 0.9613 | Val Loss: 0.2814 | Val Acc: 0.9078 | Val F1: 0.9087 | Time: 4.01s\n",
      "Epoch 4/5 | Train Loss: 0.0441 | Train Acc: 0.9834 | Val Loss: 0.1663 | Val Acc: 0.9506 | Val F1: 0.9507 | Time: 4.01s\n",
      "Epoch 5/5 | Train Loss: 0.0129 | Train Acc: 0.9964 | Val Loss: 0.1756 | Val Acc: 0.9519 | Val F1: 0.9520 | Time: 4.88s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9506 | Precision: 0.9508 | Recall: 0.9506 | F1: 0.9507\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.93      0.94      0.93       226\n",
      "         Mask       0.96      0.95      0.96       388\n",
      "Improper Mask       0.96      0.97      0.96       156\n",
      "\n",
      "     accuracy                           0.95       770\n",
      "    macro avg       0.95      0.95      0.95       770\n",
      " weighted avg       0.95      0.95      0.95       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5199 | Train Acc: 0.7899 | Val Loss: 0.2660 | Val Acc: 0.9129 | Val F1: 0.9131 | Time: 4.19s\n",
      "Epoch 2/5 | Train Loss: 0.2043 | Train Acc: 0.9253 | Val Loss: 0.2393 | Val Acc: 0.9298 | Val F1: 0.9291 | Time: 4.16s\n",
      "Epoch 3/5 | Train Loss: 0.0813 | Train Acc: 0.9708 | Val Loss: 0.2061 | Val Acc: 0.9311 | Val F1: 0.9314 | Time: 4.09s\n",
      "Epoch 4/5 | Train Loss: 0.0462 | Train Acc: 0.9825 | Val Loss: 0.2006 | Val Acc: 0.9389 | Val F1: 0.9390 | Time: 4.14s\n",
      "Epoch 5/5 | Train Loss: 0.0273 | Train Acc: 0.9916 | Val Loss: 0.2129 | Val Acc: 0.9467 | Val F1: 0.9468 | Time: 4.22s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9389 | Precision: 0.9399 | Recall: 0.9389 | F1: 0.9390\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.93      0.91      0.92       225\n",
      "         Mask       0.97      0.94      0.95       388\n",
      "Improper Mask       0.89      0.97      0.93       156\n",
      "\n",
      "     accuracy                           0.94       769\n",
      "    macro avg       0.93      0.94      0.93       769\n",
      " weighted avg       0.94      0.94      0.94       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5368 | Train Acc: 0.7869 | Val Loss: 0.4089 | Val Acc: 0.8765 | Val F1: 0.8735 | Time: 4.12s\n",
      "Epoch 2/5 | Train Loss: 0.1947 | Train Acc: 0.9315 | Val Loss: 0.2372 | Val Acc: 0.9181 | Val F1: 0.9181 | Time: 5.42s\n",
      "Epoch 3/5 | Train Loss: 0.0910 | Train Acc: 0.9714 | Val Loss: 0.2481 | Val Acc: 0.9233 | Val F1: 0.9230 | Time: 4.22s\n",
      "Epoch 4/5 | Train Loss: 0.0390 | Train Acc: 0.9847 | Val Loss: 0.2060 | Val Acc: 0.9402 | Val F1: 0.9399 | Time: 4.38s\n",
      "Epoch 5/5 | Train Loss: 0.0168 | Train Acc: 0.9929 | Val Loss: 0.1909 | Val Acc: 0.9415 | Val F1: 0.9413 | Time: 4.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 18:13:24,263] Trial 17 finished with value: 0.945942951716684 and parameters: {'backbone': 'resnet18', 'batch_size': 32, 'learning_rate': 0.00047727527324339177, 'weight_decay': 0.00016745238338472984, 'use_class_weights': True, 'scheduler_type': 'cosine', 'freeze_ratio': 0.539003338255835}. Best is trial 17 with value: 0.945942951716684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9415 | Precision: 0.9417 | Recall: 0.9415 | F1: 0.9413\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.90      0.91       225\n",
      "         Mask       0.96      0.94      0.95       388\n",
      "Improper Mask       0.93      0.99      0.96       156\n",
      "\n",
      "     accuracy                           0.94       769\n",
      "    macro avg       0.94      0.95      0.94       769\n",
      " weighted avg       0.94      0.94      0.94       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9459\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.92      0.93      0.92      1128\n",
      "         Mask       0.96      0.95      0.96      1940\n",
      "Improper Mask       0.95      0.96      0.95       780\n",
      "\n",
      "     accuracy                           0.95      3848\n",
      "    macro avg       0.94      0.95      0.94      3848\n",
      " weighted avg       0.95      0.95      0.95      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0725 | Train Acc: 0.4415 | Val Loss: 0.9234 | Val Acc: 0.6519 | Val F1: 0.6542 | Time: 4.04s\n",
      "Epoch 2/5 | Train Loss: 0.8735 | Train Acc: 0.6131 | Val Loss: 0.7729 | Val Acc: 0.7468 | Val F1: 0.7386 | Time: 4.37s\n",
      "Epoch 3/5 | Train Loss: 0.7432 | Train Acc: 0.7235 | Val Loss: 0.6645 | Val Acc: 0.7831 | Val F1: 0.7766 | Time: 4.14s\n",
      "Epoch 4/5 | Train Loss: 0.6320 | Train Acc: 0.7758 | Val Loss: 0.5889 | Val Acc: 0.7987 | Val F1: 0.7945 | Time: 5.25s\n",
      "Epoch 5/5 | Train Loss: 0.5326 | Train Acc: 0.8148 | Val Loss: 0.5299 | Val Acc: 0.8299 | Val F1: 0.8280 | Time: 4.25s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.8299 | Precision: 0.8277 | Recall: 0.8299 | F1: 0.8280\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.76      0.74      0.75       226\n",
      "         Mask       0.88      0.92      0.90       388\n",
      "Improper Mask       0.81      0.73      0.77       156\n",
      "\n",
      "     accuracy                           0.83       770\n",
      "    macro avg       0.81      0.80      0.80       770\n",
      " weighted avg       0.83      0.83      0.83       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0821 | Train Acc: 0.3684 | Val Loss: 0.9122 | Val Acc: 0.6987 | Val F1: 0.6947 | Time: 4.14s\n",
      "Epoch 2/5 | Train Loss: 0.8796 | Train Acc: 0.6098 | Val Loss: 0.7647 | Val Acc: 0.7597 | Val F1: 0.7446 | Time: 3.89s\n",
      "Epoch 3/5 | Train Loss: 0.7485 | Train Acc: 0.7118 | Val Loss: 0.6736 | Val Acc: 0.7909 | Val F1: 0.7757 | Time: 4.09s\n",
      "Epoch 4/5 | Train Loss: 0.6274 | Train Acc: 0.7814 | Val Loss: 0.5990 | Val Acc: 0.8104 | Val F1: 0.8017 | Time: 4.19s\n",
      "Epoch 5/5 | Train Loss: 0.5512 | Train Acc: 0.8064 | Val Loss: 0.5472 | Val Acc: 0.8247 | Val F1: 0.8162 | Time: 4.12s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.8247 | Precision: 0.8319 | Recall: 0.8247 | F1: 0.8162\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.88      0.59      0.71       226\n",
      "         Mask       0.80      0.97      0.88       388\n",
      "Improper Mask       0.84      0.79      0.82       156\n",
      "\n",
      "     accuracy                           0.82       770\n",
      "    macro avg       0.84      0.79      0.80       770\n",
      " weighted avg       0.83      0.82      0.82       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0484 | Train Acc: 0.4318 | Val Loss: 0.9158 | Val Acc: 0.6390 | Val F1: 0.6452 | Time: 4.14s\n",
      "Epoch 2/5 | Train Loss: 0.8568 | Train Acc: 0.6410 | Val Loss: 0.7570 | Val Acc: 0.7584 | Val F1: 0.7540 | Time: 5.37s\n",
      "Epoch 3/5 | Train Loss: 0.7143 | Train Acc: 0.7326 | Val Loss: 0.6466 | Val Acc: 0.7987 | Val F1: 0.7936 | Time: 4.26s\n",
      "Epoch 4/5 | Train Loss: 0.6118 | Train Acc: 0.7856 | Val Loss: 0.5751 | Val Acc: 0.8364 | Val F1: 0.8289 | Time: 4.20s\n",
      "Epoch 5/5 | Train Loss: 0.5325 | Train Acc: 0.8184 | Val Loss: 0.5204 | Val Acc: 0.8416 | Val F1: 0.8368 | Time: 4.10s\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.8416 | Precision: 0.8404 | Recall: 0.8416 | F1: 0.8368\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.81      0.70      0.75       226\n",
      "         Mask       0.85      0.97      0.90       388\n",
      "Improper Mask       0.86      0.74      0.79       156\n",
      "\n",
      "     accuracy                           0.84       770\n",
      "    macro avg       0.84      0.80      0.82       770\n",
      " weighted avg       0.84      0.84      0.84       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0615 | Train Acc: 0.4372 | Val Loss: 0.9143 | Val Acc: 0.6346 | Val F1: 0.6407 | Time: 3.99s\n",
      "Epoch 2/5 | Train Loss: 0.8890 | Train Acc: 0.6116 | Val Loss: 0.7559 | Val Acc: 0.7607 | Val F1: 0.7551 | Time: 4.06s\n",
      "Epoch 3/5 | Train Loss: 0.7524 | Train Acc: 0.7096 | Val Loss: 0.6451 | Val Acc: 0.7971 | Val F1: 0.7921 | Time: 4.06s\n",
      "Epoch 4/5 | Train Loss: 0.6294 | Train Acc: 0.7730 | Val Loss: 0.5678 | Val Acc: 0.8049 | Val F1: 0.8037 | Time: 5.12s\n",
      "Epoch 5/5 | Train Loss: 0.5328 | Train Acc: 0.8243 | Val Loss: 0.5052 | Val Acc: 0.8388 | Val F1: 0.8362 | Time: 4.14s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.8388 | Precision: 0.8361 | Recall: 0.8388 | F1: 0.8362\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.79      0.72      0.75       225\n",
      "         Mask       0.87      0.93      0.90       388\n",
      "Improper Mask       0.82      0.78      0.80       156\n",
      "\n",
      "     accuracy                           0.84       769\n",
      "    macro avg       0.83      0.81      0.82       769\n",
      " weighted avg       0.84      0.84      0.84       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 1.0749 | Train Acc: 0.3988 | Val Loss: 0.9292 | Val Acc: 0.6619 | Val F1: 0.6621 | Time: 4.13s\n",
      "Epoch 2/5 | Train Loss: 0.8988 | Train Acc: 0.5898 | Val Loss: 0.8059 | Val Acc: 0.7061 | Val F1: 0.6986 | Time: 3.95s\n",
      "Epoch 3/5 | Train Loss: 0.7740 | Train Acc: 0.6999 | Val Loss: 0.6917 | Val Acc: 0.7685 | Val F1: 0.7595 | Time: 4.15s\n",
      "Epoch 4/5 | Train Loss: 0.6483 | Train Acc: 0.7671 | Val Loss: 0.6121 | Val Acc: 0.7906 | Val F1: 0.7825 | Time: 4.08s\n",
      "Epoch 5/5 | Train Loss: 0.5752 | Train Acc: 0.8029 | Val Loss: 0.5534 | Val Acc: 0.8114 | Val F1: 0.8020 | Time: 4.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 18:15:16,150] Trial 18 finished with value: 0.8292597909242904 and parameters: {'backbone': 'resnet18', 'batch_size': 32, 'learning_rate': 1.1560203927866087e-05, 'weight_decay': 3.7020344469812105e-05, 'use_class_weights': True, 'scheduler_type': 'reduce_on_plateau', 'freeze_ratio': 0.625383272989948}. Best is trial 17 with value: 0.945942951716684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.8114 | Precision: 0.8095 | Recall: 0.8114 | F1: 0.8020\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.81      0.58      0.68       225\n",
      "         Mask       0.83      0.97      0.89       388\n",
      "Improper Mask       0.77      0.74      0.75       156\n",
      "\n",
      "     accuracy                           0.81       769\n",
      "    macro avg       0.80      0.76      0.77       769\n",
      " weighted avg       0.81      0.81      0.80       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.8293\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.80      0.67      0.73      1128\n",
      "         Mask       0.84      0.95      0.90      1940\n",
      "Improper Mask       0.82      0.76      0.79       780\n",
      "\n",
      "     accuracy                           0.83      3848\n",
      "    macro avg       0.82      0.79      0.80      3848\n",
      " weighted avg       0.83      0.83      0.82      3848\n",
      "\n",
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5296 | Train Acc: 0.8005 | Val Loss: 0.3713 | Val Acc: 0.8649 | Val F1: 0.8678 | Time: 4.11s\n",
      "Epoch 2/5 | Train Loss: 0.1937 | Train Acc: 0.9269 | Val Loss: 0.2085 | Val Acc: 0.9390 | Val F1: 0.9387 | Time: 5.49s\n",
      "Epoch 3/5 | Train Loss: 0.1215 | Train Acc: 0.9594 | Val Loss: 0.2557 | Val Acc: 0.9286 | Val F1: 0.9287 | Time: 4.18s\n",
      "Epoch 4/5 | Train Loss: 0.0735 | Train Acc: 0.9760 | Val Loss: 0.2886 | Val Acc: 0.9390 | Val F1: 0.9385 | Time: 4.00s\n",
      "Epoch 5/5 | Train Loss: 0.0559 | Train Acc: 0.9779 | Val Loss: 0.2031 | Val Acc: 0.9532 | Val F1: 0.9530 | Time: 4.07s\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9532 | Precision: 0.9534 | Recall: 0.9532 | F1: 0.9530\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.94      0.92      0.93       226\n",
      "         Mask       0.95      0.98      0.97       388\n",
      "Improper Mask       0.97      0.92      0.95       156\n",
      "\n",
      "     accuracy                           0.95       770\n",
      "    macro avg       0.96      0.94      0.95       770\n",
      " weighted avg       0.95      0.95      0.95       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5061 | Train Acc: 0.8041 | Val Loss: 0.3145 | Val Acc: 0.8818 | Val F1: 0.8827 | Time: 3.97s\n",
      "Epoch 2/5 | Train Loss: 0.1863 | Train Acc: 0.9337 | Val Loss: 0.3888 | Val Acc: 0.8857 | Val F1: 0.8857 | Time: 4.11s\n",
      "Epoch 3/5 | Train Loss: 0.1216 | Train Acc: 0.9591 | Val Loss: 0.2586 | Val Acc: 0.9221 | Val F1: 0.9221 | Time: 4.18s\n",
      "Epoch 4/5 | Train Loss: 0.0793 | Train Acc: 0.9766 | Val Loss: 0.3675 | Val Acc: 0.9026 | Val F1: 0.9016 | Time: 5.39s\n",
      "Epoch 5/5 | Train Loss: 0.0980 | Train Acc: 0.9584 | Val Loss: 0.2781 | Val Acc: 0.9221 | Val F1: 0.9225 | Time: 4.42s\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9221 | Precision: 0.9222 | Recall: 0.9221 | F1: 0.9221\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.90      0.89      0.89       226\n",
      "         Mask       0.95      0.94      0.94       388\n",
      "Improper Mask       0.90      0.93      0.91       156\n",
      "\n",
      "     accuracy                           0.92       770\n",
      "    macro avg       0.91      0.92      0.92       770\n",
      " weighted avg       0.92      0.92      0.92       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5182 | Train Acc: 0.7924 | Val Loss: 0.3533 | Val Acc: 0.8714 | Val F1: 0.8733 | Time: 4.12s\n",
      "Epoch 2/5 | Train Loss: 0.1703 | Train Acc: 0.9360 | Val Loss: 0.2133 | Val Acc: 0.9169 | Val F1: 0.9174 | Time: 4.21s\n",
      "Epoch 3/5 | Train Loss: 0.1570 | Train Acc: 0.9444 | Val Loss: 0.2266 | Val Acc: 0.9260 | Val F1: 0.9265 | Time: 3.95s\n",
      "Epoch 4/5 | Train Loss: 0.0771 | Train Acc: 0.9717 | Val Loss: 0.2204 | Val Acc: 0.9247 | Val F1: 0.9251 | Time: 3.89s\n",
      "Epoch 5/5 | Train Loss: 0.0489 | Train Acc: 0.9841 | Val Loss: 0.3115 | Val Acc: 0.9403 | Val F1: 0.9401 | Time: 4.11s\n",
      "Early stopping at epoch 5\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9169 | Precision: 0.9191 | Recall: 0.9169 | F1: 0.9174\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.87      0.91      0.89       226\n",
      "         Mask       0.96      0.91      0.94       388\n",
      "Improper Mask       0.89      0.94      0.91       156\n",
      "\n",
      "     accuracy                           0.92       770\n",
      "    macro avg       0.91      0.92      0.91       770\n",
      " weighted avg       0.92      0.92      0.92       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5215 | Train Acc: 0.7915 | Val Loss: 0.4044 | Val Acc: 0.8492 | Val F1: 0.8530 | Time: 5.45s\n",
      "Epoch 2/5 | Train Loss: 0.2156 | Train Acc: 0.9208 | Val Loss: 0.2687 | Val Acc: 0.9220 | Val F1: 0.9217 | Time: 4.37s\n",
      "Epoch 3/5 | Train Loss: 0.1119 | Train Acc: 0.9617 | Val Loss: 0.3008 | Val Acc: 0.9077 | Val F1: 0.9081 | Time: 4.17s\n",
      "Epoch 4/5 | Train Loss: 0.0802 | Train Acc: 0.9727 | Val Loss: 0.2728 | Val Acc: 0.9324 | Val F1: 0.9327 | Time: 4.10s\n",
      "Epoch 5/5 | Train Loss: 0.0958 | Train Acc: 0.9678 | Val Loss: 0.2207 | Val Acc: 0.9467 | Val F1: 0.9463 | Time: 4.04s\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9467 | Precision: 0.9474 | Recall: 0.9467 | F1: 0.9463\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.92      0.93      0.93       225\n",
      "         Mask       0.95      0.98      0.97       388\n",
      "Improper Mask       0.98      0.87      0.92       156\n",
      "\n",
      "     accuracy                           0.95       769\n",
      "    macro avg       0.95      0.93      0.94       769\n",
      " weighted avg       0.95      0.95      0.95       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/5 | Train Loss: 0.5142 | Train Acc: 0.8032 | Val Loss: 0.3799 | Val Acc: 0.8661 | Val F1: 0.8653 | Time: 3.98s\n",
      "Epoch 2/5 | Train Loss: 0.2003 | Train Acc: 0.9285 | Val Loss: 0.2396 | Val Acc: 0.9077 | Val F1: 0.9080 | Time: 4.11s\n",
      "Epoch 3/5 | Train Loss: 0.1126 | Train Acc: 0.9536 | Val Loss: 0.2623 | Val Acc: 0.9025 | Val F1: 0.9034 | Time: 4.25s\n",
      "Epoch 4/5 | Train Loss: 0.0976 | Train Acc: 0.9678 | Val Loss: 0.2555 | Val Acc: 0.9246 | Val F1: 0.9242 | Time: 5.58s\n",
      "Epoch 5/5 | Train Loss: 0.0691 | Train Acc: 0.9760 | Val Loss: 0.2192 | Val Acc: 0.9454 | Val F1: 0.9450 | Time: 4.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-12 18:17:10,039] Trial 19 finished with value: 0.9368550824987756 and parameters: {'backbone': 'resnet18', 'batch_size': 32, 'learning_rate': 0.0004678958791799986, 'weight_decay': 0.00017905940393727802, 'use_class_weights': True, 'scheduler_type': 'step', 'freeze_ratio': 0.5446103783744939}. Best is trial 17 with value: 0.945942951716684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 | Val Accuracy: 0.9454 | Precision: 0.9452 | Recall: 0.9454 | F1: 0.9450\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.93      0.89      0.91       225\n",
      "         Mask       0.95      0.97      0.96       388\n",
      "Improper Mask       0.95      0.97      0.96       156\n",
      "\n",
      "     accuracy                           0.95       769\n",
      "    macro avg       0.94      0.94      0.94       769\n",
      " weighted avg       0.95      0.95      0.95       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9369\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.91      0.91      1128\n",
      "         Mask       0.95      0.96      0.96      1940\n",
      "Improper Mask       0.94      0.93      0.93       780\n",
      "\n",
      "     accuracy                           0.94      3848\n",
      "    macro avg       0.93      0.93      0.93      3848\n",
      " weighted avg       0.94      0.94      0.94      3848\n",
      "\n",
      "Best trial:\n",
      "  Value: 0.945942951716684\n",
      "  backbone: resnet18\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.00047727527324339177\n",
      "  weight_decay: 0.00016745238338472984\n",
      "  use_class_weights: True\n",
      "  scheduler_type: cosine\n",
      "  freeze_ratio: 0.539003338255835\n"
     ]
    }
   ],
   "source": [
    "# run optuna to get betst hyperparameters\n",
    "params = optimize_hyperparameters(\n",
    "    all_train_image_paths, \n",
    "    all_train_labels, \n",
    "    kfold_splits, \n",
    "    n_trials=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Fold 0 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/30 | Train Loss: 0.5412 | Train Acc: 0.7846 | Val Loss: 0.2563 | Val Acc: 0.9091 | Val F1: 0.9097 | Time: 4.17s\n",
      "Epoch 2/30 | Train Loss: 0.2314 | Train Acc: 0.9204 | Val Loss: 0.2397 | Val Acc: 0.9390 | Val F1: 0.9390 | Time: 4.19s\n",
      "Epoch 3/30 | Train Loss: 0.1484 | Train Acc: 0.9431 | Val Loss: 0.2153 | Val Acc: 0.9286 | Val F1: 0.9289 | Time: 3.97s\n",
      "Epoch 4/30 | Train Loss: 0.1040 | Train Acc: 0.9652 | Val Loss: 0.2871 | Val Acc: 0.9416 | Val F1: 0.9409 | Time: 4.09s\n",
      "Epoch 5/30 | Train Loss: 0.0720 | Train Acc: 0.9747 | Val Loss: 0.2299 | Val Acc: 0.9610 | Val F1: 0.9610 | Time: 4.25s\n",
      "Epoch 6/30 | Train Loss: 0.0718 | Train Acc: 0.9776 | Val Loss: 0.2481 | Val Acc: 0.9325 | Val F1: 0.9324 | Time: 5.45s\n",
      "Epoch 7/30 | Train Loss: 0.0301 | Train Acc: 0.9916 | Val Loss: 0.2328 | Val Acc: 0.9416 | Val F1: 0.9417 | Time: 4.32s\n",
      "Epoch 8/30 | Train Loss: 0.0471 | Train Acc: 0.9864 | Val Loss: 0.2099 | Val Acc: 0.9623 | Val F1: 0.9621 | Time: 4.17s\n",
      "Epoch 9/30 | Train Loss: 0.0302 | Train Acc: 0.9880 | Val Loss: 0.2658 | Val Acc: 0.9429 | Val F1: 0.9431 | Time: 3.99s\n",
      "Epoch 10/30 | Train Loss: 0.0327 | Train Acc: 0.9880 | Val Loss: 0.2302 | Val Acc: 0.9558 | Val F1: 0.9556 | Time: 3.95s\n",
      "Epoch 11/30 | Train Loss: 0.0166 | Train Acc: 0.9951 | Val Loss: 0.1925 | Val Acc: 0.9610 | Val F1: 0.9611 | Time: 4.01s\n",
      "Epoch 12/30 | Train Loss: 0.0324 | Train Acc: 0.9893 | Val Loss: 0.2333 | Val Acc: 0.9558 | Val F1: 0.9558 | Time: 4.14s\n",
      "Epoch 13/30 | Train Loss: 0.0201 | Train Acc: 0.9951 | Val Loss: 0.2005 | Val Acc: 0.9701 | Val F1: 0.9701 | Time: 4.20s\n",
      "Epoch 14/30 | Train Loss: 0.0712 | Train Acc: 0.9769 | Val Loss: 0.2076 | Val Acc: 0.9662 | Val F1: 0.9662 | Time: 5.56s\n",
      "Epoch 15/30 | Train Loss: 0.0238 | Train Acc: 0.9912 | Val Loss: 0.2348 | Val Acc: 0.9662 | Val F1: 0.9662 | Time: 4.24s\n",
      "Epoch 16/30 | Train Loss: 0.0136 | Train Acc: 0.9977 | Val Loss: 0.2163 | Val Acc: 0.9636 | Val F1: 0.9636 | Time: 4.13s\n",
      "Early stopping at epoch 16\n",
      "\n",
      "Fold 0 | Val Accuracy: 0.9610 | Precision: 0.9614 | Recall: 0.9610 | F1: 0.9611\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.94      0.97      0.95       226\n",
      "         Mask       0.98      0.96      0.97       388\n",
      "Improper Mask       0.96      0.96      0.96       156\n",
      "\n",
      "     accuracy                           0.96       770\n",
      "    macro avg       0.96      0.96      0.96       770\n",
      " weighted avg       0.96      0.96      0.96       770\n",
      "\n",
      "\n",
      "--- Starting Fold 1 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/30 | Train Loss: 0.5268 | Train Acc: 0.7901 | Val Loss: 0.2972 | Val Acc: 0.8753 | Val F1: 0.8771 | Time: 3.88s\n",
      "Epoch 2/30 | Train Loss: 0.2296 | Train Acc: 0.9178 | Val Loss: 0.2801 | Val Acc: 0.9026 | Val F1: 0.9035 | Time: 4.05s\n",
      "Epoch 3/30 | Train Loss: 0.1258 | Train Acc: 0.9578 | Val Loss: 0.3474 | Val Acc: 0.8883 | Val F1: 0.8904 | Time: 4.08s\n",
      "Epoch 4/30 | Train Loss: 0.0785 | Train Acc: 0.9724 | Val Loss: 0.2536 | Val Acc: 0.9195 | Val F1: 0.9202 | Time: 4.17s\n",
      "Epoch 5/30 | Train Loss: 0.1007 | Train Acc: 0.9672 | Val Loss: 0.2960 | Val Acc: 0.9286 | Val F1: 0.9286 | Time: 4.11s\n",
      "Epoch 6/30 | Train Loss: 0.0456 | Train Acc: 0.9828 | Val Loss: 0.2913 | Val Acc: 0.9182 | Val F1: 0.9193 | Time: 5.47s\n",
      "Epoch 7/30 | Train Loss: 0.0303 | Train Acc: 0.9899 | Val Loss: 0.3337 | Val Acc: 0.9312 | Val F1: 0.9315 | Time: 4.17s\n",
      "Epoch 8/30 | Train Loss: 0.0423 | Train Acc: 0.9851 | Val Loss: 0.3829 | Val Acc: 0.9169 | Val F1: 0.9174 | Time: 4.02s\n",
      "Epoch 9/30 | Train Loss: 0.0259 | Train Acc: 0.9909 | Val Loss: 0.3469 | Val Acc: 0.9312 | Val F1: 0.9313 | Time: 4.15s\n",
      "Early stopping at epoch 9\n",
      "\n",
      "Fold 1 | Val Accuracy: 0.9195 | Precision: 0.9230 | Recall: 0.9195 | F1: 0.9202\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.84      0.93      0.88       226\n",
      "         Mask       0.95      0.92      0.93       388\n",
      "Improper Mask       0.97      0.90      0.94       156\n",
      "\n",
      "     accuracy                           0.92       770\n",
      "    macro avg       0.92      0.92      0.92       770\n",
      " weighted avg       0.92      0.92      0.92       770\n",
      "\n",
      "\n",
      "--- Starting Fold 2 ---\n",
      "Training on 3078 samples, validating on 770 samples\n",
      "Training class distribution: [ 902 1552  624]\n",
      "Validation class distribution: [226 388 156]\n",
      "Epoch 1/30 | Train Loss: 0.5429 | Train Acc: 0.7846 | Val Loss: 0.3223 | Val Acc: 0.8948 | Val F1: 0.8953 | Time: 4.11s\n",
      "Epoch 2/30 | Train Loss: 0.2405 | Train Acc: 0.9165 | Val Loss: 0.2742 | Val Acc: 0.9078 | Val F1: 0.9074 | Time: 4.11s\n",
      "Epoch 3/30 | Train Loss: 0.1557 | Train Acc: 0.9418 | Val Loss: 0.2486 | Val Acc: 0.9260 | Val F1: 0.9269 | Time: 4.17s\n",
      "Epoch 4/30 | Train Loss: 0.0883 | Train Acc: 0.9704 | Val Loss: 0.2257 | Val Acc: 0.9416 | Val F1: 0.9414 | Time: 5.56s\n",
      "Epoch 5/30 | Train Loss: 0.0702 | Train Acc: 0.9743 | Val Loss: 0.2650 | Val Acc: 0.9377 | Val F1: 0.9378 | Time: 4.23s\n",
      "Epoch 6/30 | Train Loss: 0.0804 | Train Acc: 0.9753 | Val Loss: 0.1917 | Val Acc: 0.9558 | Val F1: 0.9558 | Time: 4.12s\n",
      "Epoch 7/30 | Train Loss: 0.0296 | Train Acc: 0.9925 | Val Loss: 0.2931 | Val Acc: 0.9532 | Val F1: 0.9532 | Time: 4.06s\n",
      "Epoch 8/30 | Train Loss: 0.0517 | Train Acc: 0.9847 | Val Loss: 0.2478 | Val Acc: 0.9325 | Val F1: 0.9327 | Time: 4.02s\n",
      "Epoch 9/30 | Train Loss: 0.0200 | Train Acc: 0.9958 | Val Loss: 0.2961 | Val Acc: 0.9468 | Val F1: 0.9465 | Time: 4.17s\n",
      "Epoch 10/30 | Train Loss: 0.0293 | Train Acc: 0.9903 | Val Loss: 0.1987 | Val Acc: 0.9442 | Val F1: 0.9446 | Time: 4.18s\n",
      "Epoch 11/30 | Train Loss: 0.0345 | Train Acc: 0.9909 | Val Loss: 0.2489 | Val Acc: 0.9468 | Val F1: 0.9467 | Time: 4.10s\n",
      "Early stopping at epoch 11\n",
      "\n",
      "Fold 2 | Val Accuracy: 0.9558 | Precision: 0.9559 | Recall: 0.9558 | F1: 0.9558\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.94      0.94      0.94       226\n",
      "         Mask       0.96      0.97      0.96       388\n",
      "Improper Mask       0.97      0.96      0.96       156\n",
      "\n",
      "     accuracy                           0.96       770\n",
      "    macro avg       0.96      0.95      0.95       770\n",
      " weighted avg       0.96      0.96      0.96       770\n",
      "\n",
      "\n",
      "--- Starting Fold 3 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/30 | Train Loss: 0.5207 | Train Acc: 0.7921 | Val Loss: 0.3801 | Val Acc: 0.8700 | Val F1: 0.8720 | Time: 5.56s\n",
      "Epoch 2/30 | Train Loss: 0.2147 | Train Acc: 0.9234 | Val Loss: 0.2363 | Val Acc: 0.9194 | Val F1: 0.9189 | Time: 4.31s\n",
      "Epoch 3/30 | Train Loss: 0.1234 | Train Acc: 0.9500 | Val Loss: 0.2254 | Val Acc: 0.9324 | Val F1: 0.9329 | Time: 4.10s\n",
      "Epoch 4/30 | Train Loss: 0.0931 | Train Acc: 0.9691 | Val Loss: 0.1804 | Val Acc: 0.9298 | Val F1: 0.9301 | Time: 4.14s\n",
      "Epoch 5/30 | Train Loss: 0.0613 | Train Acc: 0.9821 | Val Loss: 0.1813 | Val Acc: 0.9467 | Val F1: 0.9469 | Time: 4.19s\n",
      "Epoch 6/30 | Train Loss: 0.0541 | Train Acc: 0.9812 | Val Loss: 0.1984 | Val Acc: 0.9545 | Val F1: 0.9544 | Time: 4.09s\n",
      "Epoch 7/30 | Train Loss: 0.0483 | Train Acc: 0.9844 | Val Loss: 0.1846 | Val Acc: 0.9454 | Val F1: 0.9456 | Time: 4.05s\n",
      "Epoch 8/30 | Train Loss: 0.0222 | Train Acc: 0.9935 | Val Loss: 0.2092 | Val Acc: 0.9493 | Val F1: 0.9494 | Time: 4.05s\n",
      "Epoch 9/30 | Train Loss: 0.0381 | Train Acc: 0.9870 | Val Loss: 0.2705 | Val Acc: 0.9337 | Val F1: 0.9325 | Time: 5.48s\n",
      "Early stopping at epoch 9\n",
      "\n",
      "Fold 3 | Val Accuracy: 0.9298 | Precision: 0.9317 | Recall: 0.9298 | F1: 0.9301\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.88      0.91      0.89       225\n",
      "         Mask       0.97      0.92      0.94       388\n",
      "Improper Mask       0.92      0.98      0.95       156\n",
      "\n",
      "     accuracy                           0.93       769\n",
      "    macro avg       0.92      0.94      0.93       769\n",
      " weighted avg       0.93      0.93      0.93       769\n",
      "\n",
      "\n",
      "--- Starting Fold 4 ---\n",
      "Training on 3079 samples, validating on 769 samples\n",
      "Training class distribution: [ 903 1552  624]\n",
      "Validation class distribution: [225 388 156]\n",
      "Epoch 1/30 | Train Loss: 0.5103 | Train Acc: 0.8071 | Val Loss: 0.3008 | Val Acc: 0.8934 | Val F1: 0.8934 | Time: 4.17s\n",
      "Epoch 2/30 | Train Loss: 0.1955 | Train Acc: 0.9302 | Val Loss: 0.3162 | Val Acc: 0.8960 | Val F1: 0.8982 | Time: 4.10s\n",
      "Epoch 3/30 | Train Loss: 0.1025 | Train Acc: 0.9636 | Val Loss: 0.5013 | Val Acc: 0.8544 | Val F1: 0.8542 | Time: 4.12s\n",
      "Epoch 4/30 | Train Loss: 0.1001 | Train Acc: 0.9639 | Val Loss: 0.4011 | Val Acc: 0.8934 | Val F1: 0.8926 | Time: 4.03s\n",
      "Epoch 5/30 | Train Loss: 0.0543 | Train Acc: 0.9808 | Val Loss: 0.3500 | Val Acc: 0.9116 | Val F1: 0.9127 | Time: 4.14s\n",
      "Epoch 6/30 | Train Loss: 0.0819 | Train Acc: 0.9714 | Val Loss: 0.2676 | Val Acc: 0.9389 | Val F1: 0.9382 | Time: 4.17s\n",
      "Epoch 7/30 | Train Loss: 0.0290 | Train Acc: 0.9919 | Val Loss: 0.2463 | Val Acc: 0.9376 | Val F1: 0.9377 | Time: 5.54s\n",
      "Epoch 8/30 | Train Loss: 0.0392 | Train Acc: 0.9867 | Val Loss: 0.2750 | Val Acc: 0.9389 | Val F1: 0.9385 | Time: 4.35s\n",
      "Epoch 9/30 | Train Loss: 0.0388 | Train Acc: 0.9883 | Val Loss: 0.2462 | Val Acc: 0.9467 | Val F1: 0.9468 | Time: 4.17s\n",
      "Epoch 10/30 | Train Loss: 0.0228 | Train Acc: 0.9909 | Val Loss: 0.2611 | Val Acc: 0.9363 | Val F1: 0.9363 | Time: 4.12s\n",
      "Epoch 11/30 | Train Loss: 0.0226 | Train Acc: 0.9919 | Val Loss: 0.2626 | Val Acc: 0.9363 | Val F1: 0.9364 | Time: 4.17s\n",
      "Epoch 12/30 | Train Loss: 0.0305 | Train Acc: 0.9906 | Val Loss: 0.2094 | Val Acc: 0.9519 | Val F1: 0.9517 | Time: 4.20s\n",
      "Epoch 13/30 | Train Loss: 0.0044 | Train Acc: 0.9990 | Val Loss: 0.2389 | Val Acc: 0.9506 | Val F1: 0.9507 | Time: 4.18s\n",
      "Epoch 14/30 | Train Loss: 0.0176 | Train Acc: 0.9948 | Val Loss: 0.2477 | Val Acc: 0.9545 | Val F1: 0.9545 | Time: 4.16s\n",
      "Epoch 15/30 | Train Loss: 0.0078 | Train Acc: 0.9974 | Val Loss: 0.3272 | Val Acc: 0.9350 | Val F1: 0.9353 | Time: 5.35s\n",
      "Epoch 16/30 | Train Loss: 0.0055 | Train Acc: 0.9981 | Val Loss: 0.2446 | Val Acc: 0.9493 | Val F1: 0.9493 | Time: 4.11s\n",
      "Epoch 17/30 | Train Loss: 0.0018 | Train Acc: 0.9994 | Val Loss: 0.2899 | Val Acc: 0.9519 | Val F1: 0.9520 | Time: 4.13s\n",
      "Early stopping at epoch 17\n",
      "\n",
      "Fold 4 | Val Accuracy: 0.9519 | Precision: 0.9518 | Recall: 0.9519 | F1: 0.9517\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.94      0.91      0.93       225\n",
      "         Mask       0.95      0.97      0.96       388\n",
      "Improper Mask       0.96      0.97      0.97       156\n",
      "\n",
      "     accuracy                           0.95       769\n",
      "    macro avg       0.95      0.95      0.95       769\n",
      " weighted avg       0.95      0.95      0.95       769\n",
      "\n",
      "\n",
      "Average validation accuracy across all folds: 0.9436\n",
      "\n",
      "Overall Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.91      0.93      0.92      1128\n",
      "         Mask       0.96      0.95      0.95      1940\n",
      "Improper Mask       0.95      0.96      0.95       780\n",
      "\n",
      "     accuracy                           0.94      3848\n",
      "    macro avg       0.94      0.94      0.94      3848\n",
      " weighted avg       0.94      0.94      0.94      3848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recreate model builder using best params\n",
    "def build_model_with_params():\n",
    "    model = build_model(\n",
    "        backbone=params['backbone'],\n",
    "        pretrained=True\n",
    "    )\n",
    "    return freeze_model(model, freeze_ratio=params['freeze_ratio'])\n",
    "\n",
    "\n",
    "\n",
    "# Class weights if needed\n",
    "class_weights = calculate_class_weights(all_train_labels) if params['use_class_weights'] else None\n",
    "\n",
    "# Perform k-fold validation using best params\n",
    "metrics = kfold_cross_validation(\n",
    "    model_fn=build_model_with_params,\n",
    "    train_image_paths=all_train_image_paths,\n",
    "    train_labels=all_train_labels,\n",
    "    kfold_splits=kfold_splits,\n",
    "    batch_size=params['batch_size'],\n",
    "    num_epochs=30,\n",
    "    learning_rate=params['learning_rate'],\n",
    "    weight_decay=params['weight_decay'],\n",
    "    class_weights=class_weights,\n",
    "    scheduler_type=params['scheduler_type'],\n",
    "    freeze_ratio=params['freeze_ratio']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.5401 | Val Loss: 0.3934 | Time: 4.96s\n",
      "Epoch 02 | Train Loss: 0.3178 | Val Loss: 0.2692 | Time: 4.96s\n",
      "Epoch 03 | Train Loss: 0.2214 | Val Loss: 0.1739 | Time: 4.92s\n",
      "Epoch 04 | Train Loss: 0.1697 | Val Loss: 0.1835 | Time: 5.05s\n",
      "Epoch 05 | Train Loss: 0.1472 | Val Loss: 0.1597 | Time: 6.21s\n",
      "Epoch 06 | Train Loss: 0.1079 | Val Loss: 0.1264 | Time: 4.97s\n",
      "Epoch 07 | Train Loss: 0.1048 | Val Loss: 0.1114 | Time: 5.00s\n",
      "Epoch 08 | Train Loss: 0.0909 | Val Loss: 0.1004 | Time: 4.96s\n",
      "Epoch 09 | Train Loss: 0.0847 | Val Loss: 0.1380 | Time: 4.96s\n",
      "Epoch 10 | Train Loss: 0.0942 | Val Loss: 0.1058 | Time: 4.98s\n",
      "Epoch 11 | Train Loss: 0.0936 | Val Loss: 0.1514 | Time: 6.34s\n",
      "Epoch 12 | Train Loss: 0.0565 | Val Loss: 0.0956 | Time: 5.09s\n",
      "Epoch 13 | Train Loss: 0.0570 | Val Loss: 0.1452 | Time: 4.86s\n",
      "Epoch 14 | Train Loss: 0.0626 | Val Loss: 0.1030 | Time: 5.04s\n",
      "Epoch 15 | Train Loss: 0.0438 | Val Loss: 0.1104 | Time: 4.83s\n",
      "Epoch 16 | Train Loss: 0.0557 | Val Loss: 0.0974 | Time: 5.04s\n",
      "Epoch 17 | Train Loss: 0.0359 | Val Loss: 0.1408 | Time: 5.06s\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# Train final model using full training set (with val split from it)\n",
    "final_model, test_metrics = train_final_model(\n",
    "    params,\n",
    "    all_train_image_paths,\n",
    "    all_train_labels,\n",
    "    test_image_paths,\n",
    "    test_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Final Test Results =====\n",
      "Test Accuracy: 0.9148\n",
      "Test Precision: 0.9262\n",
      "Test Recall: 0.9148\n",
      "Test F1 Score: 0.9186\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      No Mask       0.68      0.88      0.77        51\n",
      "         Mask       0.98      0.93      0.95       388\n",
      "Improper Mask       0.57      0.63      0.60        19\n",
      "\n",
      "     accuracy                           0.91       458\n",
      "    macro avg       0.74      0.82      0.77       458\n",
      " weighted avg       0.93      0.91      0.92       458\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test metrics\n",
    "print(\"\\n##### Final Test Results #####\")\n",
    "print(f\"Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"Test Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Test Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"Test F1 Score: {test_metrics['f1']:.4f}\")\n",
    "print(test_metrics['classification_report'])\n",
    "\n",
    "# Confusion matrix\n",
    "cm = test_metrics['confusion_matrix']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Mask', 'Mask', 'Improper Mask'],\n",
    "            yticklabels=['No Mask', 'Mask', 'Improper Mask'])\n",
    "plt.title('Test Set Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development of CNN Model: Major Findings\n",
    "\n",
    "- **Transfer learning works effectively**: Pre-trained ResNet18 vastly outperforms MobileNetV2, suggesting architecture matters more than model size\n",
    "\n",
    "- **Class imbalance** still remained an issue: but this was mititgated as much as possible by using augmentation, detection of the minority class (\"Improper Mask 2\") is still lagging behind, with only 63% recall compared to 93% for the majority class\n",
    "\n",
    "- **Test Distribution Shift Impact**: The 3% gap between validation performance (94.6%) and test performance (91.5%) suggests that the model has trouble generalizing to the test set with a different distribution but this is quite a small diffrence so not much of an issue\n",
    "\n",
    "- **Hyperparameter significance**: Learning rate ~0.0005 and freeze ratio ~0.54 were critical, freezing approximately half the pre-trained layers helped to provide the right balance between feature reuse and adaptation\n",
    "\n",
    "- **Training efficiency**: Early stopping typically triggered between epochs 9-17, indicating diminishing returns beyond this point and potential for faster training cycles, and this was significantly helpful at reducing training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-env)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
